#!/usr/bin/env python3
"""
ğŸ”¬ å…¨é¢è¯Šæ–­ bias_scale ä¸å­¦ä¹ çš„é—®é¢˜
"""
import sys
sys.path.insert(0, '.')

import torch
from mmcv import Config
from mmdet3d.models import build_model

# ğŸ”¥ å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ä»¥æ³¨å†Œæ‰€æœ‰ç»„ä»¶
import projects.mmdet3d_plugin  # noqa: F401

def diagnose_bias_scale():
    """å…¨é¢è¯Šæ–­"""
    
    print("="*80)
    print("ğŸ”¬ Bias Scale å­¦ä¹ é—®é¢˜è¯Šæ–­")
    print("="*80)
    
    # Step 1: åŠ è½½é…ç½®
    print("\nğŸ“‹ Step 1: åŠ è½½é…ç½®æ–‡ä»¶")
    print("-"*80)
    config_file = 'projects/configs/fusion/cmt_aqr_voxel0075_vov_1600x640_cbgs.py'
    cfg = Config.fromfile(config_file)
    
    # æ£€æŸ¥é…ç½®ä¸­çš„ optimizer
    if hasattr(cfg, 'optimizer') and 'paramwise_cfg' in cfg.optimizer:
        custom_keys = cfg.optimizer['paramwise_cfg']['custom_keys']
        print("âœ… é…ç½®æ–‡ä»¶ä¸­çš„ optimizer.paramwise_cfg.custom_keys:")
        for key, value in custom_keys.items():
            if 'bias' in key.lower():
                print(f"   ğŸ”¥ {key}: {value}")
    else:
        print("âŒ é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° paramwise_cfg!")
    
    # Step 2: æ„å»ºæ¨¡å‹
    print("\nğŸ”¨ Step 2: æ„å»ºæ¨¡å‹")
    print("-"*80)
    try:
        model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))
        print("âœ… æ¨¡å‹æ„å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ„å»ºå¤±è´¥: {e}")
        return
    
    # Step 3: æ£€æŸ¥ bias_scale æ˜¯å¦å­˜åœ¨
    print("\nğŸ” Step 3: æŸ¥æ‰¾ bias_scale å‚æ•°")
    print("-"*80)
    
    bias_scale_found = False
    bias_scale_param = None
    bias_scale_name = None
    
    for name, param in model.named_parameters():
        if 'bias_scale' in name:
            bias_scale_found = True
            bias_scale_param = param
            bias_scale_name = name
            
            print(f"âœ… æ‰¾åˆ° bias_scale å‚æ•°!")
            print(f"   å®Œæ•´å‚æ•°å: {name}")
            print(f"   å½“å‰å€¼: {param.item():.6f}")
            print(f"   requires_grad: {param.requires_grad}")
            print(f"   is_leaf: {param.is_leaf}")
            print(f"   shape: {param.shape}")
            print(f"   dtype: {param.dtype}")
            print(f"   device: {param.device}")
    
    if not bias_scale_found:
        print("âŒ æ²¡æœ‰æ‰¾åˆ° bias_scale å‚æ•°!")
        print("\nå¯èƒ½çš„åŸå› :")
        print("1. enable_aqr=False")
        print("2. learnable_scale=False")
        print("3. attention_bias_generator æ²¡æœ‰æ­£ç¡®åˆå§‹åŒ–")
        return
    
    # Step 4: æ£€æŸ¥ä¼˜åŒ–å™¨é…ç½®åŒ¹é…
    print("\nğŸ” Step 4: æ£€æŸ¥ä¼˜åŒ–å™¨é…ç½®åŒ¹é…")
    print("-"*80)
    
    # åˆ—å‡ºæ‰€æœ‰å¯èƒ½çš„é…ç½®é”®
    possible_keys = [
        'bias_scale',
        'attention_bias_generator.bias_scale',
        'pts_bbox_head.attention_bias_generator.bias_scale',
    ]
    
    print(f"å®é™…å‚æ•°å: {bias_scale_name}")
    print(f"\næ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­çš„é”®:")
    
    for key in possible_keys:
        is_in_config = key in custom_keys
        would_match = key in bias_scale_name
        
        status = "âœ…" if is_in_config else "âŒ"
        match_status = "âœ…" if would_match else "âŒ"
        
        print(f"  {status} '{key}'")
        print(f"     - åœ¨é…ç½®ä¸­: {is_in_config}")
        print(f"     - ä¼šåŒ¹é…å‚æ•°å: {would_match}")
        
        if is_in_config:
            print(f"     - lr_mult: {custom_keys[key].get('lr_mult', 'N/A')}")
    
    # Step 5: æ¨¡æ‹Ÿä¼˜åŒ–å™¨è®¾ç½®
    print("\nğŸ§ª Step 5: æ¨¡æ‹Ÿä¼˜åŒ–å™¨å‚æ•°ç»„æ„å»º")
    print("-"*80)
    
    # æ£€æŸ¥å“ªä¸ªé…ç½®ä¼šåŒ¹é…
    matched_config = None
    for key in possible_keys:
        if key in custom_keys and key in bias_scale_name:
            matched_config = key
            break
    
    if matched_config:
        print(f"âœ… å‚æ•° '{bias_scale_name}' ä¼šè¢«é…ç½®é”® '{matched_config}' åŒ¹é…")
        print(f"   lr_mult: {custom_keys[matched_config]['lr_mult']}")
    else:
        print(f"âŒ å‚æ•° '{bias_scale_name}' ä¸ä¼šè¢«ä»»ä½•é…ç½®é”®åŒ¹é…!")
        print(f"\nğŸ”§ å»ºè®®ä¿®å¤:")
        print(f"   åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ : '{bias_scale_name}': dict(lr_mult=1.0)")
    
    # Step 6: æ£€æŸ¥æ‰€æœ‰ attention_bias ç›¸å…³å‚æ•°
    print("\nğŸ“Š Step 6: æ‰€æœ‰ attention_bias ç›¸å…³å‚æ•°")
    print("-"*80)
    
    count = 0
    for name, param in model.named_parameters():
        if 'attention_bias' in name:
            count += 1
            print(f"{count}. {name}")
            print(f"   - requires_grad: {param.requires_grad}")
            print(f"   - shape: {param.shape}")
    
    if count == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½• attention_bias ç›¸å…³å‚æ•°!")
    
    # Step 7: æµ‹è¯•æ¢¯åº¦è®¡ç®—
    print("\nğŸ§ª Step 7: æµ‹è¯•æ¢¯åº¦è®¡ç®—")
    print("-"*80)
    
    if bias_scale_param is not None and bias_scale_param.requires_grad:
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æŸå¤±å‡½æ•°
        dummy_loss = bias_scale_param * 2.0
        dummy_loss.backward()
        
        if bias_scale_param.grad is not None:
            print(f"âœ… æ¢¯åº¦è®¡ç®—æˆåŠŸ!")
            print(f"   grad: {bias_scale_param.grad.item():.6f}")
        else:
            print(f"âŒ æ¢¯åº¦è®¡ç®—å¤±è´¥! grad is None")
    else:
        print(f"âŒ æ— æ³•æµ‹è¯•æ¢¯åº¦ (requires_grad={bias_scale_param.requires_grad if bias_scale_param else 'N/A'})")
    
    # Step 8: ç”Ÿæˆä¿®å¤å»ºè®®
    print("\n" + "="*80)
    print("ğŸ”§ è¯Šæ–­æ€»ç»“å’Œä¿®å¤å»ºè®®")
    print("="*80)
    
    if not bias_scale_found:
        print("âŒ é—®é¢˜: bias_scale å‚æ•°ä¸å­˜åœ¨")
        print("\nä¿®å¤æ­¥éª¤:")
        print("1. æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­ enable_aqr=True")
        print("2. æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­ learnable_scale=True")
        print("3. æ£€æŸ¥ attention_bias_config æ˜¯å¦æ­£ç¡®é…ç½®")
    elif not matched_config:
        print("âŒ é—®é¢˜: bias_scale å‚æ•°å­˜åœ¨ä½†ä¸ä¼šè¢«ä¼˜åŒ–å™¨åŒ¹é…")
        print(f"\nå®é™…å‚æ•°å: {bias_scale_name}")
        print(f"\nä¿®å¤æ­¥éª¤:")
        print(f"1. åœ¨é…ç½®æ–‡ä»¶çš„ optimizer.paramwise_cfg.custom_keys ä¸­æ·»åŠ :")
        print(f"   '{bias_scale_name}': dict(lr_mult=1.0),")
        print(f"\n2. æˆ–è€…æ£€æŸ¥å½“å‰é…ç½®æ˜¯å¦æœ‰æ‹¼å†™é”™è¯¯")
    else:
        print("âœ… é…ç½®çœ‹èµ·æ¥æ­£ç¡®!")
        print(f"   å‚æ•°å: {bias_scale_name}")
        print(f"   åŒ¹é…çš„é…ç½®é”®: {matched_config}")
        print(f"   lr_mult: {custom_keys[matched_config]['lr_mult']}")
        print("\nå¦‚æœè®­ç»ƒæ—¶ä»ç„¶ä¸æ›´æ–°ï¼Œå¯èƒ½çš„åŸå› :")
        print("1. æœåŠ¡å™¨ä»£ç æœªåŒæ­¥ - è¯·æ£€æŸ¥æœåŠ¡å™¨ä¸Šçš„æ–‡ä»¶")
        print("2. ä½¿ç”¨äº†é”™è¯¯çš„é…ç½®æ–‡ä»¶")
        print("3. checkpointä¸­åŠ è½½äº†æ—§çš„å€¼")
        print("4. å­¦ä¹ ç‡è¿‡å°æˆ–æ¢¯åº¦è¿‡å°")
    
    # Step 9: ç”Ÿæˆæ–‡ä»¶åŒæ­¥æ£€æŸ¥è„šæœ¬
    print("\n" + "="*80)
    print("ğŸ“ ç”Ÿæˆæ–‡ä»¶åŒæ­¥æ£€æŸ¥è„šæœ¬")
    print("="*80)
    
    sync_check_script = """#!/bin/bash
# æ£€æŸ¥å…³é”®æ–‡ä»¶çš„æœ€åä¿®æ”¹æ—¶é—´

echo "==================================================================="
echo "ğŸ” æ£€æŸ¥å…³é”®æ–‡ä»¶æ˜¯å¦å·²åŒæ­¥"
echo "==================================================================="

files=(
    "projects/configs/fusion/cmt_aqr_voxel0075_vov_1600x640_cbgs.py"
    "projects/mmdet3d_plugin/models/utils/attention_bias_generator.py"
    "projects/mmdet3d_plugin/models/dense_heads/cmt_head.py"
)

for file in "${files[@]}"; do
    echo ""
    echo "ğŸ“„ æ–‡ä»¶: $file"
    if [ -f "$file" ]; then
        echo "   âœ… å­˜åœ¨"
        echo "   æœ€åä¿®æ”¹: $(stat -c '%y' "$file" 2>/dev/null || stat -f '%Sm' "$file")"
        echo "   å¤§å°: $(stat -c '%s' "$file" 2>/dev/null || stat -f '%z' "$file") bytes"
        
        # æ£€æŸ¥å…³é”®è¡Œ
        if [[ "$file" == *"cmt_aqr_voxel0075_vov_1600x640_cbgs.py" ]]; then
            echo "   æ£€æŸ¥ç¬¬35è¡Œ (bias_scale é…ç½®):"
            sed -n '35p' "$file"
        fi
        
        if [[ "$file" == *"attention_bias_generator.py" ]]; then
            echo "   æ£€æŸ¥ç¬¬88è¡Œ (nn.Parameter åˆ›å»º):"
            sed -n '88p' "$file"
        fi
    else
        echo "   âŒ æ–‡ä»¶ä¸å­˜åœ¨!"
    fi
done

echo ""
echo "==================================================================="
"""
    
    with open('CMT-master/check_file_sync.sh', 'w') as f:
        f.write(sync_check_script)
    
    print("âœ… å·²ç”Ÿæˆ check_file_sync.sh")
    print("   åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œ: bash check_file_sync.sh")
    
    print("\nğŸ¯ è¯Šæ–­å®Œæˆ!")

if __name__ == '__main__':
    diagnose_bias_scale()

