#!/usr/bin/env python3
"""
AQRæƒé‡å›¾å¯è§†åŒ–å·¥å…· ğŸ¾
ç”¨äºå¯è§†åŒ–AQRç”Ÿæˆçš„æƒé‡åˆ†é…ï¼ŒéªŒè¯æƒé‡æ˜¯å¦é›†ä¸­åœ¨ç›®æ ‡ä½ç½®

ä½¿ç”¨æ–¹æ³•:
1. è®­ç»ƒæ—¶å¯ç”¨debug_modeå’Œå¯è§†åŒ–:
   python tools/train.py configs/fusion/cmt_aqr_config.py --debug-aqr

2. å•ç‹¬å¯è§†åŒ–å·²ä¿å­˜çš„æƒé‡:
   python tools/visualize_aqr_weights.py --config configs/fusion/cmt_aqr_config.py \
       --checkpoint work_dirs/latest.pth --save-dir viz_output/
"""

import argparse
import os
import numpy as np
import torch
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.colors import LinearSegmentedColormap
import cv2

from mmdet3d.apis import init_model, inference_detector
from mmcv import Config
from mmdet3d.datasets import build_dataloader, build_dataset


def visualize_weight_map_with_boxes(weight_map, gt_boxes_2d=None, pred_boxes_2d=None, 
                                   save_path='weight_viz.png', title='AQR Weight Map'):
    """
    å¯è§†åŒ–æƒé‡å›¾ï¼Œå¹¶å åŠ GTå’Œé¢„æµ‹æ¡†
    
    Args:
        weight_map: [H, W] æƒé‡å›¾
        gt_boxes_2d: List of [x, y, w, h] GTæ¡†åœ¨ç‰¹å¾å›¾ä¸Šçš„åæ ‡
        pred_boxes_2d: List of [x, y, w, h] é¢„æµ‹æ¡†åœ¨ç‰¹å¾å›¾ä¸Šçš„åæ ‡
        save_path: ä¿å­˜è·¯å¾„
        title: å›¾è¡¨æ ‡é¢˜
    """
    plt.figure(figsize=(12, 10))
    
    # åˆ›å»ºè‡ªå®šä¹‰é¢œè‰²æ˜ å°„ï¼šè“(ä½æƒé‡) -> ç»¿ -> é»„ -> çº¢(é«˜æƒé‡)
    colors = ['#000033', '#0000FF', '#00FF00', '#FFFF00', '#FF0000']
    n_bins = 100
    cmap = LinearSegmentedColormap.from_list('aqr_weights', colors, N=n_bins)
    
    # ç»˜åˆ¶æƒé‡å›¾
    im = plt.imshow(weight_map, cmap=cmap, interpolation='bilinear', aspect='auto')
    plt.colorbar(im, label='Weight Value', fraction=0.046, pad=0.04)
    
    # å åŠ GTæ¡†ï¼ˆç»¿è‰²ï¼‰
    if gt_boxes_2d is not None and len(gt_boxes_2d) > 0:
        for box in gt_boxes_2d:
            x, y, w, h = box
            rect = patches.Rectangle((x, y), w, h, linewidth=2, 
                                     edgecolor='lime', facecolor='none', 
                                     label='GT Box')
            plt.gca().add_patch(rect)
    
    # å åŠ é¢„æµ‹æ¡†ï¼ˆé»„è‰²ï¼‰
    if pred_boxes_2d is not None and len(pred_boxes_2d) > 0:
        for box in pred_boxes_2d:
            x, y, w, h = box
            rect = patches.Rectangle((x, y), w, h, linewidth=2, 
                                     edgecolor='yellow', facecolor='none', 
                                     linestyle='--', label='Pred Box')
            plt.gca().add_patch(rect)
    
    # ç§»é™¤é‡å¤çš„å›¾ä¾‹
    handles, labels = plt.gca().get_legend_handles_labels()
    by_label = dict(zip(labels, handles))
    plt.legend(by_label.values(), by_label.keys(), loc='upper right')
    
    plt.title(title, fontsize=14, fontweight='bold')
    plt.xlabel('Feature Width', fontsize=12)
    plt.ylabel('Feature Height', fontsize=12)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ… Saved: {save_path}")


def project_3d_boxes_to_bev(boxes_3d, pc_range=[-54, -54, -5, 54, 54, 3], 
                           feature_size=(180, 180)):
    """
    å°†3Dæ¡†æŠ•å½±åˆ°BEVç‰¹å¾å›¾åæ ‡
    
    Args:
        boxes_3d: [N, 7] (x, y, z, w, l, h, yaw) LiDARåæ ‡ç³»
        pc_range: ç‚¹äº‘èŒƒå›´
        feature_size: BEVç‰¹å¾å›¾å°ºå¯¸
        
    Returns:
        boxes_2d: List of [x, y, w, h] BEVç‰¹å¾å›¾åæ ‡
    """
    if boxes_3d is None or len(boxes_3d) == 0:
        return []
    
    boxes_2d = []
    pc_min = np.array([pc_range[0], pc_range[1]])
    pc_max = np.array([pc_range[3], pc_range[4]])
    pc_size = pc_max - pc_min
    
    for box in boxes_3d:
        x, y, w, l = box[0], box[1], box[3], box[4]  # æ³¨æ„ï¼šwå’Œlçš„é¡ºåº
        
        # å½’ä¸€åŒ–åˆ°[0, 1]
        x_norm = (x - pc_min[0]) / pc_size[0]
        y_norm = (y - pc_min[1]) / pc_size[1]
        w_norm = w / pc_size[0]
        l_norm = l / pc_size[1]
        
        # è½¬æ¢åˆ°ç‰¹å¾å›¾åæ ‡
        feat_x = x_norm * feature_size[1]
        feat_y = y_norm * feature_size[0]
        feat_w = w_norm * feature_size[1]
        feat_l = l_norm * feature_size[0]
        
        # BEVæ¡†ï¼š[x-l/2, y-w/2, l, w] (æ³¨æ„åæ ‡ç³»è½¬æ¢)
        boxes_2d.append([
            feat_y - feat_w/2,  # yåæ ‡
            feat_x - feat_l/2,  # xåæ ‡
            feat_w,             # å®½åº¦
            feat_l              # é•¿åº¦
        ])
    
    return boxes_2d


def visualize_perspective_weights(weight_maps_pers, img_metas, save_dir='viz_output/'):
    """
    å¯è§†åŒ–é€è§†è§†è§’çš„æƒé‡å›¾ï¼ˆ6ä¸ªç›¸æœºè§†è§’ï¼‰
    
    Args:
        weight_maps_pers: [bs, 6, 40, 100] æˆ– [6, 40, 100] é€è§†æƒé‡å›¾
        img_metas: å›¾åƒå…ƒæ•°æ®
        save_dir: ä¿å­˜ç›®å½•
    """
    os.makedirs(save_dir, exist_ok=True)
    
    if weight_maps_pers.dim() == 4:
        weight_maps_pers = weight_maps_pers[0]  # å–ç¬¬ä¸€ä¸ªbatch
    
    camera_names = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT',
                   'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_BACK_RIGHT']
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('AQR Perspective Weight Maps (All Camera Views)', 
                fontsize=16, fontweight='bold')
    
    for view_idx in range(6):
        ax = axes[view_idx // 3, view_idx % 3]
        weight_map = weight_maps_pers[view_idx].cpu().numpy()
        
        # åˆ›å»ºé¢œè‰²æ˜ å°„
        colors = ['#000033', '#0000FF', '#00FF00', '#FFFF00', '#FF0000']
        cmap = LinearSegmentedColormap.from_list('aqr_weights', colors, N=100)
        
        im = ax.imshow(weight_map, cmap=cmap, interpolation='bilinear', aspect='auto')
        ax.set_title(f'{camera_names[view_idx]}\nWeight Range: [{weight_map.min():.3f}, {weight_map.max():.3f}]')
        ax.set_xlabel('Width')
        ax.set_ylabel('Height')
        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
    
    plt.tight_layout()
    save_path = os.path.join(save_dir, 'perspective_weights_all_views.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ… Saved: {save_path}")


def analyze_weight_target_correlation(weight_map, gt_boxes_2d, feature_size=(180, 180)):
    """
    åˆ†ææƒé‡ä¸ç›®æ ‡ä½ç½®çš„ç›¸å…³æ€§
    
    Args:
        weight_map: [H, W] æƒé‡å›¾
        gt_boxes_2d: List of [x, y, w, h] GTæ¡†åæ ‡
        
    Returns:
        correlation_stats: Dict åŒ…å«ç»Ÿè®¡ä¿¡æ¯
    """
    stats = {
        'total_weight': weight_map.sum(),
        'mean_weight': weight_map.mean(),
        'max_weight': weight_map.max(),
        'weight_in_boxes': 0.0,
        'weight_outside_boxes': 0.0,
        'boxes_count': len(gt_boxes_2d),
        'coverage_ratio': 0.0
    }
    
    if len(gt_boxes_2d) == 0:
        stats['weight_outside_boxes'] = stats['total_weight']
        return stats
    
    # åˆ›å»ºç›®æ ‡åŒºåŸŸmask
    mask = np.zeros(feature_size, dtype=bool)
    for box in gt_boxes_2d:
        x, y, w, h = [int(v) for v in box]
        x1, y1 = max(0, x), max(0, y)
        x2, y2 = min(feature_size[1], x + w), min(feature_size[0], y + h)
        mask[y1:y2, x1:x2] = True
    
    # è®¡ç®—æ¡†å†…å’Œæ¡†å¤–æƒé‡
    stats['weight_in_boxes'] = weight_map[mask].sum()
    stats['weight_outside_boxes'] = weight_map[~mask].sum()
    
    if stats['total_weight'] > 0:
        stats['coverage_ratio'] = stats['weight_in_boxes'] / stats['total_weight']
    
    return stats


def visualize_weight_statistics(stats_list, save_path='weight_stats.png'):
    """
    å¯è§†åŒ–æƒé‡ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        stats_list: List of dicts æ¯ä¸ªæ ·æœ¬çš„ç»Ÿè®¡ä¿¡æ¯
        save_path: ä¿å­˜è·¯å¾„
    """
    if len(stats_list) == 0:
        return
    
    coverage_ratios = [s['coverage_ratio'] for s in stats_list]
    boxes_counts = [s['boxes_count'] for s in stats_list]
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    # 1. æƒé‡è¦†ç›–ç‡åˆ†å¸ƒ
    ax1.hist(coverage_ratios, bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    ax1.axvline(np.mean(coverage_ratios), color='red', linestyle='--', 
               linewidth=2, label=f'Mean: {np.mean(coverage_ratios):.2%}')
    ax1.set_xlabel('Weight Coverage Ratio (In Boxes / Total)', fontsize=12)
    ax1.set_ylabel('Frequency', fontsize=12)
    ax1.set_title('Distribution of Weight Coverage on GT Objects', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ç›®æ ‡æ•°é‡ vs è¦†ç›–ç‡æ•£ç‚¹å›¾
    ax2.scatter(boxes_counts, coverage_ratios, alpha=0.6, s=50, c='green', edgecolors='black')
    ax2.set_xlabel('Number of GT Objects', fontsize=12)
    ax2.set_ylabel('Weight Coverage Ratio', fontsize=12)
    ax2.set_title('Objects Count vs Weight Coverage', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"âœ… Saved: {save_path}")


def main():
    parser = argparse.ArgumentParser(description='AQRæƒé‡å¯è§†åŒ–å·¥å…·')
    parser.add_argument('--config', required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--checkpoint', help='æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--save-dir', default='aqr_viz_output/', help='å¯è§†åŒ–ç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--num-samples', type=int, default=10, help='å¯è§†åŒ–æ ·æœ¬æ•°é‡')
    parser.add_argument('--data-split', default='val', choices=['train', 'val', 'test'], 
                       help='æ•°æ®é›†åˆ†å‰²')
    args = parser.parse_args()
    
    os.makedirs(args.save_dir, exist_ok=True)
    
    # åŠ è½½é…ç½®å’Œæ¨¡å‹
    cfg = Config.fromfile(args.config)
    
    # ç¡®ä¿å¯ç”¨AQRå’Œdebugæ¨¡å¼
    if hasattr(cfg.model, 'pts_bbox_head'):
        cfg.model.pts_bbox_head.enable_aqr = True
        cfg.model.pts_bbox_head.debug_mode = True
    
    # æ„å»ºæ•°æ®é›†
    if args.data_split == 'val':
        dataset = build_dataset(cfg.data.val)
    elif args.data_split == 'train':
        dataset = build_dataset(cfg.data.train.dataset)
    else:
        dataset = build_dataset(cfg.data.test)
    
    print(f"ğŸ“Š Dataset: {len(dataset)} samples")
    print(f"ğŸ¯ Will visualize {min(args.num_samples, len(dataset))} samples")
    
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆå¦‚æœæä¾›äº†checkpointï¼‰
    if args.checkpoint:
        model = init_model(cfg, args.checkpoint, device='cuda:0')
        print(f"âœ… Model loaded from {args.checkpoint}")
    
    # å¯è§†åŒ–æ ·æœ¬
    stats_list = []
    
    for idx in range(min(args.num_samples, len(dataset))):
        print(f"\nğŸ” Processing sample {idx+1}/{min(args.num_samples, len(dataset))}...")
        
        data = dataset[idx]
        img_metas = data['img_metas'].data
        gt_bboxes_3d = data.get('gt_bboxes_3d', None)
        
        # è¿™é‡Œéœ€è¦ä»æ¨¡å‹ä¸­æå–æƒé‡å›¾
        # å®é™…ä½¿ç”¨æ—¶ï¼Œéœ€è¦åœ¨cmt_head.pyä¸­ä¿å­˜æƒé‡å›¾åˆ°æ–‡ä»¶æˆ–è¿”å›
        print(f"âš ï¸  Note: éœ€è¦åœ¨è®­ç»ƒæ—¶å¯ç”¨debug_modeå¹¶ä¿å­˜æƒé‡å›¾")
        print(f"   å¯ä»¥åœ¨cmt_head.pyçš„_apply_aqr_modulationä¸­æ·»åŠ :")
        print(f"   torch.save({{'weight_map_bev': weight_map_bev, 'weight_map_pers': weight_map_pers}}, 'debug_weights.pth')")
    
    print(f"\nâœ… Visualization completed! Results saved to {args.save_dir}")


if __name__ == '__main__':
    main()



