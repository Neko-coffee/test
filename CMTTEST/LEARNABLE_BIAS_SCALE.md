# å¯å­¦ä¹ çš„Bias Scale ğŸ“

**åˆ›å»ºæ—¶é—´**: 2025-01-XX  
**æ”¹è¿›ç±»å‹**: è‡ªé€‚åº”ä¼˜åŒ–  
**å½±å“**: è¿›ä¸€æ­¥æå‡æ€§èƒ½

---

## ğŸ¯ **æ ¸å¿ƒæ€æƒ³**

### **ä»å›ºå®šåˆ°å¯å­¦ä¹ **

```python
# æ—§æ–¹æ¡ˆï¼šå›ºå®šscale
self.bias_scale = 2.5  # äººå·¥è®¾å®š

# æ–°æ–¹æ¡ˆï¼šå¯å­¦ä¹ scale
self.bias_scale = nn.Parameter(torch.tensor(2.5))  # è®©æ¨¡å‹è‡ªå·±å­¦ä¹ æœ€ä¼˜å€¼
```

**å…³é”®ä¼˜åŠ¿**ï¼š
- âœ… æ¨¡å‹è‡ªé€‚åº”æ‰¾åˆ°æœ€ä¼˜ç¼©æ”¾å› å­
- âœ… ä¸åŒæ•°æ®é›†å¯èƒ½éœ€è¦ä¸åŒçš„scale
- âœ… è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´

---

## ğŸ’¡ **ä¸ºä»€ä¹ˆéœ€è¦å¯å­¦ä¹ Scaleï¼Ÿ**

### **é—®é¢˜1ï¼šæœ€ä¼˜scaleå› æ•°æ®è€Œå¼‚**

ä¸åŒæ•°æ®é›†ã€ä¸åŒåœºæ™¯å¯èƒ½éœ€è¦ä¸åŒçš„biaså¼ºåº¦ï¼š

| åœºæ™¯ | æœ€ä¼˜scale | åŸå›  |
|-----|----------|------|
| **åŸå¸‚é“è·¯** | 2.0-2.5 | ç‰¹å¾è´¨é‡é«˜ï¼Œæ¸©å’Œè°ƒåˆ¶ |
| **é«˜é€Ÿå…¬è·¯** | 3.0-3.5 | è¿œè·ç¦»ç›®æ ‡å¤šï¼Œéœ€è¦å¼ºè°ƒåˆ¶ |
| **å¤œé—´åœºæ™¯** | 3.5-4.0 | Cameraè´¨é‡å·®ï¼Œéœ€è¦å¼ºæŠ‘åˆ¶ |
| **é›¨é›ªå¤©æ°”** | 4.0-5.0 | ä¼ æ„Ÿå™¨å™ªå£°å¤§ï¼Œéœ€è¦å¼ºé€‰æ‹© |

**äººå·¥è°ƒå‚çš„å›°å¢ƒ**ï¼š
- âŒ éœ€è¦å¤§é‡å®éªŒ
- âŒ å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜
- âŒ æ— æ³•é€‚åº”ä¸åŒåœºæ™¯

### **é—®é¢˜2ï¼šè®­ç»ƒåŠ¨æ€å˜åŒ–**

è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ€ä¼˜scaleå¯èƒ½å˜åŒ–ï¼š

```python
# è®­ç»ƒåˆæœŸï¼ˆepoch 1-5ï¼‰
# ç‰¹å¾ä¸ç¨³å®šï¼Œéœ€è¦å°scaleé¿å…è¿‡åº¦è°ƒåˆ¶
optimal_scale â‰ˆ 1.5

# è®­ç»ƒä¸­æœŸï¼ˆepoch 6-15ï¼‰
# ç‰¹å¾ç¨³å®šï¼Œå¯ä»¥å¢å¤§scale
optimal_scale â‰ˆ 2.5

# è®­ç»ƒåæœŸï¼ˆepoch 16-24ï¼‰
# ç²¾ç»†è°ƒä¼˜ï¼Œå¯èƒ½éœ€è¦æ›´å¤§scale
optimal_scale â‰ˆ 3.0
```

**å¯å­¦ä¹ scaleçš„ä¼˜åŠ¿**ï¼š
- âœ… è‡ªåŠ¨é€‚åº”è®­ç»ƒé˜¶æ®µ
- âœ… æ— éœ€äººå·¥è°ƒæ•´schedule
- âœ… ç«¯åˆ°ç«¯ä¼˜åŒ–

---

## ğŸ”§ **æŠ€æœ¯å®ç°**

### **å®ç°æ–¹å¼**

```python
class AttentionBiasGenerator(nn.Module):
    def __init__(self, bias_scale=2.5, learnable_scale=False):
        super().__init__()
        
        if learnable_scale:
            # å¯å­¦ä¹ ï¼šä½œä¸ºæ¨¡å‹å‚æ•°
            self.bias_scale = nn.Parameter(torch.tensor(bias_scale))
        else:
            # å›ºå®šï¼šä½œä¸ºbufferï¼ˆä¸å‚ä¸æ¢¯åº¦æ›´æ–°ï¼‰
            self.register_buffer('bias_scale', torch.tensor(bias_scale))
    
    def forward(self, weights, ...):
        # ä½¿ç”¨self.bias_scaleï¼Œæ— è®ºæ˜¯Parameterè¿˜æ˜¯Bufferéƒ½å¯ä»¥
        bias = weights * self.bias_scale
        return bias
```

### **å…³é”®è®¾è®¡**

#### **1. ä½¿ç”¨nn.Parameter**
```python
self.bias_scale = nn.Parameter(torch.tensor(2.5))
```
- âœ… è‡ªåŠ¨æ³¨å†Œä¸ºæ¨¡å‹å‚æ•°
- âœ… è‡ªåŠ¨å‚ä¸æ¢¯åº¦æ›´æ–°
- âœ… è‡ªåŠ¨ä¿å­˜/åŠ è½½

#### **2. ä½¿ç”¨register_bufferï¼ˆå›ºå®šæ¨¡å¼ï¼‰**
```python
self.register_buffer('bias_scale', torch.tensor(2.5))
```
- âœ… ä¸å‚ä¸æ¢¯åº¦æ›´æ–°
- âœ… ä¼šè¢«ä¿å­˜/åŠ è½½
- âœ… ä¼šè·Ÿéšæ¨¡å‹ç§»åŠ¨åˆ°GPU

---

## ğŸ“Š **é¢„æœŸæ•ˆæœ**

### **Scaleçš„å­¦ä¹ æ›²çº¿**

```python
# é¢„æœŸçš„è®­ç»ƒè¿‡ç¨‹
Epoch 1:  scale = 2.50 (åˆå§‹å€¼)
Epoch 3:  scale = 2.15 (ä¸‹é™ï¼Œé¿å…è¿‡åº¦è°ƒåˆ¶)
Epoch 6:  scale = 2.35 (å›å‡ï¼Œç‰¹å¾ç¨³å®š)
Epoch 10: scale = 2.68 (ç»§ç»­ä¸Šå‡)
Epoch 15: scale = 2.85 (æ¥è¿‘æœ€ä¼˜)
Epoch 20: scale = 2.92 (æ”¶æ•›)
Epoch 24: scale = 2.95 (æœ€ç»ˆå€¼)
```

### **æ€§èƒ½æå‡é¢„æœŸ**

| æ–¹æ¡ˆ | mAP | NDS | è¯´æ˜ |
|-----|-----|-----|------|
| å›ºå®šscale=2.5 | 0.6450 | 0.7120 | äººå·¥è®¾å®š |
| å¯å­¦ä¹ scale | **0.6480** | **0.7140** | è‡ªé€‚åº”ä¼˜åŒ– |
| æå‡ | **+0.3%** | **+0.2%** | å°å¹…ä½†ç¨³å®š |

---

## ğŸ“ **ç†è®ºåˆ†æ**

### **æ¢¯åº¦ä¼ æ’­**

```python
# å‰å‘ä¼ æ’­
bias = weights * scale  # scaleæ˜¯å¯å­¦ä¹ çš„
attention = softmax(scores + bias)
loss = detection_loss(attention, ...)

# åå‘ä¼ æ’­
âˆ‚loss/âˆ‚scale = âˆ‚loss/âˆ‚bias * âˆ‚bias/âˆ‚scale
             = âˆ‚loss/âˆ‚bias * weights
```

**å…³é”®æ´å¯Ÿ**ï¼š
- scaleçš„æ¢¯åº¦ = biasçš„æ¢¯åº¦ Ã— weights
- å¦‚æœbiaså¤ªå°ï¼ˆæ•ˆæœä¸å¤Ÿï¼‰ï¼Œæ¢¯åº¦ä¼šæ¨åŠ¨scaleå¢å¤§
- å¦‚æœbiaså¤ªå¤§ï¼ˆè¿‡åº¦é¥±å’Œï¼‰ï¼Œæ¢¯åº¦ä¼šæ¨åŠ¨scaleå‡å°

### **è‡ªé€‚åº”æœºåˆ¶**

```python
# åœºæ™¯1ï¼šAQRæƒé‡è´¨é‡é«˜
# weightsåˆ†å¸ƒï¼š[-0.8, 0.8]ï¼ˆé«˜ç½®ä¿¡åº¦ï¼‰
# æ¢¯åº¦å€¾å‘ï¼šå¢å¤§scaleï¼Œå……åˆ†åˆ©ç”¨é«˜è´¨é‡æƒé‡

# åœºæ™¯2ï¼šAQRæƒé‡è´¨é‡ä½
# weightsåˆ†å¸ƒï¼š[-0.3, 0.3]ï¼ˆä½ç½®ä¿¡åº¦ï¼‰
# æ¢¯åº¦å€¾å‘ï¼šå‡å°scaleï¼Œé¿å…è¿‡åº¦ä¾èµ–ä¸å¯é æƒé‡
```

---

## âš™ï¸ **é…ç½®é€‰é¡¹**

### **æ¨èé…ç½®ï¼ˆå¯å­¦ä¹ ï¼‰**

```python
attention_bias_config=dict(
    bias_scale=2.5,           # åˆå§‹å€¼
    learnable_scale=True,     # ğŸ”¥ å¯ç”¨å¯å­¦ä¹ 
)
```

### **ä¿å®ˆé…ç½®ï¼ˆå›ºå®šï¼‰**

```python
attention_bias_config=dict(
    bias_scale=2.5,           # å›ºå®šå€¼
    learnable_scale=False,    # ä¸å­¦ä¹ 
)
```

### **æ¿€è¿›é…ç½®ï¼ˆæ›´å¤§åˆå§‹å€¼ï¼‰**

```python
attention_bias_config=dict(
    bias_scale=3.5,           # æ›´å¤§çš„åˆå§‹å€¼
    learnable_scale=True,     # è®©æ¨¡å‹å†³å®šæ˜¯å¦éœ€è¦è¿™ä¹ˆå¤§
)
```

---

## ğŸ” **ç›‘æ§å’Œè°ƒè¯•**

### **1. æ‰“å°scaleå€¼**

```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­
if iteration % 100 == 0:
    current_scale = model.pts_bbox_head.attention_bias_generator.bias_scale.item()
    print(f"Iteration {iteration}: bias_scale = {current_scale:.4f}")
```

### **2. å¯è§†åŒ–scaleå˜åŒ–**

```python
import matplotlib.pyplot as plt

# è®°å½•scaleå†å²
scale_history = []

# è®­ç»ƒåç»˜åˆ¶
plt.plot(scale_history)
plt.xlabel('Iteration')
plt.ylabel('Bias Scale')
plt.title('Learnable Bias Scale Evolution')
plt.savefig('bias_scale_curve.png')
```

### **3. æ£€æŸ¥æ¢¯åº¦**

```python
# æ£€æŸ¥scaleæ˜¯å¦åœ¨å­¦ä¹ 
scale_param = model.pts_bbox_head.attention_bias_generator.bias_scale
if scale_param.grad is not None:
    print(f"Scale gradient: {scale_param.grad.item():.6f}")
else:
    print("âš ï¸ Scaleæ²¡æœ‰æ¢¯åº¦ï¼")
```

---

## âš ï¸ **æ³¨æ„äº‹é¡¹**

### **1. åˆå§‹åŒ–å¾ˆé‡è¦**

```python
# âœ… æ¨èï¼šä»åˆç†çš„åˆå§‹å€¼å¼€å§‹
bias_scale = 2.5  # åŸºäºç†è®ºåˆ†æ

# âŒ ä¸æ¨èï¼šä»æç«¯å€¼å¼€å§‹
bias_scale = 0.1  # å¤ªå°ï¼Œå¯èƒ½å­¦ä¸åˆ°æœ‰æ•ˆbias
bias_scale = 10.0 # å¤ªå¤§ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®š
```

### **2. æ·»åŠ çº¦æŸï¼ˆå¯é€‰ï¼‰**

```python
# åœ¨forwardä¸­æ·»åŠ è½¯çº¦æŸ
def forward(self, weights, ...):
    # è£å‰ªscaleåˆ°åˆç†èŒƒå›´
    scale = torch.clamp(self.bias_scale, min=0.5, max=5.0)
    bias = weights * scale
    return bias
```

### **3. å­¦ä¹ ç‡è°ƒæ•´**

```python
# å¯ä»¥ç»™scaleè®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡
optimizer = dict(
    type='AdamW',
    lr=0.00014,
    paramwise_cfg=dict(
        custom_keys={
            'attention_bias_generator.bias_scale': dict(lr_mult=0.1),  # æ›´å°çš„å­¦ä¹ ç‡
        }
    )
)
```

---

## ğŸ”® **è¿›é˜¶æ‰©å±•**

### **1. æ¨¡æ€ç‰¹å®šçš„scale**

```python
class AttentionBiasGenerator(nn.Module):
    def __init__(self, ...):
        # ä¸ºLiDARå’ŒCameraåˆ†åˆ«å­¦ä¹ scale
        if learnable_scale:
            self.lidar_scale = nn.Parameter(torch.tensor(2.5))
            self.camera_scale = nn.Parameter(torch.tensor(2.5))
        
    def forward(self, lidar_weights, camera_weights, ...):
        lidar_bias = lidar_weights * self.lidar_scale
        camera_bias = camera_weights * self.camera_scale
        # ...
```

### **2. å±‚çº§scale**

```python
# ä¸åŒTransformerå±‚ä½¿ç”¨ä¸åŒscale
class CmtTransformer(nn.Module):
    def __init__(self, num_layers=6):
        self.layer_scales = nn.ParameterList([
            nn.Parameter(torch.tensor(2.5)) for _ in range(num_layers)
        ])
    
    def forward(self, ..., layer_idx):
        scale = self.layer_scales[layer_idx]
        bias = weights * scale
        # ...
```

### **3. æ¸©åº¦é€€ç«**

```python
# è®­ç»ƒåˆæœŸé™åˆ¶scaleï¼ŒåæœŸæ”¾å¼€
def get_scale_constraint(epoch):
    if epoch < 5:
        return (1.0, 2.5)  # åˆæœŸä¿å®ˆ
    elif epoch < 15:
        return (0.5, 4.0)  # ä¸­æœŸæ”¾å®½
    else:
        return (0.1, 5.0)  # åæœŸå®Œå…¨æ”¾å¼€

# åœ¨forwardä¸­åº”ç”¨
min_scale, max_scale = get_scale_constraint(current_epoch)
scale = torch.clamp(self.bias_scale, min=min_scale, max=max_scale)
```

---

## ğŸ“‹ **å®éªŒå»ºè®®**

### **å¯¹æ¯”å®éªŒ**

| å®éªŒ | learnable_scale | åˆå§‹å€¼ | ç›®çš„ |
|-----|----------------|-------|------|
| Exp 1 | False | 2.5 | åŸºçº¿ï¼ˆå›ºå®šscaleï¼‰ |
| Exp 2 | True | 2.5 | å¯å­¦ä¹ scale |
| Exp 3 | True | 1.5 | æ›´å°åˆå§‹å€¼ |
| Exp 4 | True | 3.5 | æ›´å¤§åˆå§‹å€¼ |

### **åˆ†ææŒ‡æ ‡**

1. **æœ€ç»ˆscaleå€¼**
   - æ”¶æ•›åˆ°å¤šå°‘ï¼Ÿ
   - æ˜¯å¦ç¨³å®šï¼Ÿ

2. **è®­ç»ƒæ›²çº¿**
   - æ˜¯å¦æ›´å¹³æ»‘ï¼Ÿ
   - æ”¶æ•›æ˜¯å¦æ›´å¿«ï¼Ÿ

3. **æ€§èƒ½æŒ‡æ ‡**
   - mAPæå‡å¤šå°‘ï¼Ÿ
   - å°ç›®æ ‡æ˜¯å¦æ”¹å–„ï¼Ÿ

---

## ğŸ¯ **æ€»ç»“**

### **æ ¸å¿ƒä¼˜åŠ¿**
- âœ… **è‡ªé€‚åº”**ï¼šæ¨¡å‹è‡ªå·±æ‰¾æœ€ä¼˜scale
- âœ… **ç«¯åˆ°ç«¯**ï¼šä¸æ£€æµ‹æŸå¤±è”åˆä¼˜åŒ–
- âœ… **é²æ£’**ï¼šé€‚åº”ä¸åŒæ•°æ®å’Œåœºæ™¯
- âœ… **ç®€å•**ï¼šåªéœ€ä¸€è¡Œä»£ç 

### **å®ç°æˆæœ¬**
- ä»£ç ä¿®æ”¹ï¼š10è¡Œ
- é¢å¤–å‚æ•°ï¼š1ä¸ªï¼ˆ4 bytesï¼‰
- è®¡ç®—å¼€é”€ï¼šå¯å¿½ç•¥

### **é¢„æœŸæ”¶ç›Š**
- mAPæå‡ï¼š+0.2~0.5%
- è®­ç»ƒç¨³å®šæ€§ï¼šâ¬†ï¸
- æ³›åŒ–èƒ½åŠ›ï¼šâ¬†ï¸

---

**ä¸»äººï¼Œå¯å­¦ä¹ çš„scaleæ˜¯ä¸€ä¸ªéå¸¸elegantçš„æ”¹è¿›ï¼å®ƒè®©æ¨¡å‹èƒ½å¤Ÿè‡ªé€‚åº”åœ°æ‰¾åˆ°æœ€ä¼˜çš„biaså¼ºåº¦ï¼Œè€Œä¸”å®ç°æˆæœ¬æä½ï¼** ğŸ‰âœ¨

**å»ºè®®**ï¼š
1. å…ˆç”¨`learnable_scale=True, bias_scale=2.5`è®­ç»ƒ
2. ç›‘æ§scaleçš„å˜åŒ–æ›²çº¿
3. å¦‚æœscaleæ”¶æ•›åˆ°>3.5ï¼Œè¯´æ˜éœ€è¦æ›´å¼ºçš„è°ƒåˆ¶
4. å¦‚æœscaleæ”¶æ•›åˆ°<1.5ï¼Œè¯´æ˜AQRæƒé‡å¯èƒ½è´¨é‡ä¸é«˜

