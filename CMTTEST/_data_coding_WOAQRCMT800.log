/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : tools/train.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 8
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:29500
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_vm505sxr/none_chjo6uyu
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]
  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_vm505sxr/none_chjo6uyu/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_vm505sxr/none_chjo6uyu/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_vm505sxr/none_chjo6uyu/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_vm505sxr/none_chjo6uyu/attempt_0/3/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_vm505sxr/none_chjo6uyu/attempt_0/4/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_vm505sxr/none_chjo6uyu/attempt_0/5/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_vm505sxr/none_chjo6uyu/attempt_0/6/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_vm505sxr/none_chjo6uyu/attempt_0/7/error.json
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
fatal: not a git repository (or any parent up
    custom_fp16=dict(
        pts_voxel_encoder=False, pts_middle_encoder=False,
        pts_bbox_head=False))
lr_config = dict(
    policy='cyclic',
    target_ratio=(6, 0.001),
    cyclic_times=1,
    step_ratio_up=0.3)
momentum_config = dict(
    policy='cyclic',
    target_ratio=(0.8947368421052632, 1),
    cyclic_times=1,
    step_ratio_up=0.1)
total_epochs = 1
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/cmt_aqr_voxel0100_r50_800x320_cbgs'
load_from = 'ckpts/epoch_20.pth'
resume_from = None
workflow = [('train', 1)]
gpu_ids = range(0, 8)
find_unused_parameters = True

2025-10-13 12:09:10,508 - mmdet - INFO - Set random seed to 0, deterministic: False
2025-10-13 12:09:16,406 - mmdet - INFO - initialize SECOND with init_cfg {'type': 'Kaiming', 'layer': 'Conv2d'}
2025-10-13 12:09:16,436 - mmdet - INFO - initialize SECONDFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
2025-10-13 12:09:16,475 - mmdet - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2025-10-13 12:09:16,634 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,635 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,636 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,637 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,638 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,638 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,639 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,640 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,642 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,643 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,644 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,646 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,647 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,651 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,655 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,659 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-13 12:09:16,678 - mmdet - INFO - initialize CPFPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-10-13 12:09:16,694 - mmdet - INFO - Model:
CmtDetector(
  (pts_voxel_encoder): HardSimpleVFE()
  (pts_middle_encoder): SparseEncoder(
    (conv_input): SparseSequential(
      (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (encoder_layers): SparseSequential(
      (encoder_layer1): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer2): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer3): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer4): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)

    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (grid_mask): GridMask()
  (pts_voxel_layer): SPConvVoxelization(voxel_size=[0.1 0.1 0.2], point_cloud_range=[-54. -54.  -5.  54.  54.   3.], max_num_points=10, max_voxels=(120000, 160000), num_point_features=5)
)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
2025-10-13 12:09:30,607 - mmdet - INFO - load checkpoint from local path: ckpts/epoch_20.pth
2025-10-13 12:09:30,962 - mmdet - INFO - Start running, host: root@pglkarasdosntxqy-make-6886fc6485-kv6qw, work_dir: /data/coding/work_dirs/cmt_aqr_voxel0100_r50_800x320_cbgs
2025-10-13 12:09:30,963 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(ABOVE_NORMAL) CustomFp16OptimizerHook            
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) CustomFp16OptimizerHook            
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-10-13 12:09:30,963 - mmdet - INFO - workflow: [('train', 1)], max: 1 epochs
2025-10-13 12:09:30,983 - mmdet - INFO - Checkpoints will be saved to /data/coding/work_dirs/cmt_aqr_voxel0100_r50_800x320_cbgs by HardDiskBackend.
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1158] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
2025-10-13 12:10:28,291 - mmdet - INFO - Epoch [1][50/4004]	lr: 1.429e-06, eta: 1:15:26, time: 1.145, data_time: 0.168, memory: 21115, loss_cls: 0.0890, loss_bbox: 0.5927, d0.loss_cls: 0.1092, d0.loss_bbox: 0.7469, d1.loss_cls: 0.1012, d1.loss_bbox: 0.6673, d2.loss_cls: 0.0927, d2.loss_bbox: 0.6315, d3.loss_cls: 0.0890, d3.loss_bbox: 0.6072, d4.loss_cls: 0.0890, d4.loss_bbox: 0.5957, dn_loss_cls: 0.3701, dn_loss_bbox: 0.5121, d0.dn_loss_cls: 0.4133, d0.dn_loss_bbox: 0.6468, d1.dn_loss_cls: 0.3947, d1.dn_loss_bbox: 0.5843, d2.dn_loss_cls: 0.3844, d2.dn_loss_bbox: 0.5520, d3.dn_loss_cls: 0.3740, d3.dn_loss_bbox: 0.5237, d4.dn_loss_cls: 0.3707, d4.dn_loss_bbox: 0.5145, loss: 10.0520, grad_norm: nan
2025-10-13 12:11:01,801 - mmdet - INFO - Epoch [1][100/4004]	lr: 1.517e-06, eta: 0:59:03, time: 0.670, data_time: 0.043, memory: 21115, loss_cls: 0.0877, loss_bbox: 0.5849, d0.loss_cls: 0.1079, d0.loss_bbox: 0.7409, d1.loss_cls: 0.0995, d1.loss_bbox: 0.6611, d2.loss_cls: 0.0912, d2.loss_bbox: 0.6241, d3.loss_cls: 0.0877, d3.loss_bbox: 0.5983, d4.loss_cls: 0.0876, d4.loss_bbox: 0.5890, dn_loss_cls: 0.3683, dn_loss_bbox: 0.5175, d0.dn_loss_cls: 0.4106, d0.dn_loss_bbox: 0.6520, d1.dn_loss_cls: 0.3924, d1.dn_loss_bbox: 0.5899, d2.dn_loss_cls: 0.3823, d2.dn_loss_bbox: 0.5574, d3.dn_loss_cls: 0.3725, d3.dn_loss_bbox: 0.5294, d4.dn_loss_cls: 0.3690, d4.dn_loss_bbox: 0.5201, loss: 10.0214, grad_norm: nan
2025-10-13 12:11:35,016 - mmdet - INFO - Epoch [1][150/4004]	lr: 1.662e-06, eta: 0:53:05, time: 0.664, data_time: 0.043, memory: 21505, loss_cls: 0.0880, loss_bbox: 0.5915, d0.loss_cls: 0.1089, d0.loss_bbox: 0.7483, d1.loss_cls: 0.1004, d1.loss_bbox: 0.6681, d2.loss_cls: 0.0922, d2.loss_bbox: 0.6294, d3.loss_cls: 0.0885, d3.loss_bbox: 0.6037, d4.loss_cls: 0.0883, d4.loss_bbox: 0.5927, dn_loss_cls: 0.3684, dn_loss_bbox: 0.5195, d0.dn_loss_cls: 0.4119, d0.dn_loss_bbox: 0.6596, d1.dn_loss_cls: 0.3929, d1.dn_loss_bbox: 0.5941, d2.dn_loss_cls: 0.3821, d2.dn_loss_bbox: 0.5605, d3.dn_loss_cls: 0.3722, d3.dn_loss_bbox: 0.5311, d4.dn_loss_cls: 0.3689, d4.dn_loss_bbox: 0.5220, loss: 10.0832, grad_norm: 49.7096
2025-10-13 12:12:07,869 - mmdet - INFO - Epoch [1][200/4004]	lr: 1.864e-06, eta: 0:49:42, time: 0.657, data_time: 0.046, memory: 21505, loss_cls: 0.0876, loss_bbox: 0.6039, d0.loss_cls: 0.1071, d0.loss_bbox: 0.7679, d1.loss_cls: 0.0989, d1.loss_bbox: 0.6828, d2.loss_cls: 0.0914, d2.loss_bbox: 0.6426, d3.loss_cls: 0.0878, d3.loss_bbox: 0.6181, d4.loss_cls: 0.0877, d4.loss_bbox: 0.6083, dn_loss_cls: 0.3707, dn_loss_bbox: 0.5303, d0.dn_loss_cls: 0.4128, d0.dn_loss_bbox: 0.6720, d1.dn_loss_cls: 0.3945, d1.dn_loss_bbox: 0.6063, d2.dn_loss_cls: 0.3844, d2.dn_loss_bbox: 0.5721, d3.dn_loss_cls: 0.3747, d3.dn_loss_bbox: 0.5426, d4.dn_loss_cls: 0.3713, d4.dn_loss_bbox: 0.5331, loss: 10.2488, grad_norm: 47.3661
2025-10-13 12:12:40,870 - mmdet - INFO - Epoch [1][250/4004]	lr: 2.117e-06, eta: 0:47:30, time: 0.660, data_time: 0.045, memory: 21505, loss_cls: 0.0879, loss_bbox: 0.5954, d0.loss_cls: 0.1086, d0.loss_bbox: 0.7535, d1.loss_cls: 0.0996, d1.loss_bbox: 0.6736, d2.loss_cls: 0.0918, d2.loss_bbox: 0.6338, d3.loss_cls: 0.0881, d3.loss_bbox: 0.6078, d4.loss_cls: 0.0879, d4.loss_bbox: 0.5984, dn_loss_cls: 0.3694, dn_loss_bbox: 0.5219, d0.dn_loss_cls: 0.4131, d0.dn_loss_bbox: 0.6618, d1.dn_loss_cls: 0.3944, d1.dn_loss_bbox: 0.5968, d2.dn_loss_cls: 0.3837, d2.dn_loss_bbox: 0.5623, d3.dn_loss_cls: 0.3734, d3.dn_loss_bbox: 0.5331, d4.dn_loss_cls: 0.3701, d4.dn_loss_bbox: 0.5242, loss: 10.1305, grad_norm: 46.0662
2025-10-13 12:13:13,679 - mmdet - INFO - Epoch [1][300/4004]	lr: 2.417e-06, eta: 0:45:48, time: 0.656, data_time: 0.046, memory: 21587, loss_cls: 0.0865, loss_bbox: 0.5925, d0.loss_cls: 0.1066, d0.loss_bbox: 0.7515, d1.loss_cls: 0.0982, d1.loss_bbox: 0.6675, d2.loss_cls: 0.0902, d2.loss_bbox: 0.6308, d3.loss_cls: 0.0868, d3.loss_bbox: 0.6052, d4.loss_cls: 0.0866, d4.loss_bbox: 0.5948, dn_loss_cls: 0.3709, dn_loss_bbox: 0.5226, d0.dn_loss_cls: 0.4124, d0.dn_loss_bbox: 0.6592, d1.dn_loss_cls: 0.3947, d1.dn_loss_bbox: 0.5943, d2.dn_loss_cls: 0.3848, d2.dn_loss_bbox: 0.5613, d3.dn_loss_cls: 0.3748, d3.dn_loss_bbox: 0.5339, d4.dn_loss_cls: 0.3716, d4.dn_loss_bbox: 0.5250, loss: 10.1027, grad_norm: 50.4127
2025-10-13 12:13:46,754 - mmdet - INFO - Epoch [1][350/4004]	lr: 2.760e-06, eta: 0:44:29, time: 0.662, data_time: 0.046, memory: 21587, loss_cls: 0.0868, loss_bbox: 0.5928, d0.loss_cls: 0.1074, d0.loss_bbox: 0.7542, d1.loss_cls: 0.0986, d1.loss_bbox: 0.6722, d2.loss_cls: 0.0908, d2.loss_bbox: 0.6328, d3.loss_cls: 0.0870, d3.loss_bbox: 0.6065, d4.loss_cls: 0.0869, d4.loss_bbox: 0.5961, dn_loss_cls: 0.3703, dn_loss_bbox: 0.5205, d0.dn_loss_cls: 0.4140, d0.dn_loss_bbox: 0.6605, d1.dn_loss_cls: 0.3949, d1.dn_loss_bbox: 0.5952, d2.dn_loss_cls: 0.3848, d2.dn_loss_bbox: 0.5610, d3.dn_loss_cls: 0.3744, d3.dn_loss_bbox: 0.5322, d4.dn_loss_cls: 0.3709, d4.dn_loss_bbox: 0.5230, loss: 10.1137, grad_norm: 44.4165
2025-10-13 12:14:19,895 - mmdet - INFO - Epoch [1][400/4004]	lr: 3.139e-06, eta: 0:43:22, time: 0.663, data_time: 0.045, memory: 21587, loss_cls: 0.0876, loss_bbox: 0.5991, d0.loss_cls: 0.1076, d0.loss_bbox: 0.7547, d1.loss_cls: 0.0991, d1.loss_bbox: 0.6753, d2.loss_cls: 0.0910, d2.loss_bbox: 0.6369, d3.loss_cls: 0.0877, d3.loss_bbox: 0.6111, d4.loss_cls: 0.0876, d4.loss_bbox: 0.6018, dn_loss_cls: 0.3690, dn_loss_bbox: 0.5265, d0.dn_loss_cls: 0.4119, d0.dn_loss_bbox: 0.6658, d1.dn_loss_cls: 0.3935, d1.dn_loss_bbox: 0.6016, d2.dn_loss_cls: 0.3828, d2.dn_loss_bbox: 0.5677, d3.dn_loss_cls: 0.3728, d3.dn_loss_bbox: 0.5382, d4.dn_loss_cls: 0.3697, d4.dn_loss_bbox: 0.5291, loss: 10.1681, grad_norm: 42.2764
2025-10-13 12:14:52,559 - mmdet - INFO - Epoch [1][450/4004]	lr: 3.549e-06, eta: 0:42:19, time: 0.653, data_time: 0.046, memory: 21587, loss_cls: 0.0883, loss_bbox: 0.5935, d0.loss_cls: 0.1084, d0.loss_bbox: 0.7507, d1.loss_cls: 0.1005, d1.loss_bbox: 0.6687, d2.loss_cls: 0.0920, d2.loss_bbox: 0.6324, d3.loss_cls: 0.0885, d3.loss_bbox: 0.6064, d4.loss_cls: 0.0885, d4.loss_bbox: 0.5951, dn_loss_cls: 0.3693, dn_loss_bbox: 0.5203, d0.dn_loss_cls: 0.4129, d0.dn_loss_bbox: 0.6597, d1.dn_loss_cls: 0.3937, d1.dn_loss_bbox: 0.5948, d2.dn_loss_cls: 0.3834, d2.dn_loss_bbox: 0.5600, d3.dn_loss_cls: 0.3732, d3.dn_loss_bbox: 0.5325, d4.dn_loss_cls: 0.3700, d4.dn_loss_bbox: 0.5229, loss: 10.1056, grad_norm: 47.0155
2025-10-13 12:15:25,299 - mmdet - INFO - Epoch [1][500/4004]	lr: 3.982e-06, eta: 0:41:22, time: 0.655, data_time: 0.047, memory: 21587, loss_cls: 0.0867, loss_bbox: 0.5932, d0.loss_cls: 0.1063, d0.loss_bbox: 0.7498, d1.loss_cls: 0.0979, d1.loss_bbox: 0.6693, d2.loss_cls: 0.0901, d2.loss_bbox: 0.6309, d3.loss_cls: 0.0868, d3.loss_bbox: 0.6071, d4.loss_cls: 0.0867, d4.loss_bbox: 0.5953, dn_loss_cls: 0.3696, dn_loss_bbox: 0.5189, d0.dn_loss_cls: 0.4133, d0.dn_loss_bbox: 0.6559, d1.dn_loss_cls: 0.3943, d1.dn_loss_bbox: 0.5917, d2.dn_loss_cls: 0.3842, d2.dn_loss_bbox: 0.5583, d3.dn_loss_cls: 0.3736, d3.dn_loss_bbox: 0.5308, d4.dn_loss_cls: 0.3703, d4.dn_loss_bbox: 0.5213, loss: 10.0822, grad_norm: 46.6808
2025-10-13 12:15:58,369 - mmdet - INFO - Epoch [1][550/4004]	lr: 4.430e-06, eta: 0:40:32, time: 0.661, data_time: 0.047, memory: 21587, loss_cls: 0.0889, loss_bbox: 0.5985, d0.loss_cls: 0.1097, d0.loss_bbox: 0.7563, d1.loss_cls: 0.1011, d1.loss_bbox: 0.6747, d2.loss_cls: 0.0926, d2.loss_bbox: 0.6376, d3.loss_cls: 0.0889, d3.loss_bbox: 0.6124, d4.loss_cls: 0.0888, d4.loss_bbox: 0.6005, dn_loss_cls: 0.3695, dn_loss_bbox: 0.5248, d0.dn_loss_cls: 0.4139, d0.dn_loss_bbox: 0.6633, d1.dn_loss_cls: 0.3947, d1.dn_loss_bbox: 0.5982, d2.dn_loss_cls: 0.3842, d2.dn_loss_bbox: 0.5648, d3.dn_loss_cls: 0.3737, d3.dn_loss_bbox: 0.5368, d4.dn_loss_cls: 0.3702, d4.dn_loss_bbox: 0.5273, loss: 10.1715, grad_norm: 46.8946
2025-10-13 12:16:30,818 - mmdet - INFO - Epoch [1][600/4004]	lr: 4.886e-06, eta: 0:39:41, time: 0.649, data_time: 0.044, memory: 21587, loss_cls: 0.0862, loss_bbox: 0.5848, d0.loss_cls: 0.1073, d0.loss_bbox: 0.7366, d1.loss_cls: 0.0983, d1.loss_bbox: 0.6609, d2.loss_cls: 0.0900, d2.loss_bbox: 0.6217, d3.loss_cls: 0.0863, d3.loss_bbox: 0.5981, d4.loss_cls: 0.0863, d4.loss_bbox: 0.5866, dn_loss_cls: 0.3698, dn_loss_bbox: 0.5141, d0.dn_loss_cls: 0.4131, d0.dn_loss_bbox: 0.6466, d1.dn_loss_cls: 0.3944, d1.dn_loss_bbox: 0.5846, d2.dn_loss_cls: 0.3838, d2.dn_loss_bbox: 0.5526, d3.dn_loss_cls: 0.3739, d3.dn_loss_bbox: 0.5255, d4.dn_loss_cls: 0.3706, d4.dn_loss_bbox: 0.5166, loss: 9.9889, grad_norm: 45.1499
2025-10-13 12:17:03,300 - mmdet - INFO - Epoch [1][650/4004]	lr: 5.343e-06, eta: 0:38:53, time: 0.650, data_time: 0.041, memory: 21587, loss_cls: 0.0844, loss_bbox: 0.5877, d0.loss_cls: 0.1057, d0.loss_bbox: 0.7383, d1.loss_cls: 0.0966, d1.loss_bbox: 0.6605, d2.loss_cls: 0.0880, d2.loss_bbox: 0.6258, d3.loss_cls: 0.0846, d3.loss_bbox: 0.6010, d4.loss_cls: 0.0845, d4.loss_bbox: 0.5907, dn_loss_cls: 0.3663, dn_loss_bbox: 0.5127, d0.dn_loss_cls: 0.4089, d0.dn_loss_bbox: 0.6461, d1.dn_loss_cls: 0.3912, d1.dn_loss_bbox: 0.5847, d2.dn_loss_cls: 0.3808, d2.dn_loss_bbox: 0.5523, d3.dn_loss_cls: 0.3707, d3.dn_loss_bbox: 0.5245, d4.dn_loss_cls: 0.3672, d4.dn_loss_bbox: 0.5151, loss: 9.9682, grad_norm: 52.9895
2025-10-13 12:17:35,537 - mmdet - INFO - Epoch [1][700/4004]	lr: 5.792e-06, eta: 0:38:06, time: 0.645, data_time: 0.044, memory: 21587, loss_cls: 0.0876, loss_bbox: 0.6022, d0.loss_cls: 0.1074, d0.loss_bbox: 0.7600, d1.loss_cls: 0.0992, d1.loss_bbox: 0.6786, d2.loss_cls: 0.0911, d2.loss_bbox: 0.6408, d3.loss_cls: 0.0878, d3.loss_bbox: 0.6165, d4.loss_cls: 0.0876, d4.loss_bbox: 0.6046, dn_loss_cls: 0.3710, dn_loss_bbox: 0.5315, d0.dn_loss_cls: 0.4134, d0.dn_loss_bbox: 0.6671, d1.dn_loss_cls: 0.3955, d1.dn_loss_bbox: 0.6037, d2.dn_loss_cls: 0.3854, d2.dn_loss_bbox: 0.5706, d3.dn_loss_cls: 0.3749, d3.dn_loss_bbox: 0.5430, d4.dn_loss_cls: 0.3714, d4.dn_loss_bbox: 0.5338, loss: 10.2249, grad_norm: 47.7579
2025-10-13 12:18:07,756 - mmdet - INFO - Epoch [1][750/4004]	lr: 6.226e-06, eta: 0:37:21, time: 0.644, data_time: 0.042, memory: 21587, loss_cls: 0.0854, loss_bbox: 0.5980, d0.loss_cls: 0.1053, d0.loss_bbox: 0.7569, d1.loss_cls: 0.0973, d1.loss_bbox: 0.6740, d2.loss_cls: 0.0888, d2.loss_bbox: 0.6362, d3.loss_cls: 0.0857, d3.loss_bbox: 0.6116, d4.loss_cls: 0.0856, d4.loss_bbox: 0.6009, dn_loss_cls: 0.3700, dn_loss_bbox: 0.5209, d0.dn_loss_cls: 0.4135, d0.dn_loss_bbox: 0.6555, d1.dn_loss_cls: 0.3950, d1.dn_loss_bbox: 0.5925, d2.dn_loss_cls: 0.3845, d2.dn_loss_bbox: 0.5594, d3.dn_loss_cls: 0.3743, d3.dn_loss_bbox: 0.5329, d4.dn_loss_cls: 0.3710, d4.dn_loss_bbox: 0.5237, loss: 10.1190, grad_norm: 50.6073
2025-10-13 12:18:40,308 - mmdet - INFO - Epoch [1][800/4004]	lr: 6.637e-06, eta: 0:36:39, time: 0.651, data_time: 0.043, memory: 21587, loss_cls: 0.0896, loss_bbox: 0.6091, d0.loss_cls: 0.1099, d0.loss_bbox: 0.7687, d1.loss_cls: 0.1017, d1.loss_bbox: 0.6867, d2.loss_cls: 0.0933, d2.loss_bbox: 0.6474, d3.loss_cls: 0.0898, d3.loss_bbox: 0.6227, d4.loss_cls: 0.0898, d4.loss_bbox: 0.6109, dn_loss_cls: 0.3729, dn_loss_bbox: 0.5315, d0.dn_loss_cls: 0.4162, d0.dn_loss_bbox: 0.6716, d1.dn_loss_cls: 0.3977, d1.dn_loss_bbox: 0.6059, d2.dn_loss_cls: 0.3873, d2.dn_loss_bbox: 0.5717, d3.dn_loss_cls: 0.3772, d3.dn_loss_bbox: 0.5429, d4.dn_loss_cls: 0.3738, d4.dn_loss_bbox: 0.5339, loss: 10.3021, grad_norm: 49.6701
2025-10-13 12:19:12,503 - mmdet - INFO - Epoch [1][850/4004]	lr: 7.018e-06, eta: 0:35:57, time: 0.644, data_time: 0.041, memory: 21587, loss_cls: 0.0867, loss_bbox: 0.5929, d0.loss_cls: 0.1064, d0.loss_bbox: 0.7487, d1.loss_cls: 0.0981, d1.loss_bbox: 0.6704, d2.loss_cls: 0.0901, d2.loss_bbox: 0.6338, d3.loss_cls: 0.0867, d3.loss_bbox: 0.6082, d4.loss_cls: 0.0867, d4.loss_bbox: 0.5959, dn_loss_cls: 0.3687, dn_loss_bbox: 0.5191, d0.dn_loss_cls: 0.4116, d0.dn_loss_bbox: 0.6559, d1.dn_loss_cls: 0.3934, d1.dn_loss_bbox: 0.5920, d2.dn_loss_cls: 0.3834, d2.dn_loss_bbox: 0.5585, d3.dn_loss_cls: 0.3728, d3.dn_loss_bbox: 0.5307, d4.dn_loss_cls: 0.3693, d4.dn_loss_bbox: 0.5215, loss: 10.0813, grad_norm: 54.0924
2025-10-13 12:19:44,745 - mmdet - INFO - Epoch [1][900/4004]	lr: 7.364e-06, eta: 0:35:16, time: 0.645, data_time: 0.041, memory: 21587, loss_cls: 0.0867, loss_bbox: 0.5871, d0.loss_cls: 0.1068, d0.loss_bbox: 0.7397, d1.loss_cls: 0.0985, d1.loss_bbox: 0.6628, d2.loss_cls: 0.0903, d2.loss_bbox: 0.6268, d3.loss_cls: 0.0868, d3.loss_bbox: 0.6015, d4.loss_cls: 0.0867, d4.loss_bbox: 0.5902, dn_loss_cls: 0.3691, dn_loss_bbox: 0.5118, d0.dn_loss_cls: 0.4113, d0.dn_loss_bbox: 0.6468, d1.dn_loss_cls: 0.3937, d1.dn_loss_bbox: 0.5851, d2.dn_loss_cls: 0.3835, d2.dn_loss_bbox: 0.5523, d3.dn_loss_cls: 0.3732, d3.dn_loss_bbox: 0.5234, d4.dn_loss_cls: 0.3699, d4.dn_loss_bbox: 0.5140, loss: 9.9981, grad_norm: 54.7336
2025-10-13 12:20:17,058 - mmdet - INFO - Epoch [1][950/4004]	lr: 7.667e-06, eta: 0:34:36, time: 0.646, data_time: 0.041, memory: 21587, loss_cls: 0.0888, loss_bbox: 0.5964, d0.loss_cls: 0.1092, d0.loss_bbox: 0.7565, d1.loss_cls: 0.1009, d1.loss_bbox: 0.6737, d2.loss_cls: 0.0926, d2.loss_bbox: 0.6357, d3.loss_cls: 0.0891, d3.loss_bbox: 0.6101, d4.loss_cls: 0.0891, d4.loss_bbox: 0.5984, dn_loss_cls: 0.3739, dn_loss_bbox: 0.5194, d0.dn_loss_cls: 0.4169, d0.dn_loss_bbox: 0.6556, d1.dn_loss_cls: 0.3982, d1.dn_loss_bbox: 0.5918, d2.dn_loss_cls: 0.3879, d2.dn_loss_bbox: 0.5600, d3.dn_loss_cls: 0.3777, d3.dn_loss_bbox: 0.5317, d4.dn_loss_cls: 0.3746, d4.dn_loss_bbox: 0.5220, loss: 10.1501, grad_norm: 56.4193
2025-10-13 12:20:49,303 - mmdet - INFO - Exp name: cmt_aqr_voxel0100_r50_800x320_cbgs.py
2025-10-13 12:20:49,303 - mmdet - INFO - Epoch [1][1000/4004]	lr: 7.923e-06, eta: 0:33:57, time: 0.645, data_time: 0.040, memory: 21587, loss_cls: 0.0911, loss_bbox: 0.6176, d0.loss_cls: 0.1115, d0.loss_bbox: 0.7830, d1.loss_cls: 0.1030, d1.loss_bbox: 0.6976, d2.loss_cls: 0.0948, d2.loss_bbox: 0.6586, d3.loss_cls: 0.0913, d3.loss_bbox: 0.6323, d4.loss_cls: 0.0913, d4.loss_bbox: 0.6208, dn_loss_cls: 0.3773, dn_loss_bbox: 0.5392, d0.dn_loss_cls: 0.4207, d0.dn_loss_bbox: 0.6790, d1.dn_loss_cls: 0.4017, d1.dn_loss_bbox: 0.6129, d2.dn_loss_cls: 0.3915, d2.dn_loss_bbox: 0.5793, d3.dn_loss_cls: 0.3811, d3.dn_loss_bbox: 0.5509, d4.dn_loss_cls: 0.3780, d4.dn_loss_bbox: 0.5418, loss: 10.4464, grad_norm: 56.3619
2025-10-13 12:21:21,921 - mmdet - INFO - Epoch [1][1050/4004]	lr: 8.127e-06, eta: 0:33:19, time: 0.652, data_time: 0.040, memory: 21587, loss_cls: 0.0866, loss_bbox: 0.5878, d0.loss_cls: 0.1070, d0.loss_bbox: 0.7440, d1.loss_cls: 0.0984, d1.loss_bbox: 0.6613, d2.loss_cls: 0.0902, d2.loss_bbox: 0.6255, d3.loss_cls: 0.0869, d3.loss_bbox: 0.6002, d4.loss_cls: 0.0868, d4.loss_bbox: 0.5901, dn_loss_cls: 0.3700, dn_loss_bbox: 0.5161, d0.dn_loss_cls: 0.4124, d0.dn_loss_bbox: 0.6476, d1.dn_loss_cls: 0.3939, d1.dn_loss_bbox: 0.5857, d2.dn_loss_cls: 0.3839, d2.dn_loss_bbox: 0.5540, d3.dn_loss_cls: 0.3735, d3.dn_loss_bbox: 0.5273, d4.dn_loss_cls: 0.3705, d4.dn_loss_bbox: 0.5184, loss: 10.0181, grad_norm: 46.1884
2025-10-13 12:21:54,132 - mmdet - INFO - Epoch [1][1100/4004]	lr: 8.276e-06, eta: 0:32:41, time: 0.644, data_time: 0.041, memory: 21587, loss_cls: 0.0885, loss_bbox: 0.5949, d0.loss_cls: 0.1084, d0.loss_bbox: 0.7448, d1.loss_cls: 0.1002, d1.loss_bbox: 0.6671, d2.loss_cls: 0.0919, d2.loss_bbox: 0.6327, d3.loss_cls: 0.0888, d3.loss_bbox: 0.6081, d4.loss_cls: 0.0887, d4.loss_bbox: 0.5973, dn_loss_cls: 0.3710, dn_loss_bbox: 0.5185, d0.dn_loss_cls: 0.4136, d0.dn_loss_bbox: 0.6499, d1.dn_loss_cls: 0.3954, d1.dn_loss_bbox: 0.5888, d2.dn_loss_cls: 0.3848, d2.dn_loss_bbox: 0.5568, d3.dn_loss_cls: 0.3748, d3.dn_loss_bbox: 0.5300, d4.dn_loss_cls: 0.3717, d4.dn_loss_bbox: 0.5207, loss: 10.0874, grad_norm: 52.8809
2025-10-13 12:22:26,349 - mmdet - INFO - Epoch [1][1150/4004]	lr: 8.368e-06, eta: 0:32:04, time: 0.644, data_time: 0.041, memory: 21587, loss_cls: 0.0878, loss_bbox: 0.5952, d0.loss_cls: 0.1071, d0.loss_bbox: 0.7561, d1.loss_cls: 0.0991, d1.loss_bbox: 0.6726, d2.loss_cls: 0.0911, d2.loss_bbox: 0.6328, d3.loss_cls: 0.0880, d3.loss_bbox: 0.6098, d4.loss_cls: 0.0879, d4.loss_bbox: 0.5985, dn_loss_cls: 0.3699, dn_loss_bbox: 0.5245, d0.dn_loss_cls: 0.4120, d0.dn_loss_bbox: 0.6605, d1.dn_loss_cls: 0.3942, d1.dn_loss_bbox: 0.5966, d2.dn_loss_cls: 0.3836, d2.dn_loss_bbox: 0.5629, d3.dn_loss_cls: 0.3737, d3.dn_loss_bbox: 0.5360, d4.dn_loss_cls: 0.3705, d4.dn_loss_bbox: 0.5270, loss: 10.1371, grad_norm: 55.1511
2025-10-13 12:22:58,426 - mmdet - INFO - Epoch [1][1200/4004]	lr: 8.400e-06, eta: 0:31:26, time: 0.642, data_time: 0.042, memory: 21587, loss_cls: 0.0872, loss_bbox: 0.5963, d0.loss_cls: 0.1077, d0.loss_bbox: 0.7520, d1.loss_cls: 0.0988, d1.loss_bbox: 0.6746, d2.loss_cls: 0.0904, d2.loss_bbox: 0.6374, d3.loss_cls: 0.0873, d3.loss_bbox: 0.6106, d4.loss_cls: 0.0871, d4.loss_bbox: 0.6003, dn_loss_cls: 0.3688, dn_loss_bbox: 0.5216, d0.dn_loss_cls: 0.4132, d0.dn_loss_bbox: 0.6584, d1.dn_loss_cls: 0.3936, d1.dn_loss_bbox: 0.5951, d2.dn_loss_cls: 0.3834, d2.dn_loss_bbox: 0.5617, d3.dn_loss_cls: 0.3724, d3.dn_loss_bbox: 0.5338, d4.dn_loss_cls: 0.3695, d4.dn_loss_bbox: 0.5241, loss: 10.1250, grad_norm: 52.8872
2025-10-13 12:23:30,982 - mmdet - INFO - Epoch [1][1250/4004]	lr: 8.394e-06, eta: 0:30:50, time: 0.651, data_time: 0.039, memory: 21587, loss_cls: 0.0875, loss_bbox: 0.5894, d0.loss_cls: 0.1079, d0.loss_bbox: 0.7396, d1.loss_cls: 0.0995, d1.loss_bbox: 0.6642, d2.loss_cls: 0.0911, d2.loss_bbox: 0.6280, d3.loss_cls: 0.0876, d3.loss_bbox: 0.6041, d4.loss_cls: 0.0875, d4.loss_bbox: 0.5929, dn_loss_cls: 0.3674, dn_loss_bbox: 0.5142, d0.dn_loss_cls: 0.4099, d0.dn_loss_bbox: 0.6453, d1.dn_loss_cls: 0.3917, d1.dn_loss_bbox: 0.5852, d2.dn_loss_cls: 0.3818, d2.dn_loss_bbox: 0.5533, d3.dn_loss_cls: 0.3715, d3.dn_loss_bbox: 0.5256, d4.dn_loss_cls: 0.3682, d4.dn_loss_bbox: 0.5166, loss: 10.0101, grad_norm: 52.8522
2025-10-13 12:24:03,905 - mmdet - INFO - Epoch [1][1300/4004]	lr: 8.375e-06, eta: 0:30:15, time: 0.658, data_time: 0.039, memory: 21587, loss_cls: 0.0889, loss_bbox: 0.6058, d0.loss_cls: 0.1095, d0.loss_bbox: 0.7686, d1.loss_cls: 0.1008, d1.loss_bbox: 0.6811, d2.loss_cls: 0.0927, d2.loss_bbox: 0.6436, d3.loss_cls: 0.0892, d3.loss_bbox: 0.6201, d4.loss_cls: 0.0892, d4.loss_bbox: 0.6076, dn_loss_cls: 0.3726, dn_loss_bbox: 0.5232, d0.dn_loss_cls: 0.4150, d0.dn_loss_bbox: 0.6614, d1.dn_loss_cls: 0.3966, d1.dn_loss_bbox: 0.5958, d2.dn_loss_cls: 0.3874, d2.dn_loss_bbox: 0.5636, d3.dn_loss_cls: 0.3768, d3.dn_loss_bbox: 0.5349, d4.dn_loss_cls: 0.3735, d4.dn_loss_bbox: 0.5256, loss: 10.2236, grad_norm: 53.8197
2025-10-13 12:24:36,737 - mmdet - INFO - Epoch [1][1350/4004]	lr: 8.342e-06, eta: 0:29:40, time: 0.657, data_time: 0.038, memory: 21587, loss_cls: 0.0861, loss_bbox: 0.5956, d0.loss_cls: 0.1065, d0.loss_bbox: 0.7529, d1.loss_cls: 0.0985, d1.loss_bbox: 0.6685, d2.loss_cls: 0.0904, d2.loss_bbox: 0.6304, d3.loss_cls: 0.0866, d3.loss_bbox: 0.6079, d4.loss_cls: 0.0862, d4.loss_bbox: 0.5976, dn_loss_cls: 0.3694, dn_loss_bbox: 0.5164, d0.dn_loss_cls: 0.4126, d0.dn_loss_bbox: 0.6528, d1.dn_loss_cls: 0.3934, d1.dn_loss_bbox: 0.5890, d2.dn_loss_cls: 0.3835, d2.dn_loss_bbox: 0.5563, d3.dn_loss_cls: 0.3734, d3.dn_loss_bbox: 0.5281, d4.dn_loss_cls: 0.3701, d4.dn_loss_bbox: 0.5189, loss: 10.0711, grad_norm: 54.2968
2025-10-13 12:25:09,316 - mmdet - INFO - Epoch [1][1400/4004]	lr: 8.297e-06, eta: 0:29:05, time: 0.652, data_time: 0.039, memory: 21587, loss_cls: 0.0870, loss_bbox: 0.5888, d0.loss_cls: 0.1074, d0.loss_bbox: 0.7438, d1.loss_cls: 0.0992, d1.loss_bbox: 0.6633, d2.loss_cls: 0.0907, d2.loss_bbox: 0.6261, d3.loss_cls: 0.0874, d3.loss_bbox: 0.6024, d4.loss_cls: 0.0872, d4.loss_bbox: 0.5908, dn_loss_cls: 0.3699, dn_loss_bbox: 0.5126, d0.dn_loss_cls: 0.4130, d0.dn_loss_bbox: 0.6477, d1.dn_loss_cls: 0.3940, d1.dn_loss_bbox: 0.5850, d2.dn_loss_cls: 0.3842, d2.dn_loss_bbox: 0.5523, d3.dn_loss_cls: 0.3738, d3.dn_loss_bbox: 0.5243, d4.dn_loss_cls: 0.3704, d4.dn_loss_bbox: 0.5150, loss: 10.0161, grad_norm: 49.7797
2025-10-13 12:25:41,361 - mmdet - INFO - Epoch [1][1450/4004]	lr: 8.239e-06, eta: 0:28:29, time: 0.641, data_time: 0.041, memory: 21587, loss_cls: 0.0864, loss_bbox: 0.5996, d0.loss_cls: 0.1062, d0.loss_bbox: 0.7600, d1.loss_cls: 0.0983, d1.loss_bbox: 0.6749, d2.loss_cls: 0.0902, d2.loss_bbox: 0.6360, d3.loss_cls: 0.0865, d3.loss_bbox: 0.6135, d4.loss_cls: 0.0865, d4.loss_bbox: 0.6026, dn_loss_cls: 0.3696, dn_loss_bbox: 0.5217, d0.dn_loss_cls: 0.4128, d0.dn_loss_bbox: 0.6584, d1.dn_loss_cls: 0.3940, d1.dn_loss_bbox: 0.5938, d2.dn_loss_cls: 0.3838, d2.dn_loss_bbox: 0.5606, d3.dn_loss_cls: 0.3733, d3.dn_loss_bbox: 0.5336, d4.dn_loss_cls: 0.3703, d4.dn_loss_bbox: 0.5243, loss: 10.1368, grad_norm: 51.3062
2025-10-13 12:26:13,571 - mmdet - INFO - Epoch [1][1500/4004]	lr: 8.168e-06, eta: 0:27:53, time: 0.644, data_time: 0.042, memory: 21587, loss_cls: 0.0885, loss_bbox: 0.5984, d0.loss_cls: 0.1084, d0.loss_bbox: 0.7602, d1.loss_cls: 0.1004, d1.loss_bbox: 0.6760, d2.loss_cls: 0.0921, d2.loss_bbox: 0.6384, d3.loss_cls: 0.0885, d3.loss_bbox: 0.6138, d4.loss_cls: 0.0885, d4.loss_bbox: 0.6016, dn_loss_cls: 0.3712, dn_loss_bbox: 0.5226, d0.dn_loss_cls: 0.4139, d0.dn_loss_bbox: 0.6598, d1.dn_loss_cls: 0.3954, d1.dn_loss_bbox: 0.5955, d2.dn_loss_cls: 0.3857, d2.dn_loss_bbox: 0.5628, d3.dn_loss_cls: 0.3754, d3.dn_loss_bbox: 0.5345, d4.dn_loss_cls: 0.3720, d4.dn_loss_bbox: 0.5251, loss: 10.1687, grad_norm: 50.6265
2025-10-13 12:26:45,951 - mmdet - INFO - Epoch [1][1550/4004]	lr: 8.085e-06, eta: 0:27:18, time: 0.647, data_time: 0.041, memory: 21587, loss_cls: 0.0855, loss_bbox: 0.5995, d0.loss_cls: 0.1058, d0.loss_bbox: 0.7508, d1.loss_cls: 0.0972, d1.loss_bbox: 0.6719, d2.loss_cls: 0.0891, d2.loss_bbox: 0.6349, d3.loss_cls: 0.0858, d3.loss_bbox: 0.6134, d4.loss_cls: 0.0856, d4.loss_bbox: 0.6023, dn_loss_cls: 0.3710, dn_loss_bbox: 0.5254, d0.dn_loss_cls: 0.4135, d0.dn_loss_bbox: 0.6597, d1.dn_loss_cls: 0.3953, d1.dn_loss_bbox: 0.5973, d2.dn_loss_cls: 0.3850, d2.dn_loss_bbox: 0.5637, d3.dn_loss_cls: 0.3752, d3.dn_loss_bbox: 0.5367, d4.dn_loss_cls: 0.3719, d4.dn_loss_bbox: 0.5279, loss: 10.1443, grad_norm: 56.8982
2025-10-13 12:27:18,659 - mmdet - INFO - Epoch [1][1600/4004]	lr: 7.989e-06, eta: 0:26:44, time: 0.654, data_time: 0.039, memory: 21587, loss_cls: 0.0867, loss_bbox: 0.5910, d0.loss_cls: 0.1078, d0.loss_bbox: 0.7470, d1.loss_cls: 0.0990, d1.loss_bbox: 0.6681, d2.loss_cls: 0.0907, d2.loss_bbox: 0.6278, d3.loss_cls: 0.0870, d3.loss_bbox: 0.6038, d4.loss_cls: 0.0869, d4.loss_bbox: 0.5936, dn_loss_cls: 0.3697, dn_loss_bbox: 0.5147, d0.dn_loss_cls: 0.4123, d0.dn_loss_bbox: 0.6489, d1.dn_loss_cls: 0.3939, d1.dn_loss_bbox: 0.5871, d2.dn_loss_cls: 0.3840, d2.dn_loss_bbox: 0.5543, d3.dn_loss_cls: 0.3737, d3.dn_loss_bbox: 0.5264, d4.dn_loss_cls: 0.3703, d4.dn_loss_bbox: 0.5172, loss: 10.0420, grad_norm: 50.8211
2025-10-13 12:27:50,861 - mmdet - INFO - Epoch [1][1650/4004]	lr: 7.882e-06, eta: 0:26:09, time: 0.644, data_time: 0.041, memory: 21587, loss_cls: 0.0900, loss_bbox: 0.6045, d0.loss_cls: 0.1106, d0.loss_bbox: 0.7715, d1.loss_cls: 0.1020, d1.loss_bbox: 0.6841, d2.loss_cls: 0.0939, d2.loss_bbox: 0.6433, d3.loss_cls: 0.0902, d3.loss_bbox: 0.6189, d4.loss_cls: 0.0902, d4.loss_bbox: 0.6073, dn_loss_cls: 0.3717, dn_loss_bbox: 0.5234, d0.dn_loss_cls: 0.4149, d0.dn_loss_bbox: 0.6638, d1.dn_loss_cls: 0.3958, d1.dn_loss_bbox: 0.5980, d2.dn_loss_cls: 0.3854, d2.dn_loss_bbox: 0.5638, d3.dn_loss_cls: 0.3754, d3.dn_loss_bbox: 0.5350, d4.dn_loss_cls: 0.3723, d4.dn_loss_bbox: 0.5259, loss: 10.2318, grad_norm: 53.8831
2025-10-13 12:28:22,854 - mmdet - INFO - Epoch [1][1700/4004]	lr: 7.763e-06, eta: 0:25:33, time: 0.640, data_time: 0.041, memory: 21587, loss_cls: 0.0873, loss_bbox: 0.6052, d0.loss_cls: 0.1083, d0.loss_bbox: 0.7631, d1.loss_cls: 0.0991, d1.loss_bbox: 0.6794, d2.loss_cls: 0.0910, d2.loss_bbox: 0.6421, d3.loss_cls: 0.0877, d3.loss_bbox: 0.6183, d4.loss_cls: 0.0874, d4.loss_bbox: 0.6074, dn_loss_cls: 0.3713, dn_loss_bbox: 0.5268, d0.dn_loss_cls: 0.4140, d0.dn_loss_bbox: 0.6645, d1.dn_loss_cls: 0.3954, d1.dn_loss_bbox: 0.6001, d2.dn_loss_cls: 0.3853, d2.dn_loss_bbox: 0.5662, d3.dn_loss_cls: 0.3753, d3.dn_loss_bbox: 0.5383, d4.dn_loss_cls: 0.3721, d4.dn_loss_bbox: 0.5292, loss: 10.2148, grad_norm: 49.6001
2025-10-13 12:28:55,226 - mmdet - INFO - Epoch [1][1750/4004]	lr: 7.633e-06, eta: 0:24:59, time: 0.648, data_time: 0.038, memory: 21587, loss_cls: 0.0869, loss_bbox: 0.5971, d0.loss_cls: 0.1068, d0.loss_bbox: 0.7542, d1.loss_cls: 0.0987, d1.loss_bbox: 0.6693, d2.loss_cls: 0.0905, d2.loss_bbox: 0.6334, d3.loss_cls: 0.0870, d3.loss_bbox: 0.6100, d4.loss_cls: 0.0871, d4.loss_bbox: 0.5984, dn_loss_cls: 0.3686, dn_loss_bbox: 0.5206, d0.dn_loss_cls: 0.4114, d0.dn_loss_bbox: 0.6552, d1.dn_loss_cls: 0.3930, d1.dn_loss_bbox: 0.5925, d2.dn_loss_cls: 0.3825, d2.dn_loss_bbox: 0.5587, d3.dn_loss_cls: 0.3725, d3.dn_loss_bbox: 0.5324, d4.dn_loss_cls: 0.3694, d4.dn_loss_bbox: 0.5232, loss: 10.0993, grad_norm: 46.9947
2025-10-13 12:29:27,445 - mmdet - INFO - Epoch [1][1800/4004]	lr: 7.492e-06, eta: 0:24:24, time: 0.644, data_time: 0.039, memory: 21587, loss_cls: 0.0886, loss_bbox: 0.6027, d0.loss_cls: 0.1095, d0.loss_bbox: 0.7638, d1.loss_cls: 0.1010, d1.loss_bbox: 0.6775, d2.loss_cls: 0.0926, d2.loss_bbox: 0.6396, d3.loss_cls: 0.0888, d3.loss_bbox: 0.6157, d4.loss_cls: 0.0888, d4.loss_bbox: 0.6052, dn_loss_cls: 0.3721, dn_loss_bbox: 0.5280, d0.dn_loss_cls: 0.4161, d0.dn_loss_bbox: 0.6684, d1.dn_loss_cls: 0.3974, d1.dn_loss_bbox: 0.6035, d2.dn_loss_cls: 0.3873, d2.dn_loss_bbox: 0.5685, d3.dn_loss_cls: 0.3762, d3.dn_loss_bbox: 0.5401, d4.dn_loss_cls: 0.3728, d4.dn_loss_bbox: 0.5306, loss: 10.2348, grad_norm: 51.0270
2025-10-13 12:29:59,414 - mmdet - INFO - Epoch [1][1850/4004]	lr: 7.340e-06, eta: 0:23:50, time: 0.639, data_time: 0.041, memory: 21587, loss_cls: 0.0862, loss_bbox: 0.5933, d0.loss_cls: 0.1065, d0.loss_bbox: 0.7499, d1.loss_cls: 0.0985, d1.loss_bbox: 0.6677, d2.loss_cls: 0.0902, d2.loss_bbox: 0.6297, d3.loss_cls: 0.0867, d3.loss_bbox: 0.6055, d4.loss_cls: 0.0865, d4.loss_bbox: 0.5954, dn_loss_cls: 0.3684, dn_loss_bbox: 0.5152, d0.dn_loss_cls: 0.4117, d0.dn_loss_bbox: 0.6515, d1.dn_loss_cls: 0.3928, d1.dn_loss_bbox: 0.5867, d2.dn_loss_cls: 0.3826, d2.dn_loss_bbox: 0.5539, d3.dn_loss_cls: 0.3726, d3.dn_loss_bbox: 0.5269, d4.dn_loss_cls: 0.3692, d4.dn_loss_bbox: 0.5179, loss: 10.0456, grad_norm: 48.1987
2025-10-13 12:30:31,509 - mmdet - INFO - Epoch [1][1900/4004]	lr: 7.179e-06, eta: 0:23:15, time: 0.642, data_time: 0.041, memory: 21587, loss_cls: 0.0859, loss_bbox: 0.6005, d0.loss_cls: 0.1061, d0.loss_bbox: 0.7552, d1.loss_cls: 0.0978, d1.loss_bbox: 0.6783, d2.loss_cls: 0.0894, d2.loss_bbox: 0.6369, d3.loss_cls: 0.0861, d3.loss_bbox: 0.6136, d4.loss_cls: 0.0860, d4.loss_bbox: 0.6034, dn_loss_cls: 0.3689, dn_loss_bbox: 0.5249, d0.dn_loss_cls: 0.4125, d0.dn_loss_bbox: 0.6611, d1.dn_loss_cls: 0.3936, d1.dn_loss_bbox: 0.5977, d2.dn_loss_cls: 0.3832, d2.dn_loss_bbox: 0.5650, d3.dn_loss_cls: 0.3733, d3.dn_loss_bbox: 0.5370, d4.dn_loss_cls: 0.3699, d4.dn_loss_bbox: 0.5275, loss: 10.1539, grad_norm: 50.8525
2025-10-13 12:31:03,774 - mmdet - INFO - Epoch [1][1950/4004]	lr: 7.009e-06, eta: 0:22:41, time: 0.645, data_time: 0.041, memory: 21587, loss_cls: 0.0851, loss_bbox: 0.5831, d0.loss_cls: 0.1054, d0.loss_bbox: 0.7355, d1.loss_cls: 0.0969, d1.loss_bbox: 0.6584, d2.loss_cls: 0.0883, d2.loss_bbox: 0.6220, d3.loss_cls: 0.0853, d3.loss_bbox: 0.5963, d4.loss_cls: 0.0852, d4.loss_bbox: 0.5858, dn_loss_cls: 0.3672, dn_loss_bbox: 0.5150, d0.dn_loss_cls: 0.4092, d0.dn_loss_bbox: 0.6490, d1.dn_loss_cls: 0.3914, d1.dn_loss_bbox: 0.5867, d2.dn_loss_cls: 0.3812, d2.dn_loss_bbox: 0.5544, d3.dn_loss_cls: 0.3709, d3.dn_loss_bbox: 0.5272, d4.dn_loss_cls: 0.3679, d4.dn_loss_bbox: 0.5176, loss: 9.9650, grad_norm: 47.1409
2025-10-13 12:31:35,873 - mmdet - INFO - Exp name: cmt_aqr_voxel0100_r50_800x320_cbgs.py
2025-10-13 12:31:35,873 - mmdet - INFO - Epoch [1][2000/4004]	lr: 6.829e-06, eta: 0:22:07, time: 0.642, data_time: 0.041, memory: 21587, loss_cls: 0.0867, loss_bbox: 0.5997, d0.loss_cls: 0.1067, d0.loss_bbox: 0.7563, d1.loss_cls: 0.0982, d1.loss_bbox: 0.6739, d2.loss_cls: 0.0899, d2.loss_bbox: 0.6367, d3.loss_cls: 0.0868, d3.loss_bbox: 0.6130, d4.loss_cls: 0.0867, d4.loss_bbox: 0.6024, dn_loss_cls: 0.3698, dn_loss_bbox: 0.5257, d0.dn_loss_cls: 0.4113, d0.dn_loss_bbox: 0.6603, d1.dn_loss_cls: 0.3931, d1.dn_loss_bbox: 0.5960, d2.dn_loss_cls: 0.3835, d2.dn_loss_bbox: 0.5632, d3.dn_loss_cls: 0.3735, d3.dn_loss_bbox: 0.5365, d4.dn_loss_cls: 0.3707, d4.dn_loss_bbox: 0.5280, loss: 10.1484, grad_norm: 47.7087
2025-10-13 12:32:08,015 - mmdet - INFO - Epoch [1][2050/4004]	lr: 6.642e-06, eta: 0:21:33, time: 0.643, data_time: 0.041, memory: 21587, loss_cls: 0.0868, loss_bbox: 0.5887, d0.loss_cls: 0.1075, d0.loss_bbox: 0.7439, d1.loss_cls: 0.0992, d1.loss_bbox: 0.6634, d2.loss_cls: 0.0905, d2.loss_bbox: 0.6263, d3.loss_cls: 0.0871, d3.loss_bbox: 0.6009, d4.loss_cls: 0.0869, d4.loss_bbox: 0.5904, dn_loss_cls: 0.3699, dn_loss_bbox: 0.5072, d0.dn_loss_cls: 0.4137, d0.dn_loss_bbox: 0.6407, d1.dn_loss_cls: 0.3945, d1.dn_loss_bbox: 0.5782, d2.dn_loss_cls: 0.3841, d2.dn_loss_bbox: 0.5460, d3.dn_loss_cls: 0.3738, d3.dn_loss_bbox: 0.5185, d4.dn_loss_cls: 0.3708, d4.dn_loss_bbox: 0.5097, loss: 9.9788, grad_norm: 50.0318
2025-10-13 12:32:40,164 - mmdet - INFO - Epoch [1][2100/4004]	lr: 6.447e-06, eta: 0:20:59, time: 0.643, data_time: 0.043, memory: 21587, loss_cls: 0.0865, loss_bbox: 0.5981, d0.loss_cls: 0.1071, d0.loss_bbox: 0.7570, d1.loss_cls: 0.0983, d1.loss_bbox: 0.6756, d2.loss_cls: 0.0902, d2.loss_bbox: 0.6365, d3.loss_cls: 0.0868, d3.loss_bbox: 0.6120, d4.loss_cls: 0.0866, d4.loss_bbox: 0.6011, dn_loss_cls: 0.3724, dn_loss_bbox: 0.5205, d0.dn_loss_cls: 0.4158, d0.dn_loss_bbox: 0.6594, d1.dn_loss_cls: 0.3970, d1.dn_loss_bbox: 0.5935, d2.dn_loss_cls: 0.3867, d2.dn_loss_bbox: 0.5601, d3.dn_loss_cls: 0.3762, d3.dn_loss_bbox: 0.5324, d4.dn_loss_cls: 0.3729, d4.dn_loss_bbox: 0.5230, loss: 10.1457, grad_norm: inf
2025-10-13 12:33:12,668 - mmdet - INFO - Epoch [1][2150/4004]	lr: 6.244e-06, eta: 0:20:25, time: 0.650, data_time: 0.040, memory: 21587, loss_cls: 0.0860, loss_bbox: 0.5838, d0.loss_cls: 0.1069, d0.loss_bbox: 0.7388, d1.loss_cls: 0.0984, d1.loss_bbox: 0.6568, d2.loss_cls: 0.0897, d2.loss_bbox: 0.6209, d3.loss_cls: 0.0864, d3.loss_bbox: 0.5964, d4.loss_cls: 0.0861, d4.loss_bbox: 0.5862, dn_loss_cls: 0.3650, dn_loss_bbox: 0.5130, d0.dn_loss_cls: 0.4083, d0.dn_loss_bbox: 0.6518, d1.dn_loss_cls: 0.3896, d1.dn_loss_bbox: 0.5873, d2.dn_loss_cls: 0.3794, d2.dn_loss_bbox: 0.5542, d3.dn_loss_cls: 0.3690, d3.dn_loss_bbox: 0.5254, d4.dn_loss_cls: 0.3659, d4.dn_loss_bbox: 0.5157, loss: 9.9611, grad_norm: 47.2628
2025-10-13 12:33:44,780 - mmdet - INFO - Epoch [1][2200/4004]	lr: 6.036e-06, eta: 0:19:52, time: 0.642, data_time: 0.041, memory: 21587, loss_cls: 0.0883, loss_bbox: 0.5953, d0.loss_cls: 0.1091, d0.loss_bbox: 0.7519, d1.loss_cls: 0.1004, d1.loss_bbox: 0.6733, d2.loss_cls: 0.0920, d2.loss_bbox: 0.6348, d3.loss_cls: 0.0885, d3.loss_bbox: 0.6085, d4.loss_cls: 0.0885, d4.loss_bbox: 0.5981, dn_loss_cls: 0.3694, dn_loss_bbox: 0.5250, d0.dn_loss_cls: 0.4129, d0.dn_loss_bbox: 0.6645, d1.dn_loss_cls: 0.3934, d1.dn_loss_bbox: 0.5996, d2.dn_loss_cls: 0.3830, d2.dn_loss_bbox: 0.5654, d3.dn_loss_cls: 0.3733, d3.dn_loss_bbox: 0.5364, d4.dn_loss_cls: 0.3700, d4.dn_loss_bbox: 0.5275, loss: 10.1490, grad_norm: 52.3345
2025-10-13 12:34:16,993 - mmdet - INFO - Epoch [1][2250/4004]	lr: 5.821e-06, eta: 0:19:18, time: 0.644, data_time: 0.041, memory: 21587, loss_cls: 0.0866, loss_bbox: 0.5847, d0.loss_cls: 0.1079, d0.loss_bbox: 0.7417, d1.loss_cls: 0.0991, d1.loss_bbox: 0.6625, d2.loss_cls: 0.0903, d2.loss_bbox: 0.6241, d3.loss_cls: 0.0867, d3.loss_bbox: 0.5989, d4.loss_cls: 0.0866, d4.loss_bbox: 0.5876, dn_loss_cls: 0.3680, dn_loss_bbox: 0.5120, d0.dn_loss_cls: 0.4105, d0.dn_loss_bbox: 0.6461, d1.dn_loss_cls: 0.3925, d1.dn_loss_bbox: 0.5830, d2.dn_loss_cls: 0.3822, d2.dn_loss_bbox: 0.5507, d3.dn_loss_cls: 0.3720, d3.dn_loss_bbox: 0.5232, d4.dn_loss_cls: 0.3686, d4.dn_loss_bbox: 0.5142, loss: 9.9799, grad_norm: 49.4019
2025-10-13 12:34:48,896 - mmdet - INFO - Epoch [1][2300/4004]	lr: 5.602e-06, eta: 0:18:44, time: 0.638, data_time: 0.041, memory: 21587, loss_cls: 0.0852, loss_bbox: 0.5932, d0.loss_cls: 0.1058, d0.loss_bbox: 0.7514, d1.loss_cls: 0.0972, d1.loss_bbox: 0.6687, d2.loss_cls: 0.0894, d2.loss_bbox: 0.6287, d3.loss_cls: 0.0855, d3.loss_bbox: 0.6054, d4.loss_cls: 0.0853, d4.loss_bbox: 0.5957, dn_loss_cls: 0.3672, dn_loss_bbox: 0.5191, d0.dn_loss_cls: 0.4117, d0.dn_loss_bbox: 0.6585, d1.dn_loss_cls: 0.3925, d1.dn_loss_bbox: 0.5926, d2.dn_loss_cls: 0.3816, d2.dn_loss_bbox: 0.5588, d3.dn_loss_cls: 0.3712, d3.dn_loss_bbox: 0.5312, d4.dn_loss_cls: 0.3680, d4.dn_loss_bbox: 0.5217, loss: 10.0660, grad_norm: 45.3421
2025-10-13 12:35:21,298 - mmdet - INFO - Epoch [1][2350/4004]	lr: 5.378e-06, eta: 0:18:11, time: 0.648, data_time: 0.040, memory: 21587, loss_cls: 0.0875, loss_bbox: 0.6050, d0.loss_cls: 0.1075, d0.loss_bbox: 0.7674, d1.loss_cls: 0.0995, d1.loss_bbox: 0.6817, d2.loss_cls: 0.0912, d2.loss_bbox: 0.6422, d3.loss_cls: 0.0878, d3.loss_bbox: 0.6183, d4.loss_cls: 0.0876, d4.loss_bbox: 0.6068, dn_loss_cls: 0.3718, dn_loss_bbox: 0.5259, d0.dn_loss_cls: 0.4149, d0.dn_loss_bbox: 0.6641, d1.dn_loss_cls: 0.3956, d1.dn_loss_bbox: 0.5986, d2.dn_loss_cls: 0.3854, d2.dn_loss_bbox: 0.5651, d3.dn_loss_cls: 0.3758, d3.dn_loss_bbox: 0.5375, d4.dn_loss_cls: 0.3725, d4.dn_loss_bbox: 0.5285, loss: 10.2185, grad_norm: 51.8196
2025-10-13 12:35:53,899 - mmdet - INFO - Epoch [1][2400/4004]	lr: 5.150e-06, eta: 0:17:37, time: 0.652, data_time: 0.040, memory: 21587, loss_cls: 0.0870, loss_bbox: 0.5851, d0.loss_cls: 0.1072, d0.loss_bbox: 0.7405, d1.loss_cls: 0.0989, d1.loss_bbox: 0.6620, d2.loss_cls: 0.0907, d2.loss_bbox: 0.6232, d3.loss_cls: 0.0872, d3.loss_bbox: 0.5991, d4.loss_cls: 0.0872, d4.loss_bbox: 0.5870, dn_loss_cls: 0.3685, dn_loss_bbox: 0.5120, d0.dn_loss_cls: 0.4116, d0.dn_loss_bbox: 0.6484, d1.dn_loss_cls: 0.3927, d1.dn_loss_bbox: 0.5846, d2.dn_loss_cls: 0.3826, d2.dn_loss_bbox: 0.5515, d3.dn_loss_cls: 0.3726, d3.dn_loss_bbox: 0.5241, d4.dn_loss_cls: 0.3692, d4.dn_loss_bbox: 0.5145, loss: 9.9872, grad_norm: 50.2502
2025-10-13 12:36:26,630 - mmdet - INFO - Epoch [1][2450/4004]	lr: 4.920e-06, eta: 0:17:04, time: 0.655, data_time: 0.039, memory: 21587, loss_cls: 0.0869, loss_bbox: 0.5983, d0.loss_cls: 0.1077, d0.loss_bbox: 0.7559, d1.loss_cls: 0.0992, d1.loss_bbox: 0.6741, d2.loss_cls: 0.0906, d2.loss_bbox: 0.6360, d3.loss_cls: 0.0873, d3.loss_bbox: 0.6110, d4.loss_cls: 0.0871, d4.loss_bbox: 0.6010, dn_loss_cls: 0.3671, dn_loss_bbox: 0.5205, d0.dn_loss_cls: 0.4092, d0.dn_loss_bbox: 0.6573, d1.dn_loss_cls: 0.3910, d1.dn_loss_bbox: 0.5932, d2.dn_loss_cls: 0.3810, d2.dn_loss_bbox: 0.5596, d3.dn_loss_cls: 0.3710, d3.dn_loss_bbox: 0.5324, d4.dn_loss_cls: 0.3679, d4.dn_loss_bbox: 0.5229, loss: 10.1084, grad_norm: 49.0731
2025-10-13 12:36:59,179 - mmdet - INFO - Epoch [1][2500/4004]	lr: 4.687e-06, eta: 0:16:31, time: 0.651, data_time: 0.039, memory: 21587, loss_cls: 0.0886, loss_bbox: 0.6029, d0.loss_cls: 0.1088, d0.loss_bbox: 0.7639, d1.loss_cls: 0.1006, d1.loss_bbox: 0.6796, d2.loss_cls: 0.0926, d2.loss_bbox: 0.6404, d3.loss_cls: 0.0891, d3.loss_bbox: 0.6153, d4.loss_cls: 0.0886, d4.loss_bbox: 0.6058, dn_loss_cls: 0.3739, dn_loss_bbox: 0.5270, d0.dn_loss_cls: 0.4176, d0.dn_loss_bbox: 0.6632, d1.dn_loss_cls: 0.3986, d1.dn_loss_bbox: 0.6007, d2.dn_loss_cls: 0.3883, d2.dn_loss_bbox: 0.5671, d3.dn_loss_cls: 0.3777, d3.dn_loss_bbox: 0.5387, d4.dn_loss_cls: 0.3745, d4.dn_loss_bbox: 0.5296, loss: 10.2331, grad_norm: 57.5657
2025-10-13 12:37:31,370 - mmdet - INFO - Epoch [1][2550/4004]	lr: 4.452e-06, eta: 0:15:58, time: 0.644, data_time: 0.042, memory: 21587, loss_cls: 0.0863, loss_bbox: 0.5847, d0.loss_cls: 0.1072, d0.loss_bbox: 0.7359, d1.loss_cls: 0.0987, d1.loss_bbox: 0.6600, d2.loss_cls: 0.0901, d2.loss_bbox: 0.6219, d3.loss_cls: 0.0863, d3.loss_bbox: 0.5991, d4.loss_cls: 0.0864, d4.loss_bbox: 0.5870, dn_loss_cls: 0.3664, dn_loss_bbox: 0.5143, d0.dn_loss_cls: 0.4092, d0.dn_loss_bbox: 0.6482, d1.dn_loss_cls: 0.3907, d1.dn_loss_bbox: 0.5862, d2.dn_loss_cls: 0.3806, d2.dn_loss_bbox: 0.5527, d3.dn_loss_cls: 0.3705, d3.dn_loss_bbox: 0.5259, d4.dn_loss_cls: 0.3672, d4.dn_loss_bbox: 0.5167, loss: 9.9720, grad_norm: 47.6064
2025-10-13 12:38:03,377 - mmdet - INFO - Epoch [1][2600/4004]	lr: 4.217e-06, eta: 0:15:24, time: 0.640, data_time: 0.041, memory: 21587, loss_cls: 0.0866, loss_bbox: 0.5841, d0.loss_cls: 0.1072, d0.loss_bbox: 0.7411, d1.loss_cls: 0.0989, d1.loss_bbox: 0.6621, d2.loss_cls: 0.0902, d2.loss_bbox: 0.6250, d3.loss_cls: 0.0868, d3.loss_bbox: 0.5984, d4.loss_cls: 0.0868, d4.loss_bbox: 0.5862, dn_loss_cls: 0.3690, dn_loss_bbox: 0.5129, d0.dn_loss_cls: 0.4117, d0.dn_loss_bbox: 0.6476, d1.dn_loss_cls: 0.3935, d1.dn_loss_bbox: 0.5859, d2.dn_loss_cls: 0.3831, d2.dn_loss_bbox: 0.5529, d3.dn_loss_cls: 0.3729, d3.dn_loss_bbox: 0.5245, d4.dn_loss_cls: 0.3699, d4.dn_loss_bbox: 0.5154, loss: 9.9928, grad_norm: 46.9008
2025-10-13 12:38:35,943 - mmdet - INFO - Epoch [1][2650/4004]	lr: 3.982e-06, eta: 0:14:51, time: 0.651, data_time: 0.037, memory: 21587, loss_cls: 0.0866, loss_bbox: 0.5848, d0.loss_cls: 0.1070, d0.loss_bbox: 0.7429, d1.loss_cls: 0.0986, d1.loss_bbox: 0.6609, d2.loss_cls: 0.0900, d2.loss_bbox: 0.6231, d3.loss_cls: 0.0867, d3.loss_bbox: 0.5987, d4.loss_cls: 0.0865, d4.loss_bbox: 0.5885, dn_loss_cls: 0.3673, dn_loss_bbox: 0.5133, d0.dn_loss_cls: 0.4097, d0.dn_loss_bbox: 0.6470, d1.dn_loss_cls: 0.3913, d1.dn_loss_bbox: 0.5839, d2.dn_loss_cls: 0.3809, d2.dn_loss_bbox: 0.5511, d3.dn_loss_cls: 0.3710, d3.dn_loss_bbox: 0.5248, d4.dn_loss_cls: 0.3680, d4.dn_loss_bbox: 0.5160, loss: 9.9783, grad_norm: 49.0591
2025-10-13 12:39:08,461 - mmdet - INFO - Epoch [1][2700/4004]	lr: 3.747e-06, eta: 0:14:18, time: 0.650, data_time: 0.037, memory: 21587, loss_cls: 0.0842, loss_bbox: 0.5895, d0.loss_cls: 0.1049, d0.loss_bbox: 0.7434, d1.loss_cls: 0.0966, d1.loss_bbox: 0.6634, d2.loss_cls: 0.0880, d2.loss_bbox: 0.6273, d3.loss_cls: 0.0845, d3.loss_bbox: 0.6025, d4.loss_cls: 0.0844, d4.loss_bbox: 0.5918, dn_loss_cls: 0.3687, dn_loss_bbox: 0.5217, d0.dn_loss_cls: 0.4111, d0.dn_loss_bbox: 0.6569, d1.dn_loss_cls: 0.3922, d1.dn_loss_bbox: 0.5933, d2.dn_loss_cls: 0.3828, d2.dn_loss_bbox: 0.5610, d3.dn_loss_cls: 0.3725, d3.dn_loss_bbox: 0.5336, d4.dn_loss_cls: 0.3694, d4.dn_loss_bbox: 0.5243, loss: 10.0477, grad_norm: 49.8795
2025-10-13 12:39:40,487 - mmdet - INFO - Epoch [1][2750/4004]	lr: 3.514e-06, eta: 0:13:45, time: 0.641, data_time: 0.042, memory: 21587, loss_cls: 0.0858, loss_bbox: 0.5897, d0.loss_cls: 0.1058, d0.loss_bbox: 0.7449, d1.loss_cls: 0.0975, d1.loss_bbox: 0.6634, d2.loss_cls: 0.0894, d2.loss_bbox: 0.6266, d3.loss_cls: 0.0861, d3.loss_bbox: 0.6033, d4.loss_cls: 0.0858, d4.loss_bbox: 0.5922, dn_loss_cls: 0.3688, dn_loss_bbox: 0.5128, d0.dn_loss_cls: 0.4096, d0.dn_loss_bbox: 0.6454, d1.dn_loss_cls: 0.3921, d1.dn_loss_bbox: 0.5832, d2.dn_loss_cls: 0.3824, d2.dn_loss_bbox: 0.5513, d3.dn_loss_cls: 0.3729, d3.dn_loss_bbox: 0.5245, d4.dn_loss_cls: 0.3695, d4.dn_loss_bbox: 0.5155, loss: 9.9990, grad_norm: 49.5194
2025-10-13 12:40:12,534 - mmdet - INFO - Epoch [1][2800/4004]	lr: 3.283e-06, eta: 0:13:11, time: 0.641, data_time: 0.041, memory: 21587, loss_cls: 0.0856, loss_bbox: 0.5835, d0.loss_cls: 0.1070, d0.loss_bbox: 0.7431, d1.loss_cls: 0.0982, d1.loss_bbox: 0.6612, d2.loss_cls: 0.0894, d2.loss_bbox: 0.6237, d3.loss_cls: 0.0857, d3.loss_bbox: 0.5982, d4.loss_cls: 0.0857, d4.loss_bbox: 0.5860, dn_loss_cls: 0.3652, dn_loss_bbox: 0.5097, d0.dn_loss_cls: 0.4076, d0.dn_loss_bbox: 0.6460, d1.dn_loss_cls: 0.3890, d1.dn_loss_bbox: 0.5832, d2.dn_loss_cls: 0.3791, d2.dn_loss_bbox: 0.5500, d3.dn_loss_cls: 0.3690, d3.dn_loss_bbox: 0.5216, d4.dn_loss_cls: 0.3659, d4.dn_loss_bbox: 0.5122, loss: 9.9457, grad_norm: 49.5715
2025-10-13 12:40:44,844 - mmdet - INFO - Epoch [1][2850/4004]	lr: 3.055e-06, eta: 0:12:38, time: 0.646, data_time: 0.041, memory: 21587, loss_cls: 0.0848, loss_bbox: 0.5830, d0.loss_cls: 0.1056, d0.loss_bbox: 0.7389, d1.loss_cls: 0.0970, d1.loss_bbox: 0.6574, d2.loss_cls: 0.0887, d2.loss_bbox: 0.6203, d3.loss_cls: 0.0850, d3.loss_bbox: 0.5963, d4.loss_cls: 0.0850, d4.loss_bbox: 0.5842, dn_loss_cls: 0.3660, dn_loss_bbox: 0.5102, d0.dn_loss_cls: 0.4084, d0.dn_loss_bbox: 0.6439, d1.dn_loss_cls: 0.3904, d1.dn_loss_bbox: 0.5825, d2.dn_loss_cls: 0.3800, d2.dn_loss_bbox: 0.5496, d3.dn_loss_cls: 0.3698, d3.dn_loss_bbox: 0.5220, d4.dn_loss_cls: 0.3667, d4.dn_loss_bbox: 0.5128, loss: 9.9284, grad_norm: 42.8137
2025-10-13 12:41:17,162 - mmdet - INFO - Epoch [1][2900/4004]	lr: 2.831e-06, eta: 0:12:05, time: 0.646, data_time: 0.041, memory: 21587, loss_cls: 0.0870, loss_bbox: 0.5833, d0.loss_cls: 0.1079, d0.loss_bbox: 0.7382, d1.loss_cls: 0.0996, d1.loss_bbox: 0.6581, d2.loss_cls: 0.0909, d2.loss_bbox: 0.6201, d3.loss_cls: 0.0873, d3.loss_bbox: 0.5962, d4.loss_cls: 0.0872, d4.loss_bbox: 0.5860, dn_loss_cls: 0.3661, dn_loss_bbox: 0.5082, d0.dn_loss_cls: 0.4083, d0.dn_loss_bbox: 0.6410, d1.dn_loss_cls: 0.3899, d1.dn_loss_bbox: 0.5797, d2.dn_loss_cls: 0.3798, d2.dn_loss_bbox: 0.5471, d3.dn_loss_cls: 0.3699, d3.dn_loss_bbox: 0.5199, d4.dn_loss_cls: 0.3669, d4.dn_loss_bbox: 0.5108, loss: 9.9295, grad_norm: 50.4930
2025-10-13 12:41:49,324 - mmdet - INFO - Epoch [1][2950/4004]	lr: 2.611e-06, eta: 0:11:32, time: 0.643, data_time: 0.041, memory: 21587, loss_cls: 0.0858, loss_bbox: 0.5787, d0.loss_cls: 0.1066, d0.loss_bbox: 0.7361, d1.loss_cls: 0.0979, d1.loss_bbox: 0.6558, d2.loss_cls: 0.0895, d2.loss_bbox: 0.6182, d3.loss_cls: 0.0861, d3.loss_bbox: 0.5911, d4.loss_cls: 0.0861, d4.loss_bbox: 0.5804, dn_loss_cls: 0.3652, dn_loss_bbox: 0.5096, d0.dn_loss_cls: 0.4082, d0.dn_loss_bbox: 0.6458, d1.dn_loss_cls: 0.3897, d1.dn_loss_bbox: 0.5822, d2.dn_loss_cls: 0.3791, d2.dn_loss_bbox: 0.5489, d3.dn_loss_cls: 0.3693, d3.dn_loss_bbox: 0.5216, d4.dn_loss_cls: 0.3660, d4.dn_loss_bbox: 0.5122, loss: 9.9100, grad_norm: 42.4619
2025-10-13 12:42:21,434 - mmdet - INFO - Exp name: cmt_aqr_voxel0100_r50_800x320_cbgs.py
2025-10-13 12:42:21,434 - mmdet - INFO - Epoch [1][3000/4004]	lr: 2.395e-06, eta: 0:10:59, time: 0.642, data_time: 0.041, memory: 21587, loss_cls: 0.0857, loss_bbox: 0.5857, d0.loss_cls: 0.1061, d0.loss_bbox: 0.7417, d1.loss_cls: 0.0973, d1.loss_bbox: 0.6621, d2.loss_cls: 0.0895, d2.loss_bbox: 0.6230, d3.loss_cls: 0.0859, d3.loss_bbox: 0.6000, d4.loss_cls: 0.0857, d4.loss_bbox: 0.5884, dn_loss_cls: 0.3678, dn_loss_bbox: 0.5148, d0.dn_loss_cls: 0.4104, d0.dn_loss_bbox: 0.6493, d1.dn_loss_cls: 0.3920, d1.dn_loss_bbox: 0.5869, d2.dn_loss_cls: 0.3816, d2.dn_loss_bbox: 0.5531, d3.dn_loss_cls: 0.3717, d3.dn_loss_bbox: 0.5264, d4.dn_loss_cls: 0.3685, d4.dn_loss_bbox: 0.5171, loss: 9.9908, grad_norm: 46.1085
2025-10-13 12:42:53,532 - mmdet - INFO - Epoch [1][3050/4004]	lr: 2.186e-06, eta: 0:10:26, time: 0.642, data_time: 0.042, memory: 21587, loss_cls: 0.0858, loss_bbox: 0.5922, d0.loss_cls: 0.1060, d0.loss_bbox: 0.7511, d1.loss_cls: 0.0978, d1.loss_bbox: 0.6704, d2.loss_cls: 0.0897, d2.loss_bbox: 0.6314, d3.loss_cls: 0.0861, d3.loss_bbox: 0.6050, d4.loss_cls: 0.0858, d4.loss_bbox: 0.5939, dn_loss_cls: 0.3695, dn_loss_bbox: 0.5154, d0.dn_loss_cls: 0.4113, d0.dn_loss_bbox: 0.6514, d1.dn_loss_cls: 0.3935, d1.dn_loss_bbox: 0.5879, d2.dn_loss_cls: 0.3836, d2.dn_loss_bbox: 0.5544, d3.dn_loss_cls: 0.3735, d3.dn_loss_bbox: 0.5271, d4.dn_loss_cls: 0.3701, d4.dn_loss_bbox: 0.5180, loss: 10.0510, grad_norm: 56.8992
2025-10-13 12:43:25,553 - mmdet - INFO - Epoch [1][3100/4004]	lr: 1.983e-06, eta: 0:09:53, time: 0.640, data_time: 0.042, memory: 21587, loss_cls: 0.0864, loss_bbox: 0.5921, d0.loss_cls: 0.1065, d0.loss_bbox: 0.7521, d1.loss_cls: 0.0985, d1.loss_bbox: 0.6699, d2.loss_cls: 0.0902, d2.loss_bbox: 0.6317, d3.loss_cls: 0.0865, d3.loss_bbox: 0.6059, d4.loss_cls: 0.0865, d4.loss_bbox: 0.5942, dn_loss_cls: 0.3680, dn_loss_bbox: 0.5190, d0.dn_loss_cls: 0.4112, d0.dn_loss_bbox: 0.6587, d1.dn_loss_cls: 0.3925, d1.dn_loss_bbox: 0.5919, d2.dn_loss_cls: 0.3825, d2.dn_loss_bbox: 0.5577, d3.dn_loss_cls: 0.3722, d3.dn_loss_bbox: 0.5309, d4.dn_loss_cls: 0.3687, d4.dn_loss_bbox: 0.5217, loss: 10.0752, grad_norm: 52.3453
2025-10-13 12:43:57,633 - mmdet - INFO - Epoch [1][3150/4004]	lr: 1.786e-06, eta: 0:09:20, time: 0.642, data_time: 0.041, memory: 21587, loss_cls: 0.0876, loss_bbox: 0.5838, d0.loss_cls: 0.1085, d0.loss_bbox: 0.7454, d1.loss_cls: 0.0999, d1.loss_bbox: 0.6644, d2.loss_cls: 0.0913, d2.loss_bbox: 0.6234, d3.loss_cls: 0.0877, d3.loss_bbox: 0.5985, d4.loss_cls: 0.0878, d4.loss_bbox: 0.5858, dn_loss_cls: 0.3664, dn_loss_bbox: 0.5113, d0.dn_loss_cls: 0.4094, d0.dn_loss_bbox: 0.6509, d1.dn_loss_cls: 0.3909, d1.dn_loss_bbox: 0.5860, d2.dn_loss_cls: 0.3802, d2.dn_loss_bbox: 0.5519, d3.dn_loss_cls: 0.3703, d3.dn_loss_bbox: 0.5237, d4.dn_loss_cls: 0.3671, d4.dn_loss_bbox: 0.5138, loss: 9.9860, grad_norm: 45.0297
2025-10-13 12:44:30,257 - mmdet - INFO - Epoch [1][3200/4004]	lr: 1.598e-06, eta: 0:08:47, time: 0.652, data_time: 0.039, memory: 21587, loss_cls: 0.0849, loss_bbox: 0.5834, d0.loss_cls: 0.1052, d0.loss_bbox: 0.7414, d1.loss_cls: 0.0971, d1.loss_bbox: 0.6607, d2.loss_cls: 0.0884, d2.loss_bbox: 0.6222, d3.loss_cls: 0.0851, d3.loss_bbox: 0.5969, d4.loss_cls: 0.0849, d4.loss_bbox: 0.5857, dn_loss_cls: 0.3639, dn_loss_bbox: 0.5083, d0.dn_loss_cls: 0.4060, d0.dn_loss_bbox: 0.6435, d1.dn_loss_cls: 0.3881, d1.dn_loss_bbox: 0.5809, d2.dn_loss_cls: 0.3777, d2.dn_loss_bbox: 0.5475, d3.dn_loss_cls: 0.3680, d3.dn_loss_bbox: 0.5202, d4.dn_loss_cls: 0.3646, d4.dn_loss_bbox: 0.5109, loss: 9.9154, grad_norm: 50.6820
2025-10-13 12:45:02,917 - mmdet - INFO - Epoch [1][3250/4004]	lr: 1.417e-06, eta: 0:08:14, time: 0.653, data_time: 0.038, memory: 21587, loss_cls: 0.0859, loss_bbox: 0.5891, d0.loss_cls: 0.1064, d0.loss_bbox: 0.7485, d1.loss_cls: 0.0977, d1.loss_bbox: 0.6663, d2.loss_cls: 0.0894, d2.loss_bbox: 0.6282, d3.loss_cls: 0.0862, d3.loss_bbox: 0.6017, d4.loss_cls: 0.0860, d4.loss_bbox: 0.5913, dn_loss_cls: 0.3672, dn_loss_bbox: 0.5131, d0.dn_loss_cls: 0.4098, d0.dn_loss_bbox: 0.6493, d1.dn_loss_cls: 0.3915, d1.dn_loss_bbox: 0.5860, d2.dn_loss_cls: 0.3815, d2.dn_loss_bbox: 0.5528, d3.dn_loss_cls: 0.3714, d3.dn_loss_bbox: 0.5252, d4.dn_loss_cls: 0.3679, d4.dn_loss_bbox: 0.5156, loss: 10.0078, grad_norm: 47.5122
2025-10-13 12:45:35,405 - mmdet - INFO - Epoch [1][3300/4004]	lr: 1.246e-06, eta: 0:07:41, time: 0.650, data_time: 0.037, memory: 21587, loss_cls: 0.0847, loss_bbox: 0.5915, d0.loss_cls: 0.1045, d0.loss_bbox: 0.7534, d1.loss_cls: 0.0964, d1.loss_bbox: 0.6695, d2.loss_cls: 0.0885, d2.loss_bbox: 0.6306, d3.loss_cls: 0.0851, d3.loss_bbox: 0.6035, d4.loss_cls: 0.0848, d4.loss_bbox: 0.5934, dn_loss_cls: 0.3680, dn_loss_bbox: 0.5169, d0.dn_loss_cls: 0.4121, d0.dn_loss_bbox: 0.6581, d1.dn_loss_cls: 0.3928, d1.dn_loss_bbox: 0.5924, d2.dn_loss_cls: 0.3827, d2.dn_loss_bbox: 0.5582, d3.dn_loss_cls: 0.3723, d3.dn_loss_bbox: 0.5291, d4.dn_loss_cls: 0.3687, d4.dn_loss_bbox: 0.5197, loss: 10.0571, grad_norm: 46.2712
2025-10-13 12:46:07,730 - mmdet - INFO - Epoch [1][3350/4004]	lr: 1.083e-06, eta: 0:07:08, time: 0.647, data_time: 0.040, memory: 21587, loss_cls: 0.0881, loss_bbox: 0.5856, d0.loss_cls: 0.1087, d0.loss_bbox: 0.7453, d1.loss_cls: 0.1001, d1.loss_bbox: 0.6637, d2.loss_cls: 0.0919, d2.loss_bbox: 0.6242, d3.loss_cls: 0.0882, d3.loss_bbox: 0.6004, d4.loss_cls: 0.0883, d4.loss_bbox: 0.5881, dn_loss_cls: 0.3669, dn_loss_bbox: 0.5114, d0.dn_loss_cls: 0.4104, d0.dn_loss_bbox: 0.6486, d1.dn_loss_cls: 0.3919, d1.dn_loss_bbox: 0.5839, d2.dn_loss_cls: 0.3816, d2.dn_loss_bbox: 0.5510, d3.dn_loss_cls: 0.3709, d3.dn_loss_bbox: 0.5232, d4.dn_loss_cls: 0.3675, d4.dn_loss_bbox: 0.5140, loss: 9.9941, grad_norm: 45.6484
2025-10-13 12:46:39,791 - mmdet - INFO - Epoch [1][3400/4004]	lr: 9.304e-07, eta: 0:06:35, time: 0.641, data_time: 0.041, memory: 21587, loss_cls: 0.0866, loss_bbox: 0.5940, d0.loss_cls: 0.1070, d0.loss_bbox: 0.7540, d1.loss_cls: 0.0984, d1.loss_bbox: 0.6721, d2.loss_cls: 0.0903, d2.loss_bbox: 0.6328, d3.loss_cls: 0.0870, d3.loss_bbox: 0.6078, d4.loss_cls: 0.0867, d4.loss_bbox: 0.5958, dn_loss_cls: 0.3689, dn_loss_bbox: 0.5142, d0.dn_loss_cls: 0.4103, d0.dn_loss_bbox: 0.6512, d1.dn_loss_cls: 0.3925, d1.dn_loss_bbox: 0.5856, d2.dn_loss_cls: 0.3825, d2.dn_loss_bbox: 0.5527, d3.dn_loss_cls: 0.3727, d3.dn_loss_bbox: 0.5263, d4.dn_loss_cls: 0.3697, d4.dn_loss_bbox: 0.5165, loss: 10.0557, grad_norm: 44.4192
2025-10-13 12:47:12,142 - mmdet - INFO - Epoch [1][3450/4004]	lr: 7.880e-07, eta: 0:06:03, time: 0.647, data_time: 0.038, memory: 21587, loss_cls: 0.0860, loss_bbox: 0.5860, d0.loss_cls: 0.1068, d0.loss_bbox: 0.7494, d1.loss_cls: 0.0982, d1.loss_bbox: 0.6643, d2.loss_cls: 0.0897, d2.loss_bbox: 0.6281, d3.loss_cls: 0.0862, d3.loss_bbox: 0.6001, d4.loss_cls: 0.0860, d4.loss_bbox: 0.5888, dn_loss_cls: 0.3645, dn_loss_bbox: 0.5142, d0.dn_loss_cls: 0.4073, d0.dn_loss_bbox: 0.6555, d1.dn_loss_cls: 0.3882, d1.dn_loss_bbox: 0.5903, d2.dn_loss_cls: 0.3778, d2.dn_loss_bbox: 0.5547, d3.dn_loss_cls: 0.3685, d3.dn_loss_bbox: 0.5264, d4.dn_loss_cls: 0.3651, d4.dn_loss_bbox: 0.5168, loss: 9.9989, grad_norm: 46.8250
2025-10-13 12:47:44,092 - mmdet - INFO - Epoch [1][3500/4004]	lr: 6.563e-07, eta: 0:05:30, time: 0.639, data_time: 0.041, memory: 21587, loss_cls: 0.0854, loss_bbox: 0.5883, d0.loss_cls: 0.1055, d0.loss_bbox: 0.7480, d1.loss_cls: 0.0972, d1.loss_bbox: 0.6679, d2.loss_cls: 0.0892, d2.loss_bbox: 0.6284, d3.loss_cls: 0.0856, d3.loss_bbox: 0.6031, d4.loss_cls: 0.0855, d4.loss_bbox: 0.5914, dn_loss_cls: 0.3658, dn_loss_bbox: 0.5137, d0.dn_loss_cls: 0.4098, d0.dn_loss_bbox: 0.6523, d1.dn_loss_cls: 0.3907, d1.dn_loss_bbox: 0.5873, d2.dn_loss_cls: 0.3808, d2.dn_loss_bbox: 0.5542, d3.dn_loss_cls: 0.3704, d3.dn_loss_bbox: 0.5257, d4.dn_loss_cls: 0.3666, d4.dn_loss_bbox: 0.5163, loss: 10.0089, grad_norm: 45.7873
2025-10-13 12:48:16,158 - mmdet - INFO - Epoch [1][3550/4004]	lr: 5.357e-07, eta: 0:04:57, time: 0.641, data_time: 0.042, memory: 21587, loss_cls: 0.0876, loss_bbox: 0.5962, d0.loss_cls: 0.1081, d0.loss_bbox: 0.7610, d1.loss_cls: 0.0998, d1.loss_bbox: 0.6755, d2.loss_cls: 0.0916, d2.loss_bbox: 0.6354, d3.loss_cls: 0.0879, d3.loss_bbox: 0.6103, d4.loss_cls: 0.0877, d4.loss_bbox: 0.5993, dn_loss_cls: 0.3681, dn_loss_bbox: 0.5192, d0.dn_loss_cls: 0.4106, d0.dn_loss_bbox: 0.6580, d1.dn_loss_cls: 0.3927, d1.dn_loss_bbox: 0.5938, d2.dn_loss_cls: 0.3821, d2.dn_loss_bbox: 0.5597, d3.dn_loss_cls: 0.3720, d3.dn_loss_bbox: 0.5312, d4.dn_loss_cls: 0.3689, d4.dn_loss_bbox: 0.5217, loss: 10.1184, grad_norm: 52.1279
2025-10-13 12:48:48,081 - mmdet - INFO - Epoch [1][3600/4004]	lr: 4.266e-07, eta: 0:04:24, time: 0.638, data_time: 0.041, memory: 21587, loss_cls: 0.0854, loss_bbox: 0.5860, d0.loss_cls: 0.1062, d0.loss_bbox: 0.7483, d1.loss_cls: 0.0976, d1.loss_bbox: 0.6653, d2.loss_cls: 0.0890, d2.loss_bbox: 0.6265, d3.loss_cls: 0.0857, d3.loss_bbox: 0.6002, d4.loss_cls: 0.0853, d4.loss_bbox: 0.5899, dn_loss_cls: 0.3656, dn_loss_bbox: 0.5141, d0.dn_loss_cls: 0.4086, d0.dn_loss_bbox: 0.6514, d1.dn_loss_cls: 0.3893, d1.dn_loss_bbox: 0.5880, d2.dn_loss_cls: 0.3795, d2.dn_loss_bbox: 0.5544, d3.dn_loss_cls: 0.3697, d3.dn_loss_bbox: 0.5261, d4.dn_loss_cls: 0.3664, d4.dn_loss_bbox: 0.5166, loss: 9.9952, grad_norm: 42.6725
2025-10-13 12:49:20,141 - mmdet - INFO - Epoch [1][3650/4004]	lr: 3.294e-07, eta: 0:03:51, time: 0.641, data_time: 0.042, memory: 21587, loss_cls: 0.0851, loss_bbox: 0.5919, d0.loss_cls: 0.1056, d0.loss_bbox: 0.7540, d1.loss_cls: 0.0974, d1.loss_bbox: 0.6694, d2.loss_cls: 0.0890, d2.loss_bbox: 0.6303, d3.loss_cls: 0.0855, d3.loss_bbox: 0.6052, d4.loss_cls: 0.0851, d4.loss_bbox: 0.5955, dn_loss_cls: 0.3672, dn_loss_bbox: 0.5122, d0.dn_loss_cls: 0.4101, d0.dn_loss_bbox: 0.6523, d1.dn_loss_cls: 0.3917, d1.dn_loss_bbox: 0.5868, d2.dn_loss_cls: 0.3817, d2.dn_loss_bbox: 0.5527, d3.dn_loss_cls: 0.3715, d3.dn_loss_bbox: 0.5242, d4.dn_loss_cls: 0.3681, d4.dn_loss_bbox: 0.5149, loss: 10.0275, grad_norm: 44.5933
2025-10-13 12:49:52,173 - mmdet - INFO - Epoch [1][3700/4004]	lr: 2.444e-07, eta: 0:03:18, time: 0.641, data_time: 0.042, memory: 21587, loss_cls: 0.0863, loss_bbox: 0.5891, d0.loss_cls: 0.1067, d0.loss_bbox: 0.7449, d1.loss_cls: 0.0985, d1.loss_bbox: 0.6637, d2.loss_cls: 0.0900, d2.loss_bbox: 0.6261, d3.loss_cls: 0.0865, d3.loss_bbox: 0.6019, d4.loss_cls: 0.0863, d4.loss_bbox: 0.5923, dn_loss_cls: 0.3685, dn_loss_bbox: 0.5163, d0.dn_loss_cls: 0.4107, d0.dn_loss_bbox: 0.6544, d1.dn_loss_cls: 0.3926, d1.dn_loss_bbox: 0.5893, d2.dn_loss_cls: 0.3825, d2.dn_loss_bbox: 0.5560, d3.dn_loss_cls: 0.3725, d3.dn_loss_bbox: 0.5281, d4.dn_loss_cls: 0.3692, d4.dn_loss_bbox: 0.5189, loss: 10.0312, grad_norm: 46.8450
2025-10-13 12:50:24,232 - mmdet - INFO - Epoch [1][3750/4004]	lr: 1.717e-07, eta: 0:02:46, time: 0.641, data_time: 0.041, memory: 21587, loss_cls: 0.0857, loss_bbox: 0.5848, d0.loss_cls: 0.1057, d0.loss_bbox: 0.7436, d1.loss_cls: 0.0976, d1.loss_bbox: 0.6608, d2.loss_cls: 0.0893, d2.loss_bbox: 0.6246, d3.loss_cls: 0.0858, d3.loss_bbox: 0.5995, d4.loss_cls: 0.0858, d4.loss_bbox: 0.5878, dn_loss_cls: 0.3664, dn_loss_bbox: 0.5122, d0.dn_loss_cls: 0.4089, d0.dn_loss_bbox: 0.6470, d1.dn_loss_cls: 0.3905, d1.dn_loss_bbox: 0.5838, d2.dn_loss_cls: 0.3803, d2.dn_loss_bbox: 0.5511, d3.dn_loss_cls: 0.3705, d3.dn_loss_bbox: 0.5238, d4.dn_loss_cls: 0.3671, d4.dn_loss_bbox: 0.5147, loss: 9.9676, grad_norm: 42.4065
2025-10-13 12:50:56,475 - mmdet - INFO - Epoch [1][3800/4004]	lr: 1.118e-07, eta: 0:02:13, time: 0.645, data_time: 0.042, memory: 21587, loss_cls: 0.0865, loss_bbox: 0.5877, d0.loss_cls: 0.1069, d0.loss_bbox: 0.7471, d1.loss_cls: 0.0984, d1.loss_bbox: 0.6640, d2.loss_cls: 0.0901, d2.loss_bbox: 0.6268, d3.loss_cls: 0.0867, d3.loss_bbox: 0.6009, d4.loss_cls: 0.0867, d4.loss_bbox: 0.5891, dn_loss_cls: 0.3678, dn_loss_bbox: 0.5132, d0.dn_loss_cls: 0.4101, d0.dn_loss_bbox: 0.6492, d1.dn_loss_cls: 0.3925, d1.dn_loss_bbox: 0.5861, d2.dn_loss_cls: 0.3821, d2.dn_loss_bbox: 0.5530, d3.dn_loss_cls: 0.3718, d3.dn_loss_bbox: 0.5253, d4.dn_loss_cls: 0.3685, d4.dn_loss_bbox: 0.5157, loss: 10.0064, grad_norm: 48.6042
2025-10-13 12:51:28,518 - mmdet - INFO - Epoch [1][3850/4004]	lr: 6.461e-08, eta: 0:01:40, time: 0.641, data_time: 0.042, memory: 21587, loss_cls: 0.0855, loss_bbox: 0.5867, d0.loss_cls: 0.1060, d0.loss_bbox: 0.7473, d1.loss_cls: 0.0976, d1.loss_bbox: 0.6647, d2.loss_cls: 0.0890, d2.loss_bbox: 0.6284, d3.loss_cls: 0.0856, d3.loss_bbox: 0.6017, d4.loss_cls: 0.0856, d4.loss_bbox: 0.5899, dn_loss_cls: 0.3670, dn_loss_bbox: 0.5170, d0.dn_loss_cls: 0.4104, d0.dn_loss_bbox: 0.6535, d1.dn_loss_cls: 0.3913, d1.dn_loss_bbox: 0.5899, d2.dn_loss_cls: 0.3809, d2.dn_loss_bbox: 0.5564, d3.dn_loss_cls: 0.3712, d3.dn_loss_bbox: 0.5286, d4.dn_loss_cls: 0.3678, d4.dn_loss_bbox: 0.5196, loss: 10.0217, grad_norm: 42.2266
2025-10-13 12:52:00,533 - mmdet - INFO - Epoch [1][3900/4004]	lr: 3.045e-08, eta: 0:01:07, time: 0.640, data_time: 0.041, memory: 21587, loss_cls: 0.0853, loss_bbox: 0.5862, d0.loss_cls: 0.1062, d0.loss_bbox: 0.7460, d1.loss_cls: 0.0978, d1.loss_bbox: 0.6661, d2.loss_cls: 0.0895, d2.loss_bbox: 0.6243, d3.loss_cls: 0.0858, d3.loss_bbox: 0.6005, d4.loss_cls: 0.0854, d4.loss_bbox: 0.5894, dn_loss_cls: 0.3664, dn_loss_bbox: 0.5136, d0.dn_loss_cls: 0.4094, d0.dn_loss_bbox: 0.6506, d1.dn_loss_cls: 0.3905, d1.dn_loss_bbox: 0.5875, d2.dn_loss_cls: 0.3797, d2.dn_loss_bbox: 0.5532, d3.dn_loss_cls: 0.3702, d3.dn_loss_bbox: 0.5259, d4.dn_loss_cls: 0.3670, d4.dn_loss_bbox: 0.5163, loss: 9.9928, grad_norm: 46.4447
2025-10-13 12:52:33,073 - mmdet - INFO - Epoch [1][3950/4004]	lr: 9.376e-09, eta: 0:00:35, time: 0.651, data_time: 0.041, memory: 21587, loss_cls: 0.0872, loss_bbox: 0.5931, d0.loss_cls: 0.1075, d0.loss_bbox: 0.7570, d1.loss_cls: 0.0989, d1.loss_bbox: 0.6717, d2.loss_cls: 0.0907, d2.loss_bbox: 0.6322, d3.loss_cls: 0.0874, d3.loss_bbox: 0.6065, d4.loss_cls: 0.0872, d4.loss_bbox: 0.5955, dn_loss_cls: 0.3686, dn_loss_bbox: 0.5150, d0.dn_loss_cls: 0.4114, d0.dn_loss_bbox: 0.6528, d1.dn_loss_cls: 0.3939, d1.dn_loss_bbox: 0.5890, d2.dn_loss_cls: 0.3833, d2.dn_loss_bbox: 0.5550, d3.dn_loss_cls: 0.3727, d3.dn_loss_bbox: 0.5268, d4.dn_loss_cls: 0.3693, d4.dn_loss_bbox: 0.5175, loss: 10.0702, grad_norm: 47.1152
2025-10-13 12:53:05,435 - mmdet - INFO - Exp name: cmt_aqr_voxel0100_r50_800x320_cbgs.py
2025-10-13 12:53:05,435 - mmdet - INFO - Epoch [1][4000/4004]	lr: 1.466e-09, eta: 0:00:02, time: 0.647, data_time: 0.038, memory: 21587, loss_cls: 0.0856, loss_bbox: 0.5839, d0.loss_cls: 0.1066, d0.loss_bbox: 0.7389, d1.loss_cls: 0.0982, d1.loss_bbox: 0.6599, d2.loss_cls: 0.0895, d2.loss_bbox: 0.6197, d3.loss_cls: 0.0857, d3.loss_bbox: 0.5970, d4.loss_cls: 0.0856, d4.loss_bbox: 0.5866, dn_loss_cls: 0.3645, dn_loss_bbox: 0.5091, d0.dn_loss_cls: 0.4078, d0.dn_loss_bbox: 0.6433, d1.dn_loss_cls: 0.3890, d1.dn_loss_bbox: 0.5821, d2.dn_loss_cls: 0.3788, d2.dn_loss_bbox: 0.5485, d3.dn_loss_cls: 0.3690, d3.dn_loss_bbox: 0.5209, d4.dn_loss_cls: 0.3654, d4.dn_loss_bbox: 0.5116, loss: 9.9272, grad_norm: 46.5257
2025-10-13 12:53:08,326 - mmdet - INFO - Saving checkpoint at 1 epochs
[                                                  ] 0/6019, elapsed: 0s, ETA:/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
mAP: 0.6575                                          
mATE: 0.3353
mASE: 0.2493
mAOE: 0.3339
mAVE: 0.2715
mAAE: 0.1899
NDS: 0.6908
Eval time: 145.3s

Per-class results:
Object Class	AP	ATE	ASE	AOE	AVE	AAE
car	0.859	0.188	0.145	0.073	0.293	0.199
truck	0.609	0.349	0.179	0.122	0.246	0.220
bus	0.735	0.369	0.172	0.051	0.462	0.240
trailer	0.423	0.595	0.204	0.606	0.175	0.170
construction_vehicle	0.301	0.791	0.457	0.952	0.124	0.329
pedestrian	0.840	0.181	0.275	0.356	0.221	0.099
motorcycle	0.729	0.234	0.232	0.278	0.468	0.253
bicycle	0.641	0.192	0.255	0.508	0.183	0.009
traffic_cone	0.727	0.197	0.310	nan	nan	nan
barrier	0.711	0.257	0.264	0.058	nan	nan
2025-10-13 13:04:50,789 - mmdet - INFO - Exp name: cmt_aqr_voxel0100_r50_800x320_cbgs.py
2025-10-13 13:04:50,790 - mmdet - INFO - Epoch(val) [1][753]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7581, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8661, pts_bbox_NuScenes/car_AP_dist_2.0: 0.8972, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9138, pts_bbox_NuScenes/car_trans_err: 0.1881, pts_bbox_NuScenes/car_scale_err: 0.1449, pts_bbox_NuScenes/car_orient_err: 0.0735, pts_bbox_NuScenes/car_vel_err: 0.2933, pts_bbox_NuScenes/car_attr_err: 0.1991, pts_bbox_NuScenes/mATE: 0.3353, pts_bbox_NuScenes/mASE: 0.2493, pts_bbox_NuScenes/mAOE: 0.3339, pts_bbox_NuScenes/mAVE: 0.2715, pts_bbox_NuScenes/mAAE: 0.1899, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.3915, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.5985, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.7050, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7412, pts_bbox_NuScenes/truck_trans_err: 0.3489, pts_bbox_NuScenes/truck_scale_err: 0.1785, pts_bbox_NuScenes/truck_orient_err: 0.1220, pts_bbox_NuScenes/truck_vel_err: 0.2459, pts_bbox_NuScenes/truck_attr_err: 0.2198, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0328, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.1775, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.4357, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.5561, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.7906, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4568, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.9519, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1241, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.3292, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.4801, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7133, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8570, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.8907, pts_bbox_NuScenes/bus_trans_err: 0.3686, pts_bbox_NuScenes/bus_scale_err: 0.1720, pts_bbox_NuScenes/bus_orient_err: 0.0509, pts_bbox_NuScenes/bus_vel_err: 0.4617, pts_bbox_NuScenes/bus_attr_err: 0.2401, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.0977, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.3596, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5581, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6780, pts_bbox_NuScenes/trailer_trans_err: 0.5948, pts_bbox_NuScenes/trailer_scale_err: 0.2037, pts_bbox_NuScenes/trailer_orient_err: 0.6063, pts_bbox_NuScenes/trailer_vel_err: 0.1751, pts_bbox_NuScenes/trailer_attr_err: 0.1700, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.5690, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.7059, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7726, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.7977, pts_bbox_NuScenes/barrier_trans_err: 0.2571, pts_bbox_NuScenes/barrier_scale_err: 0.2640, pts_bbox_NuScenes/barrier_orient_err: 0.0583, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.6038, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7425, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7786, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.7899, pts_bbox_NuScenes/motorcycle_trans_err: 0.2342, pts_bbox_NuScenes/motorcycle_scale_err: 0.2324, pts_bbox_NuScenes/motorcycle_orient_err: 0.2779, pts_bbox_NuScenes/motorcycle_vel_err: 0.4678, pts_bbox_NuScenes/motorcycle_attr_err: 0.2533, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5823, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.6474, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.6603, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6739, pts_bbox_NuScenes/bicycle_trans_err: 0.1920, pts_bbox_NuScenes/bicycle_scale_err: 0.2554, pts_bbox_NuScenes/bicycle_orient_err: 0.5080, pts_bbox_NuScenes/bicycle_vel_err: 0.1830, pts_bbox_NuScenes/bicycle_attr_err: 0.0091, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.7754, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8356, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8654, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8826, pts_bbox_NuScenes/pedestrian_trans_err: 0.1815, pts_bbox_NuScenes/pedestrian_scale_err: 0.2751, pts_bbox_NuScenes/pedestrian_orient_err: 0.3564, pts_bbox_NuScenes/pedestrian_vel_err: 0.2213, pts_bbox_NuScenes/pedestrian_attr_err: 0.0988, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.6448, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.7135, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7570, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.7934, pts_bbox_NuScenes/traffic_cone_trans_err: 0.1969, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3101, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.6908, pts_bbox_NuScenes/mAP: 0.6575
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:70: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0005121231079101562 seconds
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 0, "group_rank": 0, "worker_id": "19660", "role": "default", "hostname": "pglkarasdosntxqy-make-6886fc6485-kv6qw", "state": "SUCCEEDED", "total_run_time": 3363, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [0], \"role_rank\": [0], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 1, "group_rank": 0, "worker_id": "19661", "role": "default", "hostname": "pglkarasdosntxqy-make-6886fc6485-kv6qw", "state": "SUCCEEDED", "total_run_time": 3363, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [1], \"role_rank\": [1], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 2, "group_rank": 0, "worker_id": "19662", "role": "default", "hostname": "pglkarasdosntxqy-make-6886fc6485-kv6qw", "state": "SUCCEEDED", "total_run_time": 3363, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [2], \"role_rank\": [2], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 3, "group_rank": 0, "worker_id": "19663", "role": "default", "hostname": "pglkarasdosntxqy-make-6886fc6485-kv6qw", "state": "SUCCEEDED", "total_run_time": 3363, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [3], \"role_rank\": [3], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 4, "group_rank": 0, "worker_id": "19664", "role": "default", "hostname": "pglkarasdosntxqy-make-6886fc6485-kv6qw", "state": "SUCCEEDED", "total_run_time": 3363, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [4], \"role_rank\": [4], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 5, "group_rank": 0, "worker_id": "19665", "role": "default", "hostname": "pglkarasdosntxqy-make-6886fc6485-kv6qw", "state": "SUCCEEDED", "total_run_time": 3363, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [5], \"role_rank\": [5], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 6, "group_rank": 0, "worker_id": "19666", "role": "default", "hostname": "pglkarasdosntxqy-make-6886fc6485-kv6qw", "state": "SUCCEEDED", "total_run_time": 3363, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [6], \"role_rank\": [6], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 7, "group_rank": 0, "worker_id": "19668", "role": "default", "hostname": "pglkarasdosntxqy-make-6886fc6485-kv6qw", "state": "SUCCEEDED", "total_run_time": 3363, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [7], \"role_rank\": [7], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "AGENT", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": null, "group_rank": 0, "worker_id": null, "role": "default", "hostname": "pglkarasdosntxqy-make-6886fc6485-kv6qw", "state": "SUCCEEDED", "total_run_time": 3363, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\"}", "agent_restarts": 0}}
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
