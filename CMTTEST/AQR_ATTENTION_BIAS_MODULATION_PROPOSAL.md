# AQR Attention Biasè°ƒåˆ¶æ–¹æ¡ˆè¯¦ç»†è®¾è®¡ ğŸ¯

## ğŸ“‹ æ–¹æ¡ˆæ¦‚è¿°

### æ ¸å¿ƒæ€æƒ³

**ä¸ä¿®æ”¹ç‰¹å¾å€¼ï¼Œé€šè¿‡Attention Mask/Biasæ¥æ§åˆ¶queryå¯¹ä¸åŒæ¨¡æ€ç‰¹å¾çš„å…³æ³¨åº¦**

```
åŸæ–¹æ¡ˆï¼ˆç‰¹å¾è°ƒåˆ¶ï¼‰ï¼š
  ç‰¹å¾æå– â†’ [æƒé‡å›¾Ã—ç‰¹å¾] â†’ Transformer â†’ é¢„æµ‹
  é—®é¢˜ï¼šæ”¹å˜äº†ç‰¹å¾å€¼ï¼ˆ1.0â†’1.5ï¼‰ï¼Œç ´åé¢„è®­ç»ƒåˆ†å¸ƒ

æ–°æ–¹æ¡ˆï¼ˆAttention Biasï¼‰ï¼š
  ç‰¹å¾æå– â†’ Transformer[å†…éƒ¨ç”¨biasè°ƒåˆ¶attention] â†’ é¢„æµ‹
  ä¼˜åŠ¿ï¼šç‰¹å¾å€¼ä¸å˜ï¼Œåªæ”¹å˜attentionæƒé‡åˆ†å¸ƒ
```

---

## ğŸ”¬ ç†è®ºåŸºç¡€

### Attentionæœºåˆ¶çš„æ•°å­¦åŸç†

```python
# æ ‡å‡†Attentionè®¡ç®—
Q = query @ W_q        # [num_queries, dim]
K = key @ W_k          # [num_features, dim]
V = value @ W_v        # [num_features, dim]

scores = Q @ K.T / sqrt(d)                    # [num_queries, num_features]
attention_weights = softmax(scores + mask)    # ğŸ”¥ maskåœ¨è¿™é‡Œèµ·ä½œç”¨
output = attention_weights @ V                # [num_queries, dim]
```

### Attention Mask/Biasçš„ä½œç”¨æœºåˆ¶

```
maskçš„å€¼åŸŸå’Œæ•ˆæœï¼š
- mask = 0         â†’ æ­£å¸¸attentionï¼ˆæƒé‡ä¸å˜ï¼‰
- mask = -inf      â†’ å®Œå…¨å±è”½ï¼ˆæƒé‡ä¸º0ï¼‰
- mask = -5.0      â†’ é™ä½å…³æ³¨åº¦ï¼ˆæƒé‡å‡å°ï¼‰â­ AQRç”¨
- mask = +5.0      â†’ å¢åŠ å…³æ³¨åº¦ï¼ˆæƒé‡å¢å¤§ï¼‰â­ AQRç”¨

å…³é”®ç‰¹æ€§ï¼š
1. âœ… ç»è¿‡softmaxå½’ä¸€åŒ–ï¼Œä¸ä¼šäº§ç”Ÿæç«¯å€¼
2. âœ… åªå½±å“ç›¸å¯¹æƒé‡ï¼Œä¸æ”¹å˜ç‰¹å¾å€¼
3. âœ… Flash AttentionåŸç”Ÿæ”¯æŒï¼Œæ— éœ€ä¿®æ”¹å†…éƒ¨
```

### ä¸ç‰¹å¾è°ƒåˆ¶çš„å¯¹æ¯”

```python
# æ–¹æ³•1ï¼šç‰¹å¾è°ƒåˆ¶ï¼ˆç°æœ‰æ–¹æ¡ˆï¼‰
modulated_features = original_features * weight_map
# é—®é¢˜ï¼š
# - å¦‚æœweight=1.5ï¼Œç‰¹å¾å€¼ä»1.0â†’1.5ï¼ˆç ´ååˆ†å¸ƒï¼‰
# - æ¨¡å‹å¯èƒ½"è®¤ä¸å‡º"è°ƒåˆ¶åçš„ç‰¹å¾
# - ç±»ä¼¼äºæŠŠ"ç»¿è‰²"çš„RGBå€¼æ”¹å˜äº†

# æ–¹æ³•2ï¼šAttention Biasï¼ˆæ–°æ–¹æ¡ˆï¼‰
attention_weights = softmax(scores + bias)
output = attention_weights @ original_features
# ä¼˜åŠ¿ï¼š
# - ç‰¹å¾å€¼å§‹ç»ˆä¿æŒåŸæ ·ï¼ˆ1.0è¿˜æ˜¯1.0ï¼‰
# - åªæ˜¯æ”¹å˜äº†"çœ‹è¿™ä¸ªç‰¹å¾çš„æƒé‡"
# - ç±»ä¼¼äºè°ƒæ•´"çœ‹ç»¿è‰²çš„æ³¨æ„åŠ›"ï¼Œè€Œä¸æ˜¯æ”¹å˜ç»¿è‰²æœ¬èº«
```

---

## ğŸ—ï¸ è¯¦ç»†è®¾è®¡

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CMT Head Forward                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  1. ç‰¹å¾æå–                                             â”‚
â”‚     â”œâ”€ BEVç‰¹å¾: [bs, 256, 180, 180]                    â”‚
â”‚     â””â”€ Cameraç‰¹å¾: [bs*6, 256, 40, 100]                â”‚
â”‚                                                          â”‚
â”‚  2. AQRæƒé‡ç”Ÿæˆ â­                                       â”‚
â”‚     â”œâ”€ Input: query_embed, memory, ref_points           â”‚
â”‚     â”œâ”€ Output: lidar_weights [bs, 900]                  â”‚
â”‚     â””â”€        camera_weights [bs, 900]                  â”‚
â”‚                                                          â”‚
â”‚  3. Attention Biasç”Ÿæˆ ğŸ”¥ æ ¸å¿ƒåˆ›æ–°                       â”‚
â”‚     â”œâ”€ å°†query-levelæƒé‡è½¬æ¢ä¸ºfeature-level bias        â”‚
â”‚     â”œâ”€ Input: lidar_weights, camera_weights             â”‚
â”‚     â””â”€ Output: attention_bias [bs, 900, 32400+24000]    â”‚
â”‚             (32400=180Ã—180 BEV, 24000=6Ã—40Ã—100 Camera)  â”‚
â”‚                                                          â”‚
â”‚  4. Transformerèåˆ                                      â”‚
â”‚     â”œâ”€ Input: BEVç‰¹å¾(ä¸å˜), Cameraç‰¹å¾(ä¸å˜)           â”‚
â”‚     â”œâ”€       attention_bias (ä¼ å…¥attn_mask)             â”‚
â”‚     â””â”€ Output: èåˆç‰¹å¾                                  â”‚
â”‚                                                          â”‚
â”‚  5. æ£€æµ‹å¤´é¢„æµ‹                                           â”‚
â”‚     â””â”€ å¤šä»»åŠ¡é¢„æµ‹                                        â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒæ¨¡å—1ï¼šAttention Biasç”Ÿæˆå™¨

```python
class AttentionBiasGenerator(nn.Module):
    """
    å°†query-levelçš„æ¨¡æ€æƒé‡è½¬æ¢ä¸ºattention-levelçš„bias
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æ¥æ”¶AQRç”Ÿæˆçš„queryæƒé‡ï¼ˆæ¯ä¸ªqueryä¸€ä¸ªlidar/cameraæƒé‡ï¼‰
    2. å°†æƒé‡æ˜ å°„ä¸ºattention biasï¼ˆæ§åˆ¶queryå¯¹ç‰¹å¾çš„å…³æ³¨åº¦ï¼‰
    3. æ”¯æŒå…¨å±€biaså’Œå±€éƒ¨biasä¸¤ç§ç­–ç•¥
    """
    
    def __init__(self, 
                 bev_feature_shape=(180, 180),
                 pers_feature_shape=(6, 40, 100),
                 bias_strength=5.0,           # ğŸ”¥ æ§åˆ¶biasçš„å¼ºåº¦
                 use_local_bias=False,        # ğŸ”¥ æ˜¯å¦ä½¿ç”¨å±€éƒ¨bias
                 local_window_size=15):       # å±€éƒ¨çª—å£å¤§å°
        super().__init__()
        self.bev_feature_shape = bev_feature_shape
        self.pers_feature_shape = pers_feature_shape
        self.bias_strength = bias_strength
        self.use_local_bias = use_local_bias
        self.local_window_size = local_window_size
        
        # è®¡ç®—ç‰¹å¾æ•°é‡
        self.bev_feat_num = bev_feature_shape[0] * bev_feature_shape[1]
        self.pers_feat_num = (pers_feature_shape[0] * 
                             pers_feature_shape[1] * 
                             pers_feature_shape[2])
        self.total_feat_num = self.bev_feat_num + self.pers_feat_num
        
    def forward(self, lidar_weights, camera_weights, 
                pts_idx=None, pts_pers_idx=None):
        """
        Args:
            lidar_weights: [bs, num_queries] LiDARæ¨¡æ€æƒé‡
            camera_weights: [bs, num_queries] Cameraæ¨¡æ€æƒé‡
            pts_idx: [bs, num_queries] queryåœ¨BEVç‰¹å¾å›¾ä¸­çš„ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
            pts_pers_idx: [bs, num_queries, 3] queryåœ¨é€è§†å›¾ä¸­çš„ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            attention_bias: [bs, num_queries, total_feat_num]
        """
        bs, num_queries = lidar_weights.shape
        
        if self.use_local_bias and pts_idx is not None:
            # ç­–ç•¥Aï¼šå±€éƒ¨åŒ–biasï¼ˆæ›´ç²¾ç»†ï¼‰
            return self._generate_local_bias(
                lidar_weights, camera_weights, 
                pts_idx, pts_pers_idx
            )
        else:
            # ç­–ç•¥Bï¼šå…¨å±€biasï¼ˆæ›´ç®€å•ï¼‰
            return self._generate_global_bias(
                lidar_weights, camera_weights
            )
    
    def _generate_global_bias(self, lidar_weights, camera_weights):
        """
        å…¨å±€biasç­–ç•¥ï¼šæ¯ä¸ªqueryå¯¹æ‰€æœ‰åŒæ¨¡æ€ç‰¹å¾æ–½åŠ ç›¸åŒçš„bias
        
        ä¼˜åŠ¿ï¼šç®€å•ï¼Œè®¡ç®—é«˜æ•ˆ
        åŠ£åŠ¿ï¼šä¸è€ƒè™‘ç©ºé—´ä½ç½®ä¿¡æ¯
        """
        bs, num_queries = lidar_weights.shape
        
        # åˆå§‹åŒ–biasï¼ˆå…¨0ï¼‰
        attention_bias = torch.zeros(
            bs, num_queries, self.total_feat_num,
            device=lidar_weights.device
        )
        
        # ğŸ”¥ æ ¸å¿ƒæ˜ å°„ï¼šå°†[0,1]çš„æƒé‡æ˜ å°„åˆ°[-Î±, +Î±]çš„bias
        # æƒé‡0.5 â†’ bias 0ï¼ˆä¸­ç«‹ï¼‰
        # æƒé‡1.0 â†’ bias +Î±ï¼ˆå¼ºçƒˆå…³æ³¨ï¼‰
        # æƒé‡0.0 â†’ bias -Î±ï¼ˆå¼ºçƒˆæŠ‘åˆ¶ï¼‰
        
        alpha = self.bias_strength
        
        # BEVéƒ¨åˆ†çš„bias
        bev_bias = (lidar_weights - 0.5) * 2 * alpha  # [bs, num_queries]
        attention_bias[:, :, :self.bev_feat_num] = bev_bias.unsqueeze(-1)
        
        # Cameraéƒ¨åˆ†çš„bias
        cam_bias = (camera_weights - 0.5) * 2 * alpha  # [bs, num_queries]
        attention_bias[:, :, self.bev_feat_num:] = cam_bias.unsqueeze(-1)
        
        return attention_bias
    
    def _generate_local_bias(self, lidar_weights, camera_weights,
                            pts_idx, pts_pers_idx):
        """
        å±€éƒ¨åŒ–biasç­–ç•¥ï¼šåªåœ¨queryçš„æŠ•å½±ä½ç½®é™„è¿‘æ–½åŠ bias
        
        ä¼˜åŠ¿ï¼šæ›´ç²¾ç»†ï¼Œç©ºé—´å¯¹åº”æ€§å¼º
        åŠ£åŠ¿ï¼šè®¡ç®—å¤æ‚åº¦è¾ƒé«˜
        
        ç±»ä¼¼äºæƒé‡å›¾æ¸²æŸ“ï¼Œä½†æ¸²æŸ“çš„æ˜¯biasè€Œéæƒé‡
        """
        bs, num_queries = lidar_weights.shape
        
        # åˆå§‹åŒ–bias
        attention_bias = torch.zeros(
            bs, num_queries, self.total_feat_num,
            device=lidar_weights.device
        )
        
        # ğŸ”¥ BEVéƒ¨åˆ†ï¼šåœ¨æŠ•å½±ä½ç½®é™„è¿‘æ–½åŠ å±€éƒ¨bias
        for b in range(bs):
            for q in range(num_queries):
                # è·å–queryåœ¨BEVä¸­çš„æŠ•å½±ä½ç½®
                center_idx = pts_idx[b, q]
                y = center_idx // self.bev_feature_shape[1]
                x = center_idx % self.bev_feature_shape[1]
                
                # è®¡ç®—å±€éƒ¨çª—å£
                window_size = self.local_window_size
                y_min = max(0, y - window_size // 2)
                y_max = min(self.bev_feature_shape[0], y + window_size // 2 + 1)
                x_min = max(0, x - window_size // 2)
                x_max = min(self.bev_feature_shape[1], x + window_size // 2 + 1)
                
                # ç”Ÿæˆå±€éƒ¨bias
                for yi in range(y_min, y_max):
                    for xi in range(x_min, x_max):
                        feat_idx = yi * self.bev_feature_shape[1] + xi
                        
                        # è·ç¦»è¡°å‡ï¼ˆå¯é€‰ï¼‰
                        dist = ((yi - y)**2 + (xi - x)**2)**0.5
                        decay = max(0, 1 - dist / (window_size / 2))
                        
                        # æ–½åŠ bias
                        bias_value = (lidar_weights[b, q] - 0.5) * 2 * self.bias_strength * decay
                        attention_bias[b, q, feat_idx] = bias_value
        
        # ğŸ”¥ Cameraéƒ¨åˆ†ï¼šç±»ä¼¼å¤„ç†
        # ï¼ˆä¸ºç®€æ´èµ·è§ï¼Œè¿™é‡Œçœç•¥ï¼Œå®é™…å®ç°ç±»ä¼¼BEVï¼‰
        
        return attention_bias
```

### æ ¸å¿ƒæ¨¡å—2ï¼šé›†æˆåˆ°CMT Head

```python
# åœ¨cmt_head.pyä¸­ä¿®æ”¹

class CmtHead(BaseModule):
    def __init__(self, ..., 
                 enable_aqr=False,
                 aqr_bias_strength=5.0,      # ğŸ”¥ æ–°å‚æ•°
                 aqr_use_local_bias=False,   # ğŸ”¥ æ–°å‚æ•°
                 **kwargs):
        super().__init__(**kwargs)
        
        # ... å…¶ä»–åˆå§‹åŒ– ...
        
        if enable_aqr:
            # AQRæƒé‡ç”Ÿæˆå™¨ï¼ˆä¿æŒä¸å˜ï¼‰
            self.aqr_weight_generator = AQRWeightGenerator(...)
            
            # ğŸ”¥ æ–°å¢ï¼šAttention Biasç”Ÿæˆå™¨
            self.attention_bias_generator = AttentionBiasGenerator(
                bev_feature_shape=(180, 180),
                pers_feature_shape=(6, 40, 100),
                bias_strength=aqr_bias_strength,
                use_local_bias=aqr_use_local_bias
            )
            
            # ğŸ”¥ åˆ é™¤ï¼šç‰¹å¾è°ƒåˆ¶å™¨ï¼ˆä¸å†éœ€è¦ï¼‰
            # self.feature_modulator = FeatureModulator(...)
    
    def _apply_aqr_modulation(self, x, x_img, reference_points, img_metas):
        """
        AQRè°ƒåˆ¶ï¼šç”Ÿæˆattention bias
        
        ä¿®æ”¹å‰ï¼šè¿”å›è°ƒåˆ¶åçš„ç‰¹å¾
        ä¿®æ”¹åï¼šè¿”å›attention biasï¼ˆç‰¹å¾ä¸å˜ï¼‰
        """
        
        # Step 1: å‡†å¤‡è¾“å…¥
        bs = x.shape[0] if x is not None else len(img_metas)
        
        # ç‰¹å¾å±•å¹³ï¼ˆç”¨äºAQR encoderï¼‰
        if x is not None:
            x_flat = x.flatten(2).permute(2, 0, 1)
        if x_img is not None:
            BN, C, H, W = x_img.shape
            x_img_flat = x_img.view(bs, BN//bs, C, H, W).permute(0, 1, 3, 4, 2).flatten(1, 3).permute(1, 0, 2)
        
        memory = torch.cat([x_flat, x_img_flat], dim=0) if x is not None and x_img is not None else None
        
        # Step 2: ç”Ÿæˆquery-levelæƒé‡ï¼ˆä¿æŒä¸å˜ï¼‰
        lidar_weights, camera_weights, _, projection_info = self.aqr_weight_generator(
            query_embed=self.query_embedding(reference_points),
            memory=memory,
            pos_embed=None,
            ref_points=reference_points,
            img_metas=img_metas
        )
        
        # Step 3: ğŸ”¥ æ ¸å¿ƒå˜åŒ–ï¼šç”Ÿæˆattention biasè€Œéè°ƒåˆ¶ç‰¹å¾
        attention_bias = self.attention_bias_generator(
            lidar_weights=lidar_weights,
            camera_weights=camera_weights,
            pts_idx=projection_info.get('pts_idx'),
            pts_pers_idx=projection_info.get('pts_pers_idx')
        )
        
        # Step 4: è¿”å›åŸå§‹ç‰¹å¾ + attention bias
        return x, x_img, attention_bias  # âœ… ç‰¹å¾ä¸å˜ï¼
    
    def forward_single(self, x, x_img, img_metas):
        """
        å•å°ºåº¦å‰å‘ä¼ æ’­
        """
        ret_dicts = []
        
        # å…±äº«å·ç§¯
        if x is not None:
            x = self.shared_conv(x)
        
        # å‚è€ƒç‚¹å’ŒDNå¤„ç†
        reference_points = self.reference_points.weight
        reference_points, attn_mask, mask_dict = self.prepare_for_dn(
            x.shape[0] if x is not None else len(img_metas), 
            reference_points, 
            img_metas
        )
        
        # ğŸ”¥ AQRå¤„ç†ï¼šç”Ÿæˆattention bias
        aqr_attention_bias = None
        if self.enable_aqr and x is not None and x_img is not None:
            x, x_img, aqr_attention_bias = self._apply_aqr_modulation(
                x, x_img, reference_points, img_metas
            )
            # âœ… å…³é”®ï¼šç‰¹å¾xå’Œx_imgä¿æŒåŸæ ·ï¼
        
        # ä½ç½®ç¼–ç ç”Ÿæˆï¼ˆä¸å˜ï¼‰
        if x is not None:
            mask = x.new_zeros(x.shape[0], x.shape[2], x.shape[3])
            bev_pos_embeds = self.bev_embedding(...)
        else:
            mask, bev_pos_embeds = None, None
        
        if x_img is not None:
            rv_pos_embeds = self._rv_pe(x_img, img_metas)
        else:
            rv_pos_embeds = None
        
        # æŸ¥è¯¢åµŒå…¥ç”Ÿæˆï¼ˆä¸å˜ï¼‰
        bev_query_embeds, rv_query_embeds = self.query_embed(reference_points, img_metas)
        query_embeds = bev_query_embeds
        if rv_query_embeds is not None:
            query_embeds = query_embeds + rv_query_embeds
        
        # ğŸ”¥ Transformerèåˆï¼šä¼ å…¥attention bias
        outs_dec, _ = self.transformer(
            x, x_img, query_embeds,
            bev_pos_embeds, rv_pos_embeds,
            attn_masks=attn_mask,
            aqr_attention_bias=aqr_attention_bias  # âœ… æ–°å¢å‚æ•°
        )
        
        # åç»­å¤„ç†ä¸å˜
        # ...
        
        return ret_dicts
```

### æ ¸å¿ƒæ¨¡å—3ï¼šTransformeræ¥å£ä¿®æ”¹

```python
# åœ¨cmt_transformer.pyä¸­ä¿®æ”¹

class CmtTransformer(BaseModule):
    def forward(self, x, x_img, query_embed, bev_pos_embed, rv_pos_embed, 
                attn_masks=None, aqr_attention_bias=None, reg_branch=None):
        """
        Args:
            aqr_attention_bias: [bs, num_queries, total_feat_num] 
                               AQRç”Ÿæˆçš„attention biasï¼ˆå¯é€‰ï¼‰
        """
        
        # Step 1: ç‰¹å¾å¤„ç†ï¼ˆä¸å˜ï¼‰
        bs, c, h, w = x.shape
        x = x.flatten(2).permute(2, 0, 1)  # [h*w, bs, c]
        
        BN, C, H, W = x_img.shape
        x_img = x_img.view(bs, BN//bs, C, H, W)
        x_img = x_img.permute(0, 1, 3, 4, 2).flatten(1, 3)
        x_img = x_img.permute(1, 0, 2)  # [views*h*w, bs, c]
        
        # Step 2: èåˆMemoryå’Œä½ç½®ç¼–ç ï¼ˆä¸å˜ï¼‰
        memory = torch.cat([x, x_img], dim=0)  # [total_feat, bs, c]
        pos_embed = torch.cat([bev_pos_embed, rv_pos_embed], dim=0)
        
        # Step 3: ğŸ”¥ å¤„ç†AQR attention bias
        if aqr_attention_bias is not None:
            # è½¬æ¢æ ¼å¼ï¼š[bs, num_queries, total_feat] â†’ [num_queries, bs, total_feat]
            aqr_bias = aqr_attention_bias.permute(1, 0, 2)
            
            # ğŸ”¥ å…³é”®ï¼šèåˆåˆ°attn_masksä¸­
            # attn_maskså¯èƒ½æ˜¯Noneã€Tensoræˆ–list
            if attn_masks is None:
                # åˆ›å»ºæ–°çš„mask listï¼š[cross_attn_mask, self_attn_mask]
                attn_masks = [aqr_bias, None]
            elif isinstance(attn_masks, list):
                # å·²ç»æ˜¯listï¼ŒåŠ åˆ°cross_attn_maskä¸Š
                if attn_masks[0] is None:
                    attn_masks[0] = aqr_bias
                else:
                    attn_masks[0] = attn_masks[0] + aqr_bias  # å åŠ bias
            else:
                # æ˜¯å•ä¸ªTensorï¼ŒåŠ ä¸Šå»
                attn_masks = attn_masks + aqr_bias
        
        # Step 4: åˆå§‹åŒ–æŸ¥è¯¢ï¼ˆä¸å˜ï¼‰
        target = torch.zeros_like(query_embed)
        target = target.permute(1, 0, 2)
        query_embed = query_embed.permute(1, 0, 2)
        
        # Step 5: Decoderå¤„ç†ï¼ˆå®Œå…¨ä¸å˜ï¼ï¼‰
        out_dec = self.decoder(
            query=target,
            key=memory,
            value=memory,
            key_pos=pos_embed,
            query_pos=query_embed,
            key_padding_mask=mask,
            attn_masks=attn_masks,  # âœ… åŒ…å«äº†AQR bias
            reg_branch=reg_branch,
        )
        
        out_dec = out_dec.transpose(1, 2)
        return out_dec, memory
```

---

## ğŸ›ï¸ å…³é”®è¶…å‚æ•°

### 1. `bias_strength` (Î±)

```
ä½œç”¨ï¼šæ§åˆ¶biasçš„å¼ºåº¦

å–å€¼èŒƒå›´ï¼š[1.0, 10.0]

æ•ˆæœï¼š
- Î± = 1.0   â†’ æ¸©å’Œè°ƒåˆ¶ï¼Œbias âˆˆ [-1, +1]
- Î± = 5.0   â†’ ä¸­ç­‰è°ƒåˆ¶ï¼Œbias âˆˆ [-5, +5]  â­ æ¨èèµ·ç‚¹
- Î± = 10.0  â†’ å¼ºçƒˆè°ƒåˆ¶ï¼Œbias âˆˆ [-10, +10]

æ•°å­¦å«ä¹‰ï¼š
  softmax([s1, s2] + [bias1, bias2])
  
  å½“bias=5.0ï¼Œscoreå·®å¼‚è¾ƒå°æ—¶ï¼š
  - åŸæœ¬ï¼šsoftmax([0.5, 0.6]) = [0.475, 0.525]
  - åŠ biasï¼šsoftmax([0.5+5, 0.6]) = [0.993, 0.007]  # æå¤§å¢å¼º
  
  å½“bias=1.0ï¼Œç›¸åŒæƒ…å†µï¼š
  - åŠ biasï¼šsoftmax([0.5+1, 0.6]) = [0.710, 0.290]  # æ¸©å’Œå¢å¼º
```

### 2. `use_local_bias`

```
ä½œç”¨ï¼šæ˜¯å¦ä½¿ç”¨å±€éƒ¨åŒ–biasï¼ˆåœ¨æŠ•å½±ä½ç½®é™„è¿‘æ–½åŠ biasï¼‰

å–å€¼ï¼šTrue / False

æ•ˆæœï¼š
- Falseï¼ˆå…¨å±€biasï¼‰ï¼š
  âœ… è®¡ç®—ç®€å•ï¼Œé€Ÿåº¦å¿«
  âœ… é€‚åˆç²—ç²’åº¦çš„æ¨¡æ€é€‰æ‹©
  âŒ ä¸è€ƒè™‘ç©ºé—´ä½ç½®ä¿¡æ¯
  
- Trueï¼ˆå±€éƒ¨biasï¼‰ï¼š
  âœ… ç©ºé—´å¯¹åº”æ€§å¼º
  âœ… æ›´ç²¾ç»†çš„æ§åˆ¶
  âŒ è®¡ç®—å¤æ‚åº¦é«˜
  âŒ éœ€è¦æŠ•å½±ç´¢å¼•ä¿¡æ¯

æ¨èï¼šå…ˆç”¨Falseå¿«é€ŸéªŒè¯ï¼Œæ•ˆæœå¥½å†å°è¯•True
```

### 3. `local_window_size`

```
ä½œç”¨ï¼šå±€éƒ¨biasçš„çª—å£å¤§å°ï¼ˆä»…åœ¨use_local_bias=Trueæ—¶æœ‰æ•ˆï¼‰

å–å€¼èŒƒå›´ï¼š[5, 25]

æ•ˆæœï¼š
- window_size = 5  â†’ å°çª—å£ï¼Œç²¾ç¡®å®šä½
- window_size = 15 â†’ ä¸­ç­‰çª—å£ â­ æ¨èï¼ˆä¸LAMä¸€è‡´ï¼‰
- window_size = 25 â†’ å¤§çª—å£ï¼Œè¦†ç›–èŒƒå›´å¹¿

ä¸LAMçš„å…³ç³»ï¼š
  å¯ä»¥è®¾ç½®ä¸ºä¸LAMç›¸åŒçš„çª—å£å¤§å°ï¼ˆcamera=15, lidar=5ï¼‰
  ä¿æŒç©ºé—´ä¸€è‡´æ€§
```

---

## ğŸ“Š é¢„æœŸæ•ˆæœåˆ†æ

### ç†è®ºä¼˜åŠ¿

```
1. ç‰¹å¾åˆ†å¸ƒä¿æŒ â­â­â­â­â­
   - BEVç‰¹å¾ï¼šå®Œå…¨ä¸å˜
   - Cameraç‰¹å¾ï¼šå®Œå…¨ä¸å˜
   - é¿å…äº†"ç»¿è‰²1.0â†’1.5"é—®é¢˜

2. ç¨³å®šæ€§æå‡ â­â­â­â­â­
   - Softmaxå½’ä¸€åŒ–ä¿è¯attentionæƒé‡å’Œä¸º1
   - ä¸ä¼šå‡ºç°æç«¯å€¼
   - æ¢¯åº¦æ›´ç¨³å®š

3. å¯è§£é‡Šæ€§å¼º â­â­â­â­
   - Biasæ˜¯æ ‡å‡†æ“ä½œï¼Œå¹¿æ³›ä½¿ç”¨
   - å¯è§†åŒ–attentionæƒé‡å˜åŒ–
   - è°ƒè¯•å‹å¥½

4. å…¼å®¹æ€§å¥½ â­â­â­â­â­
   - Flash AttentionåŸç”Ÿæ”¯æŒ
   - ä¸éœ€è¦ä¿®æ”¹å†…éƒ¨å®ç°
   - ä¸ç°æœ‰æ¶æ„æ— ç¼é›†æˆ
```

### æ€§èƒ½é¢„æœŸ

```
ä¸Baselineå¯¹æ¯”ï¼ˆé¢„æµ‹ï¼‰ï¼š

1. è®­ç»ƒç¨³å®šæ€§ï¼š
   - Baselineï¼ˆæ— AQRï¼‰ï¼šç¨³å®š
   - ç‰¹å¾è°ƒåˆ¶AQRï¼šä¸ç¨³å®šï¼ˆlossæ³¢åŠ¨å¤§ï¼‰
   - Attention Bias AQRï¼šç¨³å®š â­

2. æ”¶æ•›é€Ÿåº¦ï¼š
   - Baselineï¼šæ­£å¸¸
   - ç‰¹å¾è°ƒåˆ¶AQRï¼šè¾ƒæ…¢ï¼ˆéœ€è¦é‡æ–°é€‚åº”ç‰¹å¾ï¼‰
   - Attention Bias AQRï¼šæ­£å¸¸æˆ–æ›´å¿« â­

3. æœ€ç»ˆæ€§èƒ½ï¼š
   - Baselineï¼š67.9% mAPï¼ˆé¢„è®­ç»ƒï¼‰
   - ç‰¹å¾è°ƒåˆ¶AQRï¼š64-66% mAPï¼ˆä¸‹é™ï¼‰
   - Attention Bias AQRï¼š68-70% mAPï¼ˆæå‡ï¼‰â­ é¢„æœŸ

ç†ç”±ï¼š
- ä¿æŒäº†é¢„è®­ç»ƒç‰¹å¾åˆ†å¸ƒ
- è‡ªé€‚åº”çš„æ¨¡æ€é€‰æ‹©
- ä¸ç ´åæ¨¡å‹å·²å­¦åˆ°çš„çŸ¥è¯†
```

---

## ğŸ”§ å®ç°è®¡åˆ’

### Phase 1: æ ¸å¿ƒåŠŸèƒ½å®ç°ï¼ˆé¢„è®¡2-3å°æ—¶ï¼‰

```
ä»»åŠ¡æ¸…å•ï¼š
â–¡ åˆ›å»ºAttentionBiasGeneratorç±»
  - å®ç°_generate_global_bias
  - é¢„ç•™_generate_local_biasæ¥å£
  
â–¡ ä¿®æ”¹CmtHead
  - ä¿®æ”¹_apply_aqr_modulation
  - ä¿®æ”¹forward_single
  
â–¡ ä¿®æ”¹CmtTransformer
  - æ·»åŠ aqr_attention_biaså‚æ•°
  - å®ç°biasèåˆé€»è¾‘
  
â–¡ é…ç½®æ–‡ä»¶
  - æ·»åŠ aqr_bias_strengthå‚æ•°
  - æ·»åŠ aqr_use_local_biaså‚æ•°
```

### Phase 2: æµ‹è¯•éªŒè¯ï¼ˆé¢„è®¡1å°æ—¶ï¼‰

```
æµ‹è¯•é¡¹ç›®ï¼š
â–¡ Forwardä¸æŠ¥é”™
â–¡ Biaså€¼èŒƒå›´æ­£ç¡®ï¼ˆ-Î±åˆ°+Î±ï¼‰
â–¡ Attention maskå½¢çŠ¶åŒ¹é…
â–¡ ä¸åŸæœ‰DN maskå…¼å®¹
â–¡ å¯è§†åŒ–biasåˆ†å¸ƒ
```

### Phase 3: è®­ç»ƒå®éªŒï¼ˆé¢„è®¡1 epochï¼‰

```
å®éªŒé…ç½®ï¼š
- æ•°æ®é›†ï¼š800Ã—320åˆ†è¾¨ç‡
- Epochï¼š1ä¸ªepochå¿«é€ŸéªŒè¯
- å¯¹æ¯”ï¼šBaseline vs Attention Bias AQR

ç›‘æ§æŒ‡æ ‡ï¼š
- Lossç¨³å®šæ€§
- mAPå˜åŒ–
- Attentionæƒé‡åˆ†å¸ƒ
- æ¯ä¸ªç±»åˆ«çš„æ€§èƒ½

è¶…å‚æ•°è°ƒä¼˜ï¼š
- bias_strength: [3.0, 5.0, 7.0]
```

### Phase 4: å±€éƒ¨biaså®ç°ï¼ˆå¯é€‰ï¼Œé¢„è®¡2-3å°æ—¶ï¼‰

```
å¦‚æœPhase 3æ•ˆæœå¥½ï¼Œå†å®ç°å±€éƒ¨biasï¼š
â–¡ å®ç°_generate_local_bias
â–¡ æ·»åŠ è·ç¦»è¡°å‡
â–¡ ä¼˜åŒ–è®¡ç®—æ•ˆç‡
â–¡ å¯¹æ¯”å…¨å±€vså±€éƒ¨æ•ˆæœ
```

---

## ğŸ“ ä»£ç ä¿®æ”¹æ¸…å•

### æ–°å¢æ–‡ä»¶

```
projects/mmdet3d_plugin/models/utils/attention_bias_generator.py
  - AttentionBiasGeneratorç±»
  - çº¦150è¡Œ
```

### ä¿®æ”¹æ–‡ä»¶

```
1. cmt_head.py
   ä¿®æ”¹è¡Œæ•°ï¼šçº¦50è¡Œ
   ä¸»è¦ä¿®æ”¹ï¼š
   - __init__ï¼šæ·»åŠ bias_generatoråˆå§‹åŒ–
   - _apply_aqr_modulationï¼šæ”¹ä¸ºç”Ÿæˆbias
   - forward_singleï¼šä¼ é€’biaså‚æ•°
   
2. cmt_transformer.py
   ä¿®æ”¹è¡Œæ•°ï¼šçº¦20è¡Œ
   ä¸»è¦ä¿®æ”¹ï¼š
   - forwardï¼šæ·»åŠ aqr_attention_biaså‚æ•°
   - å®ç°biasèåˆé€»è¾‘
   
3. cmt_aqr_voxel0100_r50_800x320_cbgs.py
   ä¿®æ”¹è¡Œæ•°ï¼šçº¦5è¡Œ
   ä¸»è¦ä¿®æ”¹ï¼š
   - æ·»åŠ aqr_bias_strength=5.0
   - æ·»åŠ aqr_use_local_bias=False
```

### åˆ é™¤æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰

```
å¦‚æœæ•ˆæœå¥½ï¼Œå¯ä»¥åˆ é™¤ï¼š
- feature_modulator.pyï¼ˆçº¦200è¡Œï¼‰
- weight_renderer.pyçš„éƒ¨åˆ†åŠŸèƒ½ï¼ˆçº¦300è¡Œï¼‰

å®é™…ä»£ç é‡å‡€å‡å°‘ï¼
```

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

### å¿…é¡»è¾¾åˆ°

```
1. âœ… è®­ç»ƒç¨³å®šæ€§ â‰¥ Baseline
   - Lossä¸å‡ºç°å¤§å¹…æ³¢åŠ¨
   - æ¢¯åº¦èŒƒæ•°åœ¨åˆç†èŒƒå›´

2. âœ… æ€§èƒ½ä¸ä½äºBaseline
   - mAP â‰¥ 67.9%
   - NDS â‰¥ 70.8%

3. âœ… ä»£ç å¯ç»´æŠ¤æ€§
   - é€»è¾‘æ¸…æ™°
   - æ˜“äºè°ƒè¯•
   - å¯è§†åŒ–å®Œå–„
```

### æœŸæœ›è¾¾åˆ°

```
1. â­ æ€§èƒ½æå‡
   - mAPæå‡1-2%
   - å°ç›®æ ‡æ€§èƒ½æå‡æ˜æ˜¾

2. â­ æ¨¡æ€è‡ªé€‚åº”
   - ä¸åŒåœºæ™¯è‡ªåŠ¨é€‰æ‹©åˆé€‚æ¨¡æ€
   - Camera/LiDARæƒé‡åˆ†å¸ƒåˆç†

3. â­ å¯è§£é‡Šæ€§
   - å¯è§†åŒ–æ˜¾ç¤ºåˆç†çš„æ³¨æ„åŠ›æ¨¡å¼
   - ç¬¦åˆç›´è§‰
```

---

## ğŸ” æ½œåœ¨é£é™©ä¸å¯¹ç­–

### é£é™©1ï¼šBiaså¼ºåº¦è¿‡å¤§

```
ç—‡çŠ¶ï¼š
- Attentionå®Œå…¨é›†ä¸­åœ¨ä¸€ä¸ªæ¨¡æ€
- æ€§èƒ½åè€Œä¸‹é™

å¯¹ç­–ï¼š
- é™ä½bias_strengthï¼ˆ5.0â†’3.0â†’1.0ï¼‰
- æ·»åŠ bias clipping
- ç›‘æ§attentionåˆ†å¸ƒçš„ç†µ
```

### é£é™©2ï¼šä¸DN maskå†²çª

```
ç—‡çŠ¶ï¼š
- DNè®­ç»ƒæ—¶å‡ºç°é”™è¯¯
- Maskç»´åº¦ä¸åŒ¹é…

å¯¹ç­–ï¼š
- ä»”ç»†å¤„ç†maskèåˆé€»è¾‘
- åˆ†åˆ«å¤„ç†DN queryå’Œæ™®é€šquery
- å……åˆ†æµ‹è¯•è¾¹ç•Œæƒ…å†µ
```

### é£é™©3ï¼šè®¡ç®—å¼€é”€å¢åŠ 

```
ç—‡çŠ¶ï¼š
- è®­ç»ƒé€Ÿåº¦æ˜æ˜¾ä¸‹é™

å¯¹ç­–ï¼š
- ä¼˜å…ˆä½¿ç”¨å…¨å±€biasï¼ˆè®¡ç®—ç®€å•ï¼‰
- å±€éƒ¨biasä½¿ç”¨é«˜æ•ˆå®ç°ï¼ˆå‘é‡åŒ–ï¼‰
- å¿…è¦æ—¶ä½¿ç”¨æ›´å°çš„çª—å£
```

---

## ğŸ“š ç›¸å…³ç†è®ºå‚è€ƒ

### Attention Biasåœ¨Transformerä¸­çš„åº”ç”¨

```
1. ä½ç½®ç¼–ç æœ¬è´¨ä¸Šä¹Ÿæ˜¯ä¸€ç§attention bias
   - ç»å¯¹ä½ç½®ç¼–ç ï¼šåŠ åˆ°Q/Kä¸Š
   - ç›¸å¯¹ä½ç½®ç¼–ç ï¼šç›´æ¥åŠ åˆ°attention scoresä¸Š
   - AQR biasï¼šæ¨¡æ€åå¥½çš„bias

2. Transformer-XLçš„ç›¸å¯¹ä½ç½®bias
   - è¯æ˜äº†biaså¯ä»¥æœ‰æ•ˆå¼•å¯¼attention
   - ä¸ç ´åæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›

3. Vision Transformerçš„å±€éƒ¨attention bias
   - Shifted Windowç­‰æŠ€æœ¯
   - é€šè¿‡biasé™åˆ¶attentionèŒƒå›´
```

### ä¸ç‰¹å¾è°ƒåˆ¶çš„ç†è®ºå¯¹æ¯”

```
ç‰¹å¾ç©ºé—´ vs æ³¨æ„åŠ›ç©ºé—´ï¼š

ç‰¹å¾è°ƒåˆ¶ï¼š
  f' = f Ã— w
  é—®é¢˜ï¼šæ”¹å˜äº†ç‰¹å¾çš„è¯­ä¹‰ç©ºé—´
  
Attentionè°ƒåˆ¶ï¼š
  Î±' = softmax(score + bias)
  ä¼˜åŠ¿ï¼šåªæ”¹å˜ç‰¹å¾çš„ä½¿ç”¨æƒé‡ï¼Œä¸æ”¹å˜ç‰¹å¾æœ¬èº«
  
ç±»æ¯”ï¼š
  ç‰¹å¾è°ƒåˆ¶ = æ”¹å˜ç‰©ä½“æœ¬èº«
  Attentionè°ƒåˆ¶ = æ”¹å˜çœ‹ç‰©ä½“çš„æ–¹å¼
```

---

## ğŸ¾ æ€»ç»“

### æ ¸å¿ƒåˆ›æ–°ç‚¹

```
1. ğŸ”¥ ä»"æ”¹å˜ç‰¹å¾å€¼"åˆ°"æ”¹å˜æ³¨æ„åŠ›æƒé‡"
   - ä¿æŠ¤é¢„è®­ç»ƒçŸ¥è¯†
   - ç†è®ºæ›´ç¨³å¥

2. ğŸ”¥ å®Œå…¨å…¼å®¹Flash Attention
   - æ— éœ€ä¿®æ”¹åº•å±‚å®ç°
   - åˆ©ç”¨ç°æœ‰ä¼˜åŒ–

3. ğŸ”¥ ä»£ç é‡æ›´å°‘
   - åˆ é™¤å¤æ‚çš„ç‰¹å¾è°ƒåˆ¶é€»è¾‘
   - ç®€åŒ–æ•´ä½“æ¶æ„
```

### å…³é”®ä¼˜åŠ¿

```
âœ… ç†è®ºåŸºç¡€æ‰å®ï¼ˆAttention Biasæ˜¯æ ‡å‡†åšæ³•ï¼‰
âœ… å®ç°å¤æ‚åº¦ä½ï¼ˆçº¦150è¡Œæ–°å¢ä»£ç ï¼‰
âœ… è°ƒè¯•å‹å¥½ï¼ˆå¯è§†åŒ–attentionæƒé‡ï¼‰
âœ… æ€§èƒ½å¯æœŸï¼ˆä¸ç ´åç‰¹å¾åˆ†å¸ƒï¼‰
âœ… å¯æ‰©å±•æ€§å¼ºï¼ˆæ”¯æŒå±€éƒ¨/å…¨å±€biasï¼‰
```

### åç»­æ‹“å±•æ–¹å‘

```
1. å¯å­¦ä¹ çš„biaså‡½æ•°
   - ä¸æ˜¯ç®€å•çš„çº¿æ€§æ˜ å°„
   - ç”¨å°å‹ç½‘ç»œå­¦ä¹ æƒé‡â†’biasçš„æ˜ å°„

2. åŠ¨æ€bias strength
   - ä¸åŒå±‚ä½¿ç”¨ä¸åŒçš„Î±
   - æ ¹æ®è®­ç»ƒè¿›åº¦è‡ªé€‚åº”è°ƒæ•´

3. å¤šç²’åº¦bias
   - Query-levelï¼ˆå½“å‰æ–¹æ¡ˆï¼‰
   - Head-levelï¼ˆä¸åŒattention headä¸åŒbiasï¼‰
   - Layer-levelï¼ˆä¸åŒDecoderå±‚ä¸åŒbiasï¼‰
```

---

**ä¸»äººï¼Œè¿™å°±æ˜¯Attention Biasè°ƒåˆ¶æ–¹æ¡ˆçš„è¯¦ç»†è®¾è®¡ï¼ğŸ¯**

æ ¸å¿ƒæ€æƒ³å°±æ˜¯ï¼š**ä¸æ”¹å˜"ç»¿è‰²"æœ¬èº«ï¼Œåªæ”¹å˜"çœ‹ç»¿è‰²çš„æƒé‡"ï¼** ğŸŒ³ğŸ‘€

