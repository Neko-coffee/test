/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : tools/train.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 8
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:29500
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_2fxoxyty/none_odz030mq
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
  role_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]
  global_world_sizes=[8, 8, 8, 8, 8, 8, 8, 8]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_2fxoxyty/none_odz030mq/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_2fxoxyty/none_odz030mq/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_2fxoxyty/none_odz030mq/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_2fxoxyty/none_odz030mq/attempt_0/3/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker4 reply file to: /tmp/torchelastic_2fxoxyty/none_odz030mq/attempt_0/4/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker5 reply file to: /tmp/torchelastic_2fxoxyty/none_odz030mq/attempt_0/5/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker6 reply file to: /tmp/torchelastic_2fxoxyty/none_odz030mq/attempt_0/6/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker7 reply file to: /tmp/torchelastic_2fxoxyty/none_odz030mq/attempt_0/7/error.json
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
['/data/coding/tools', '/data/coding', '/data/miniconda/envs/torch/lib/python38.zip', '/data/miniconda/envs/torch/lib/python3.8', '/data/miniconda/envs/torch/lib/python3.8/lib-dynload', '/data/miniconda/envs/torch/lib/python3.8/site-packages', '/data/miniconda/envs/torch/lib/python3.8/site-packages/qudida-0.0.4-py3.8.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/opencv_python_headless-4.10.0.84-py3.8-linux-x86_64.egg', '/data/miniconda/envs/torch/lib/python3.8/site-packages/albumentations-1.3.1-py3.8.egg', '']
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
projects.mmdet3d_plugin
fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-10-12 02:26:35,562 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: NVIDIA A100-PCIE-40GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 1.9.0+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.10.0+cu111
OpenCV: 4.8.1
MMCV: 1.6.0
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.1
MMDetection: 2.24.0
MMSegmentation: 0.29.1
MMDetection3D: 1.0.0rc5+
spconv2.0: True
------------------------------------------------------------

fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
2025-10-12 02:26:37,593 - mmdet - INFO - Distributed training: True
2025-10-12 02:26:39,724 - mmdet - INFO - Config:
plugin = True
plugin_dir = 'projects/mmdet3d_plugin/'
point_cloud_range = [-54.0, -54.0, -5.0, 54.0, 54.0, 3.0]
class_names = [
    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
]
voxel_size = [0.1, 0.1, 0.2]
out_size_factor = 8
evaluation = dict(interval=1)
dataset_type = 'CustomNuScenesDataset'
data_root = 'data/nuscenes/'
input_modality = dict(
    use_lidar=True,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=False)
img_norm_cfg = dict(
    mean=[103.53, 116.28, 123.675], std=[57.375, 57.12, 58.395], to_rgb=False)
ida_aug_conf = dict(
    resize_lim=(0.47, 0.625),
    final_dim=(320, 800),
    bot_pct_lim=(0.0, 0.0),
    rot_lim=(0.0, 0.0),
    H=900,
    W=1600,
    rand_flip=True)
train_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=[0, 1, 2, 3, 4]),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=10,
        use_dim=[0, 1, 2, 3, 4]),
    dict(type='LoadMultiViewImageFromFiles'),
    dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),
    dict(type='ModalMask3D', mode='train'),
    dict(
        type='GlobalRotScaleTransAll',
        rot_range=[-0.785, 0.785],
        scale_ratio_range=[0.9, 1.1],
        translation_std=[0.5, 0.5, 0.5]),
    dict(
        type='CustomRandomFlip3D',
        sync_2d=False,
        flip_ratio_bev_horizontal=0.5,
        flip_ratio_bev_vertical=0.5),
    dict(
        type='PointsRangeFilter',
        point_cloud_range=[-54.0, -54.0, -5.0, 54.0, 54.0, 3.0]),
    dict(
        type='ObjectRangeFilter',
        point_cloud_range=[-54.0, -54.0, -5.0, 54.0, 54.0, 3.0]),
    dict(
        type='ObjectNameFilter',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='PyramidAugmentation',
        enable_sa_dropout=0.15,
        enable_sa_sparsity=None,
        enable_sa_swap=None,
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier'
        ]),
    dict(type='PointShuffle'),
    dict(
        type='ResizeCropFlipImage',
        data_aug_conf=dict(
            resize_lim=(0.47, 0.625),
            final_dim=(320, 800),
            bot_pct_lim=(0.0, 0.0),
            rot_lim=(0.0, 0.0),
            H=900,
            W=1600,
            rand_flip=True),
        training=True),
    dict(
        type='CustomRandomBrightnessContrast',
        brightness_limit=(-0.2, 0.2),
        contrast_limit=(-0.2, 0.2),
        brightness_by_max=True,
        p=1.0),
    dict(
        type='NormalizeMultiviewImage',
        mean=[103.53, 116.28, 123.675],
        std=[57.375, 57.12, 58.395],
        to_rgb=False),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='Collect3D',
        keys=['points', 'img', 'gt_bboxes_3d', 'gt_labels_3d'],
        meta_keys=('filename', 'ori_shape', 'img_shape', 'lidar2img',
                   'depth2img', 'cam2img', 'pad_shape', 'scale_factor', 'flip',
                   'pcd_horizontal_flip', 'pcd_vertical_flip', 'box_mode_3d',
                   'box_type_3d', 'img_norm_cfg', 'pcd_trans', 'sample_idx',
                   'pcd_scale_factor', 'pcd_rotation', 'pts_filename',
                   'transformation_3d_flow', 'rot_degree', 'gt_bboxes_3d',
                   'gt_labels_3d'))
]
test_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=[0, 1, 2, 3, 4]),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=10,
        use_dim=[0, 1, 2, 3, 4]),
    dict(type='LoadMultiViewImageFromFiles'),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1333, 800),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(
                type='GlobalRotScaleTrans',
                rot_range=[0, 0],
                scale_ratio_range=[1.0, 1.0],
                translation_std=[0, 0, 0]),
            dict(type='RandomFlip3D'),
            dict(
                type='ResizeCropFlipImage',
                data_aug_conf=dict(
                    resize_lim=(0.47, 0.625),
                    final_dim=(320, 800),
                    bot_pct_lim=(0.0, 0.0),
                    rot_lim=(0.0, 0.0),
                    H=900,
                    W=1600,
                    rand_flip=True),
                training=False),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[57.375, 57.12, 58.395],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ],
                with_label=False),
            dict(type='Collect3D', keys=['points', 'img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=6,
    train=dict(
        type='CBGSDataset',
        dataset=dict(
            type='CustomNuScenesDataset',
            data_root='data/nuscenes/',
            ann_file='data/nuscenes//nuscenes_infos_train.pkl',
            load_interval=1,
            pipeline=[
                dict(
                    type='LoadPointsFromFile',
                    coord_type='LIDAR',
                    load_dim=5,
                    use_dim=[0, 1, 2, 3, 4]),
                dict(
                    type='LoadPointsFromMultiSweeps',
                    sweeps_num=10,
                    use_dim=[0, 1, 2, 3, 4]),
                dict(type='LoadMultiViewImageFromFiles'),
                dict(
                    type='LoadAnnotations3D',
                    with_bbox_3d=True,
                    with_label_3d=True),
                dict(type='ModalMask3D', mode='train'),
                dict(
                    type='GlobalRotScaleTransAll',
                    rot_range=[-0.785, 0.785],
                    scale_ratio_range=[0.9, 1.1],
                    translation_std=[0.5, 0.5, 0.5]),
                dict(
                    type='CustomRandomFlip3D',
                    sync_2d=False,
                    flip_ratio_bev_horizontal=0.5,
                    flip_ratio_bev_vertical=0.5),
                dict(
                    type='PointsRangeFilter',
                    point_cloud_range=[-54.0, -54.0, -5.0, 54.0, 54.0, 3.0]),
                dict(
                    type='ObjectRangeFilter',
                    point_cloud_range=[-54.0, -54.0, -5.0, 54.0, 54.0, 3.0]),
                dict(
                    type='ObjectNameFilter',
                    classes=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier', 'motorcycle', 'bicycle',
                        'pedestrian', 'traffic_cone'
                    ]),
                dict(
                    type='PyramidAugmentation',
                    enable_sa_dropout=0.15,
                    enable_sa_sparsity=None,
                    enable_sa_swap=None,
                    classes=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier'
                    ]),
                dict(type='PointShuffle'),
                dict(
                    type='ResizeCropFlipImage',
                    data_aug_conf=dict(
                        resize_lim=(0.47, 0.625),
                        final_dim=(320, 800),
                        bot_pct_lim=(0.0, 0.0),
                        rot_lim=(0.0, 0.0),
                        H=900,
                        W=1600,
                        rand_flip=True),
                    training=True),
                dict(
                    type='CustomRandomBrightnessContrast',
                    brightness_limit=(-0.2, 0.2),
                    contrast_limit=(-0.2, 0.2),
                    brightness_by_max=True,
                    p=1.0),
                dict(
                    type='NormalizeMultiviewImage',
                    mean=[103.53, 116.28, 123.675],
                    std=[57.375, 57.12, 58.395],
                    to_rgb=False),
                dict(type='PadMultiViewImage', size_divisor=32),
                dict(
                    type='DefaultFormatBundle3D',
                    class_names=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier', 'motorcycle', 'bicycle',
                        'pedestrian', 'traffic_cone'
                    ]),
                dict(
                    type='Collect3D',
                    keys=['points', 'img', 'gt_bboxes_3d', 'gt_labels_3d'],
                    meta_keys=('filename', 'ori_shape', 'img_shape',
                               'lidar2img', 'depth2img', 'cam2img',
                               'pad_shape', 'scale_factor', 'flip',
                               'pcd_horizontal_flip', 'pcd_vertical_flip',
                               'box_mode_3d', 'box_type_3d', 'img_norm_cfg',
                               'pcd_trans', 'sample_idx', 'pcd_scale_factor',
                               'pcd_rotation', 'pts_filename',
                               'transformation_3d_flow', 'rot_degree',
                               'gt_bboxes_3d', 'gt_labels_3d'))
            ],
            classes=[
                'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                'traffic_cone'
            ],
            modality=dict(
                use_lidar=True,
                use_camera=True,
                use_radar=False,
                use_map=False,
                use_external=False),
            test_mode=False,
            box_type_3d='LiDAR')),
    val=dict(
        type='CustomNuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes//nuscenes_infos_val.pkl',
        load_interval=1,
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=[0, 1, 2, 3, 4]),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=10,
                use_dim=[0, 1, 2, 3, 4]),
            dict(type='LoadMultiViewImageFromFiles'),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='ResizeCropFlipImage',
                        data_aug_conf=dict(
                            resize_lim=(0.47, 0.625),
                            final_dim=(320, 800),
                            bot_pct_lim=(0.0, 0.0),
                            rot_lim=(0.0, 0.0),
                            H=900,
                            W=1600,
                            rand_flip=True),
                        training=False),
                    dict(
                        type='NormalizeMultiviewImage',
                        mean=[103.53, 116.28, 123.675],
                        std=[57.375, 57.12, 58.395],
                        to_rgb=False),
                    dict(type='PadMultiViewImage', size_divisor=32),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='Collect3D', keys=['points', 'img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'),
    test=dict(
        type='CustomNuScenesDataset',
        data_root='data/nuscenes/',
        ann_file='data/nuscenes//nuscenes_infos_val.pkl',
        load_interval=1,
        pipeline=[
            dict(
                type='LoadPointsFromFile',
                coord_type='LIDAR',
                load_dim=5,
                use_dim=[0, 1, 2, 3, 4]),
            dict(
                type='LoadPointsFromMultiSweeps',
                sweeps_num=10,
                use_dim=[0, 1, 2, 3, 4]),
            dict(type='LoadMultiViewImageFromFiles'),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1333, 800),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='GlobalRotScaleTrans',
                        rot_range=[0, 0],
                        scale_ratio_range=[1.0, 1.0],
                        translation_std=[0, 0, 0]),
                    dict(type='RandomFlip3D'),
                    dict(
                        type='ResizeCropFlipImage',
                        data_aug_conf=dict(
                            resize_lim=(0.47, 0.625),
                            final_dim=(320, 800),
                            bot_pct_lim=(0.0, 0.0),
                            rot_lim=(0.0, 0.0),
                            H=900,
                            W=1600,
                            rand_flip=True),
                        training=False),
                    dict(
                        type='NormalizeMultiviewImage',
                        mean=[103.53, 116.28, 123.675],
                        std=[57.375, 57.12, 58.395],
                        to_rgb=False),
                    dict(type='PadMultiViewImage', size_divisor=32),
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(type='Collect3D', keys=['points', 'img'])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=True,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=False),
        test_mode=True,
        box_type_3d='LiDAR'))
model = dict(
    type='CmtDetector',
    use_grid_mask=False,
    img_backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(2, 3),
        frozen_stages=-1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        with_cp=False,
        style='pytorch'),
    img_neck=dict(
        type='CPFPN', in_channels=[1024, 2048], out_channels=256, num_outs=2),
    pts_voxel_layer=dict(
        num_point_features=5,
        max_num_points=10,
        voxel_size=[0.1, 0.1, 0.2],
        max_voxels=(120000, 160000),
        point_cloud_range=[-54.0, -54.0, -5.0, 54.0, 54.0, 3.0]),
    pts_voxel_encoder=dict(type='HardSimpleVFE', num_features=5),
    pts_middle_encoder=dict(
        type='SparseEncoder',
        in_channels=5,
        sparse_shape=[41, 1024, 1024],
        output_channels=128,
        order=('conv', 'norm', 'act'),
        encoder_channels=((16, 16, 32), (32, 32, 64), (64, 64, 128), (128,
                                                                      128)),
        encoder_paddings=((0, 0, 1), (0, 0, 1), (0, 0, [0, 1, 1]), (0, 0)),
        block_type='basicblock'),
    pts_backbone=dict(
        type='SECOND',
        in_channels=256,
        out_channels=[128, 256],
        layer_nums=[5, 5],
        layer_strides=[1, 2],
        norm_cfg=dict(type='BN', eps=0.001, momentum=0.01),
        conv_cfg=dict(type='Conv2d', bias=False)),
    pts_neck=dict(
        type='SECONDFPN',
        in_channels=[128, 256],
        out_channels=[256, 256],
        upsample_strides=[1, 2],
        norm_cfg=dict(type='BN', eps=0.001, momentum=0.01),
        upsample_cfg=dict(type='deconv', bias=False),
        use_conv_for_no_stride=True),
    pts_bbox_head=dict(
        type='CmtHead',
        in_channels=512,
        hidden_dim=256,
        downsample_scale=8,
        common_heads=dict(
            center=(2, 2), height=(1, 2), dim=(3, 2), rot=(2, 2), vel=(2, 2)),
        tasks=[
            dict(
                num_class=10,
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ])
        ],
        bbox_coder=dict(
            type='MultiTaskBBoxCoder',
            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            pc_range=[-54.0, -54.0, -5.0, 54.0, 54.0, 3.0],
            max_num=300,
            voxel_size=[0.1, 0.1, 0.2],
            num_classes=10),
        separate_head=dict(
            type='SeparateTaskHead', init_bias=-2.19, final_kernel=1),
        transformer=dict(
            type='CmtTransformer',
            decoder=dict(
                type='PETRTransformerDecoder',
                return_intermediate=True,
                num_layers=6,
                transformerlayers=dict(
                    type='PETRTransformerDecoderLayer',
                    with_cp=False,
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='PETRMultiheadFlashAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1)
                    ],
                    ffn_cfgs=dict(
                        type='FFN',
                        embed_dims=256,
                        feedforward_channels=1024,
                        num_fcs=2,
                        ffn_drop=0.0,
                        act_cfg=dict(type='ReLU', inplace=True)),
                    feedforward_channels=1024,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2,
            alpha=0.25,
            reduction='mean',
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', reduction='mean', loss_weight=0.25),
        loss_heatmap=dict(
            type='GaussianFocalLoss', reduction='mean', loss_weight=1.0),
        enable_aqr=True,
        debug_mode=True,
        visualization_interval=1000,
        aqr_config=dict(
            embed_dims=256,
            window_sizes=[8, 5],
            use_type_embed=True,
            bev_feature_shape=(128, 128),
            pers_feature_shape=(6, 20, 50),
            encoder_config=dict(
                type='PETRTransformerDecoder',
                return_intermediate=True,
                num_layers=1,
                transformerlayers=dict(
                    type='PETRTransformerDecoderLayer',
                    with_cp=False,
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=4,
                            dropout=0.1)
                    ],
                    ffn_cfgs=dict(
                        type='FFN',
                        embed_dims=256,
                        feedforward_channels=1024,
                        num_fcs=2,
                        ffn_drop=0.1,
                        act_cfg=dict(type='ReLU', inplace=True)),
                    feedforward_channels=1024,
                    operation_order=('cross_attn', 'norm', 'ffn', 'norm')))),
        renderer_config=dict(
            render_method='gaussian',
            gaussian_sigma=1.0,
            bilinear_radius=1.5,
            distance_decay=0.8,
            min_weight_threshold=0.01,
            bev_feature_shape=(128, 128),
            pers_feature_shape=(6, 20, 50),
            normalize_weights=True),
        use_simple_modulation=False,
        modulator_config=dict(
            type='FeatureModulator',
            modulation_type='element_wise',
            normalize_weights=False,
            residual_connection=True,
            residual_weight=0.7,
            learnable_modulation=False,
            activation='none')),
    train_cfg=dict(
        pts=dict(
            dataset='nuScenes',
            assigner=dict(
                type='HungarianAssigner3D',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
                iou_cost=dict(type='IoUCost', weight=0.0),
                pc_range=[-54.0, -54.0, -5.0, 54.0, 54.0, 3.0],
                code_weights=[
                    2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2
                ]),
            pos_weight=-1,
            gaussian_overlap=0.1,
            min_radius=2,
            grid_size=[1024, 1024, 40],
            voxel_size=[0.1, 0.1, 0.2],
            out_size_factor=8,
            code_weights=[2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
            point_cloud_range=[-54.0, -54.0, -5.0, 54.0, 54.0, 3.0])),
    test_cfg=dict(
        pts=dict(
            dataset='nuScenes',
            grid_size=[1024, 1024, 40],
            out_size_factor=8,
            pc_range=[-54.0, -54.0, -5.0, 54.0, 54.0, 3.0],
            voxel_size=[0.1, 0.1, 0.2],
            nms_type=None,
            nms_thr=0.2,
            use_rotate_nms=True,
            max_num=200)))
optimizer = dict(
    type='AdamW',
    lr=1.4e-05,
    paramwise_cfg=dict(
        custom_keys=dict(
            img_backbone=dict(lr_mult=0.01, decay_mult=5),
            img_neck=dict(lr_mult=0.1),
            pts_voxel_encoder=dict(lr_mult=0.1),
            pts_middle_encoder=dict(lr_mult=0.1),
            pts_backbone=dict(lr_mult=0.05),
            pts_neck=dict(lr_mult=0.1),
            transformer=dict(lr_mult=0.8),
            query_embed=dict(lr_mult=0.8),
            reference_points=dict(lr_mult=0.5),
            task_heads=dict(lr_mult=0.8),
            shared_conv=dict(lr_mult=0.8),
            aqr_weight_generator=dict(lr_mult=8.0),
            weight_renderer=dict(lr_mult=8.0),
            feature_modulator=dict(lr_mult=8.0))),
    weight_decay=0.01)
optimizer_config = dict(
    type='CustomFp16OptimizerHook',
    loss_scale='dynamic',
    grad_clip=dict(max_norm=35, norm_type=2),
    custom_fp16=dict(
        pts_voxel_encoder=False, pts_middle_encoder=False,
        pts_bbox_head=False))
lr_config = dict(
    policy='cyclic',
    target_ratio=(6, 0.001),
    cyclic_times=1,
    step_ratio_up=0.3)
momentum_config = dict(
    policy='cyclic',
    target_ratio=(0.8947368421052632, 1),
    cyclic_times=1,
    step_ratio_up=0.1)
total_epochs = 1
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=50,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './work_dirs/cmt_aqr_voxel0100_r50_800x320_cbgs'
load_from = 'ckpts/epoch_20.pth'
resume_from = None
workflow = [('train', 1)]
gpu_ids = range(0, 8)
find_unused_parameters = True

2025-10-12 02:26:39,724 - mmdet - INFO - Set random seed to 0, deterministic: False
‚úÖ AQR components initialized successfully!
   - AQRWeightGenerator: AQRWeightGenerator
   - WeightRenderer: WeightRenderer (gaussian)
   - FeatureModulator: üõ°Ô∏è Full mode (element_wise, residual=True)
‚úÖ AQR components initialized successfully!
   - AQRWeightGenerator: AQRWeightGenerator
   - WeightRenderer: WeightRenderer (gaussian)
   - FeatureModulator: üõ°Ô∏è Full mode (element_wise, residual=True)
‚úÖ AQR components initialized successfully!
   - AQRWeightGenerator: AQRWeightGenerator
   - WeightRenderer: WeightRenderer (gaussian)
   - FeatureModulator: üõ°Ô∏è Full mode (element_wise, residual=True)
‚úÖ AQR components initialized successfully!
   - AQRWeightGenerator: AQRWeightGenerator
   - WeightRenderer: WeightRenderer (gaussian)
   - FeatureModulator: üõ°Ô∏è Full mode (element_wise, residual=True)
‚úÖ AQR components initialized successfully!
   - AQRWeightGenerator: AQRWeightGenerator
   - WeightRenderer: WeightRenderer (gaussian)
   - FeatureModulator: üõ°Ô∏è Full mode (element_wise, residual=True)
‚úÖ AQR components initialized successfully!
   - AQRWeightGenerator: AQRWeightGenerator
   - WeightRenderer: WeightRenderer (gaussian)
   - FeatureModulator: üõ°Ô∏è Full mode (element_wise, residual=True)
‚úÖ AQR components initialized successfully!
   - AQRWeightGenerator: AQRWeightGenerator
   - WeightRenderer: WeightRenderer (gaussian)
   - FeatureModulator: üõ°Ô∏è Full mode (element_wise, residual=True)
‚úÖ AQR components initialized successfully!
   - AQRWeightGenerator: AQRWeightGenerator
   - WeightRenderer: WeightRenderer (gaussian)
   - FeatureModulator: üõ°Ô∏è Full mode (element_wise, residual=True)
2025-10-12 02:26:45,752 - mmdet - INFO - initialize SECOND with init_cfg {'type': 'Kaiming', 'layer': 'Conv2d'}
2025-10-12 02:26:45,781 - mmdet - INFO - initialize SECONDFPN with init_cfg [{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
2025-10-12 02:26:45,825 - mmdet - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2025-10-12 02:26:45,985 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,985 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,986 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,987 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,988 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,988 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,989 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,991 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,992 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,994 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,995 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,996 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:45,997 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:46,001 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:46,006 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:46,013 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-10-12 02:26:46,031 - mmdet - INFO - initialize CPFPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-10-12 02:26:46,048 - mmdet - INFO - Model:
CmtDetector(
  (pts_voxel_encoder): HardSimpleVFE()
  (pts_middle_encoder): SparseEncoder(
    (conv_input): SparseSequential(
      (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (encoder_layers): SparseSequential(
      (encoder_layer1): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer2): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer3): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): SparseSequential(
          (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
      (encoder_layer4): SparseSequential(
        (0): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): SparseBasicBlock(
          (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
          (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (conv_out): SparseSequential(
      (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (pts_backbone): SECOND(
    (blocks): ModuleList(
      (0): Sequential(
        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (7): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (11): ReLU(inplace=True)
        (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (13): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (14): ReLU(inplace=True)
        (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (16): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (17): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (7): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (8): ReLU(inplace=True)
        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (11): ReLU(inplace=True)
        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (13): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (14): ReLU(inplace=True)
        (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (16): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (17): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
  (pts_neck): SECONDFPN(
    (deblocks): ModuleList(
      (0): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
  )
  init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
  (pts_bbox_head): CmtHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (loss_heatmap): GaussianFocalLoss()
    (shared_conv): ConvModule(
      (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (transformer): CmtTransformer(
      (decoder): PETRTransformerDecoder(
        (layers): ModuleList(
          (0): PETRTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): PETRMultiheadFlashAttention(
                (attn): FlashMHA(
                  (inner_attn): FlashAttention()
                  (out_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): PETRTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): PETRMultiheadFlashAttention(
                (attn): FlashMHA(
                  (inner_attn): FlashAttention()
                  (out_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): PETRTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): PETRMultiheadFlashAttention(
                (attn): FlashMHA(
                  (inner_attn): FlashAttention()
                  (out_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): PETRTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): PETRMultiheadFlashAttention(
                (attn): FlashMHA(
                  (inner_attn): FlashAttention()
                  (out_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (4): PETRTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): PETRMultiheadFlashAttention(
                (attn): FlashMHA(
                  (inner_attn): FlashAttention()
                  (out_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
          (5): PETRTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): PETRMultiheadFlashAttention(
                (attn): FlashMHA(
                  (inner_attn): FlashAttention()
                  (out_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (post_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (reference_points): Embedding(900, 3)
    (bev_embedding): Sequential(
      (0): Linear(in_features=512, out_features=256, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=256, out_features=256, bias=True)
    )
    (rv_embedding): Sequential(
      (0): Linear(in_features=192, out_features=1024, bias=True)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=1024, out_features=256, bias=True)
    )
    (task_heads): ModuleList(
      (0): SeparateTaskHead(
        (center): Sequential(
          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)
          (1): GroupLayerNorm1d()
          (2): ReLU(inplace=True)
          (3): Conv1d(384, 12, kernel_size=(1,), stride=(1,), groups=6)
        )
        (height): Sequential(
          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)
          (1): GroupLayerNorm1d()
          (2): ReLU(inplace=True)
          (3): Conv1d(384, 6, kernel_size=(1,), stride=(1,), groups=6)
        )
        (dim): Sequential(
          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)
          (1): GroupLayerNorm1d()
          (2): ReLU(inplace=True)
          (3): Conv1d(384, 18, kernel_size=(1,), stride=(1,), groups=6)
        )
        (rot): Sequential(
          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)
          (1): GroupLayerNorm1d()
          (2): ReLU(inplace=True)
          (3): Conv1d(384, 12, kernel_size=(1,), stride=(1,), groups=6)
        )
        (vel): Sequential(
          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)
          (1): GroupLayerNorm1d()
          (2): ReLU(inplace=True)
          (3): Conv1d(384, 12, kernel_size=(1,), stride=(1,), groups=6)
        )
        (cls_logits): Sequential(
          (0): Conv1d(1536, 384, kernel_size=(1,), stride=(1,), groups=6, bias=False)
          (1): GroupLayerNorm1d()
          (2): ReLU(inplace=True)
          (3): Conv1d(384, 60, kernel_size=(1,), stride=(1,), groups=6)
        )
      )
      init_cfg={'type': 'Kaiming', 'layer': 'Conv1d'}
    )
    (aqr_weight_generator): AQRWeightGenerator(
      (encoder): PETRTransformerDecoder(
        (layers): ModuleList(
          (0): PETRTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=1024, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=1024, out_features=256, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (post_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (weight_predictor): Linear(in_features=256, out_features=2, bias=True)
    )
    (weight_renderer): WeightRenderer()
    (feature_modulator): FeatureModulator(
      (activation_fn): Identity()
    )
  )
  (img_backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
  )
  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
  (img_neck): CPFPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (grid_mask): GridMask()
  (pts_voxel_layer): SPConvVoxelization(voxel_size=[0.1 0.1 0.2], point_cloud_range=[-54. -54.  -5.  54.  54.   3.], max_num_points=10, max_voxels=(120000, 160000), num_point_features=5)
)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmdet3d/apis/train.py:243: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.
  warnings.warn(
2025-10-12 02:26:58,757 - mmdet - INFO - load checkpoint from local path: ckpts/epoch_20.pth
2025-10-12 02:27:00,396 - mmdet - WARNING - The model and loaded state dict do not match exactly

missing keys in source state_dict: pts_bbox_head.aqr_weight_generator.bev_type_embed, pts_bbox_head.aqr_weight_generator.rv_type_embed, pts_bbox_head.aqr_weight_generator.encoder.layers.0.attentions.0.attn.in_proj_weight, pts_bbox_head.aqr_weight_generator.encoder.layers.0.attentions.0.attn.in_proj_bias, pts_bbox_head.aqr_weight_generator.encoder.layers.0.attentions.0.attn.out_proj.weight, pts_bbox_head.aqr_weight_generator.encoder.layers.0.attentions.0.attn.out_proj.bias, pts_bbox_head.aqr_weight_generator.encoder.layers.0.ffns.0.layers.0.0.weight, pts_bbox_head.aqr_weight_generator.encoder.layers.0.ffns.0.layers.0.0.bias, pts_bbox_head.aqr_weight_generator.encoder.layers.0.ffns.0.layers.1.weight, pts_bbox_head.aqr_weight_generator.encoder.layers.0.ffns.0.layers.1.bias, pts_bbox_head.aqr_weight_generator.encoder.layers.0.norms.0.weight, pts_bbox_head.aqr_weight_generator.encoder.layers.0.norms.0.bias, pts_bbox_head.aqr_weight_generator.encoder.layers.0.norms.1.weight, pts_bbox_head.aqr_weight_generator.encoder.layers.0.norms.1.bias, pts_bbox_head.aqr_weight_generator.encoder.post_norm.weight, pts_bbox_head.aqr_weight_generator.encoder.post_norm.bias, pts_bbox_head.aqr_weight_generator.weight_predictor.weight, pts_bbox_head.aqr_weight_generator.weight_predictor.bias, pts_bbox_head.weight_renderer.gaussian_kernel

2025-10-12 02:27:00,416 - mmdet - INFO - Start running, host: root@fyleanvkgntuufnb-make-789c955558-4v6fw, work_dir: /data/coding/work_dirs/cmt_aqr_voxel0100_r50_800x320_cbgs
2025-10-12 02:27:00,417 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(ABOVE_NORMAL) CustomFp16OptimizerHook            
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CyclicLrUpdaterHook                
(HIGH        ) CyclicMomentumUpdaterHook          
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) CustomFp16OptimizerHook            
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-10-12 02:27:00,417 - mmdet - INFO - workflow: [('train', 1)], max: 1 epochs
2025-10-12 02:27:00,420 - mmdet - INFO - Checkpoints will be saved to /data/coding/work_dirs/cmt_aqr_voxel0100_r50_800x320_cbgs by HardDiskBackend.
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)
  return torch.floor_divide(self, other)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
/data/miniconda/envs/torch/lib/python3.8/site-packages/mmcv/runner/hooks/optimizer.py:55: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  return clip_grad.clip_grad_norm_(params, **self.grad_clip)
2025-10-12 02:29:02,562 - mmdet - INFO - Epoch [1][50/4004]	lr: 1.429e-06, eta: 2:40:54, time: 2.442, data_time: 0.153, memory: 22547, loss_cls: 0.1936, loss_bbox: 1.0405, d0.loss_cls: 0.1734, d0.loss_bbox: 1.0629, d1.loss_cls: 0.1697, d1.loss_bbox: 1.0454, d2.loss_cls: 0.1771, d2.loss_bbox: 1.0374, d3.loss_cls: 0.1798, d3.loss_bbox: 1.0758, d4.loss_cls: 0.1962, d4.loss_bbox: 1.0693, dn_loss_cls: 0.7772, dn_loss_bbox: 1.0617, d0.dn_loss_cls: 0.5920, d0.dn_loss_bbox: 1.1471, d1.dn_loss_cls: 0.6963, d1.dn_loss_bbox: 1.1312, d2.dn_loss_cls: 0.7135, d2.dn_loss_bbox: 1.1205, d3.dn_loss_cls: 0.7513, d3.dn_loss_bbox: 1.1653, d4.dn_loss_cls: 0.8027, d4.dn_loss_bbox: 1.0732, loss: 18.4532, grad_norm: nan
2025-10-12 02:30:40,362 - mmdet - INFO - Epoch [1][100/4004]	lr: 1.517e-06, eta: 2:23:04, time: 1.956, data_time: 0.051, memory: 22547, loss_cls: 0.1652, loss_bbox: 0.9350, d0.loss_cls: 0.1626, d0.loss_bbox: 1.0157, d1.loss_cls: 0.1534, d1.loss_bbox: 0.9604, d2.loss_cls: 0.1573, d2.loss_bbox: 0.9437, d3.loss_cls: 0.1569, d3.loss_bbox: 0.9699, d4.loss_cls: 0.1662, d4.loss_bbox: 0.9534, dn_loss_cls: 0.6520, dn_loss_bbox: 0.9216, d0.dn_loss_cls: 0.5524, d0.dn_loss_bbox: 1.0196, d1.dn_loss_cls: 0.6069, d1.dn_loss_bbox: 0.9815, d2.dn_loss_cls: 0.6170, d2.dn_loss_bbox: 0.9658, d3.dn_loss_cls: 0.6451, d3.dn_loss_bbox: 0.9809, d4.dn_loss_cls: 0.6699, d4.dn_loss_bbox: 0.9331, loss: 16.2855, grad_norm: 257.0284
2025-10-12 02:32:19,641 - mmdet - INFO - Epoch [1][150/4004]	lr: 1.662e-06, eta: 2:16:40, time: 1.986, data_time: 0.046, memory: 22856, loss_cls: 0.1503, loss_bbox: 0.8865, d0.loss_cls: 0.1576, d0.loss_bbox: 0.9955, d1.loss_cls: 0.1487, d1.loss_bbox: 0.9332, d2.loss_cls: 0.1478, d2.loss_bbox: 0.9120, d3.loss_cls: 0.1467, d3.loss_bbox: 0.9210, d4.loss_cls: 0.1524, d4.loss_bbox: 0.9007, dn_loss_cls: 0.5787, dn_loss_bbox: 0.8541, d0.dn_loss_cls: 0.5370, d0.dn_loss_bbox: 0.9427, d1.dn_loss_cls: 0.5694, d1.dn_loss_bbox: 0.9135, d2.dn_loss_cls: 0.5685, d2.dn_loss_bbox: 0.8891, d3.dn_loss_cls: 0.5881, d3.dn_loss_bbox: 0.9106, d4.dn_loss_cls: 0.5948, d4.dn_loss_bbox: 0.8639, loss: 15.2628, grad_norm: 196.7707
2025-10-12 02:33:57,498 - mmdet - INFO - Epoch [1][200/4004]	lr: 1.864e-06, eta: 2:12:11, time: 1.957, data_time: 0.044, memory: 22856, loss_cls: 0.1320, loss_bbox: 0.8296, d0.loss_cls: 0.1479, d0.loss_bbox: 0.9781, d1.loss_cls: 0.1353, d1.loss_bbox: 0.8978, d2.loss_cls: 0.1302, d2.loss_bbox: 0.8603, d3.loss_cls: 0.1285, d3.loss_bbox: 0.8635, d4.loss_cls: 0.1323, d4.loss_bbox: 0.8380, dn_loss_cls: 0.5205, dn_loss_bbox: 0.7884, d0.dn_loss_cls: 0.5179, d0.dn_loss_bbox: 0.8856, d1.dn_loss_cls: 0.5185, d1.dn_loss_bbox: 0.8360, d2.dn_loss_cls: 0.5158, d2.dn_loss_bbox: 0.8120, d3.dn_loss_cls: 0.5276, d3.dn_loss_bbox: 0.8190, d4.dn_loss_cls: 0.5304, d4.dn_loss_bbox: 0.7946, loss: 14.1397, grad_norm: 155.3280
2025-10-12 02:35:36,178 - mmdet - INFO - Epoch [1][250/4004]	lr: 2.117e-06, eta: 2:09:03, time: 1.974, data_time: 0.042, memory: 22856, loss_cls: 0.1274, loss_bbox: 0.7865, d0.loss_cls: 0.1469, d0.loss_bbox: 0.9489, d1.loss_cls: 0.1335, d1.loss_bbox: 0.8609, d2.loss_cls: 0.1270, d2.loss_bbox: 0.8209, d3.loss_cls: 0.1249, d3.loss_bbox: 0.8180, d4.loss_cls: 0.1277, d4.loss_bbox: 0.7955, dn_loss_cls: 0.4953, dn_loss_bbox: 0.7314, d0.dn_loss_cls: 0.5096, d0.dn_loss_bbox: 0.8459, d1.dn_loss_cls: 0.5011, d1.dn_loss_bbox: 0.7899, d2.dn_loss_cls: 0.4970, d2.dn_loss_bbox: 0.7623, d3.dn_loss_cls: 0.5043, d3.dn_loss_bbox: 0.7624, d4.dn_loss_cls: 0.5022, d4.dn_loss_bbox: 0.7423, loss: 13.4619, grad_norm: 300.8627
2025-10-12 02:37:11,828 - mmdet - INFO - Epoch [1][300/4004]	lr: 2.417e-06, eta: 2:05:48, time: 1.913, data_time: 0.042, memory: 22962, loss_cls: 0.1161, loss_bbox: 0.7413, d0.loss_cls: 0.1386, d0.loss_bbox: 0.9163, d1.loss_cls: 0.1240, d1.loss_bbox: 0.8262, d2.loss_cls: 0.1161, d2.loss_bbox: 0.7810, d3.loss_cls: 0.1145, d3.loss_bbox: 0.7733, d4.loss_cls: 0.1160, d4.loss_bbox: 0.7482, dn_loss_cls: 0.4617, dn_loss_bbox: 0.6870, d0.dn_loss_cls: 0.4891, d0.dn_loss_bbox: 0.8034, d1.dn_loss_cls: 0.4736, d1.dn_loss_bbox: 0.7489, d2.dn_loss_cls: 0.4664, d2.dn_loss_bbox: 0.7155, d3.dn_loss_cls: 0.4679, d3.dn_loss_bbox: 0.7125, d4.dn_loss_cls: 0.4656, d4.dn_loss_bbox: 0.6922, loss: 12.6953, grad_norm: 167.9115
2025-10-12 02:38:46,006 - mmdet - INFO - Epoch [1][350/4004]	lr: 2.760e-06, eta: 2:02:45, time: 1.883, data_time: 0.043, memory: 22962, loss_cls: 0.1110, loss_bbox: 0.7156, d0.loss_cls: 0.1335, d0.loss_bbox: 0.8980, d1.loss_cls: 0.1204, d1.loss_bbox: 0.8067, d2.loss_cls: 0.1118, d2.loss_bbox: 0.7578, d3.loss_cls: 0.1103, d3.loss_bbox: 0.7441, d4.loss_cls: 0.1112, d4.loss_bbox: 0.7209, dn_loss_cls: 0.4441, dn_loss_bbox: 0.6556, d0.dn_loss_cls: 0.4790, d0.dn_loss_bbox: 0.7845, d1.dn_loss_cls: 0.4599, d1.dn_loss_bbox: 0.7247, d2.dn_loss_cls: 0.4512, d2.dn_loss_bbox: 0.6878, d3.dn_loss_cls: 0.4514, d3.dn_loss_bbox: 0.6764, d4.dn_loss_cls: 0.4474, d4.dn_loss_bbox: 0.6606, loss: 12.2640, grad_norm: 151.2079
2025-10-12 02:40:19,236 - mmdet - INFO - Epoch [1][400/4004]	lr: 3.139e-06, eta: 1:59:56, time: 1.865, data_time: 0.043, memory: 22962, loss_cls: 0.1076, loss_bbox: 0.6969, d0.loss_cls: 0.1309, d0.loss_bbox: 0.8829, d1.loss_cls: 0.1175, d1.loss_bbox: 0.7912, d2.loss_cls: 0.1082, d2.loss_bbox: 0.7416, d3.loss_cls: 0.1064, d3.loss_bbox: 0.7254, d4.loss_cls: 0.1072, d4.loss_bbox: 0.7031, dn_loss_cls: 0.4329, dn_loss_bbox: 0.6435, d0.dn_loss_cls: 0.4704, d0.dn_loss_bbox: 0.7763, d1.dn_loss_cls: 0.4504, d1.dn_loss_bbox: 0.7123, d2.dn_loss_cls: 0.4410, d2.dn_loss_bbox: 0.6743, d3.dn_loss_cls: 0.4378, d3.dn_loss_bbox: 0.6631, d4.dn_loss_cls: 0.4332, d4.dn_loss_bbox: 0.6475, loss: 12.0013, grad_norm: 103.0234
2025-10-12 02:41:52,464 - mmdet - INFO - Epoch [1][450/4004]	lr: 3.549e-06, eta: 1:57:24, time: 1.865, data_time: 0.044, memory: 22962, loss_cls: 0.1029, loss_bbox: 0.6775, d0.loss_cls: 0.1273, d0.loss_bbox: 0.8595, d1.loss_cls: 0.1148, d1.loss_bbox: 0.7659, d2.loss_cls: 0.1047, d2.loss_bbox: 0.7195, d3.loss_cls: 0.1026, d3.loss_bbox: 0.7007, d4.loss_cls: 0.1026, d4.loss_bbox: 0.6803, dn_loss_cls: 0.4207, dn_loss_bbox: 0.6116, d0.dn_loss_cls: 0.4621, d0.dn_loss_bbox: 0.7493, d1.dn_loss_cls: 0.4406, d1.dn_loss_bbox: 0.6796, d2.dn_loss_cls: 0.4321, d2.dn_loss_bbox: 0.6445, d3.dn_loss_cls: 0.4253, d3.dn_loss_bbox: 0.6292, d4.dn_loss_cls: 0.4214, d4.dn_loss_bbox: 0.6143, loss: 11.5888, grad_norm: 75.5816
2025-10-12 02:43:25,876 - mmdet - INFO - Epoch [1][500/4004]	lr: 3.982e-06, eta: 1:55:05, time: 1.868, data_time: 0.043, memory: 22962, loss_cls: 0.0982, loss_bbox: 0.6604, d0.loss_cls: 0.1221, d0.loss_bbox: 0.8471, d1.loss_cls: 0.1097, d1.loss_bbox: 0.7529, d2.loss_cls: 0.1004, d2.loss_bbox: 0.7054, d3.loss_cls: 0.0982, d3.loss_bbox: 0.6845, d4.loss_cls: 0.0979, d4.loss_bbox: 0.6672, dn_loss_cls: 0.4128, dn_loss_bbox: 0.5942, d0.dn_loss_cls: 0.4573, d0.dn_loss_bbox: 0.7366, d1.dn_loss_cls: 0.4347, d1.dn_loss_bbox: 0.6673, d2.dn_loss_cls: 0.4243, d2.dn_loss_bbox: 0.6310, d3.dn_loss_cls: 0.4171, d3.dn_loss_bbox: 0.6100, d4.dn_loss_cls: 0.4137, d4.dn_loss_bbox: 0.5981, loss: 11.3408, grad_norm: 79.7005
2025-10-12 02:45:00,239 - mmdet - INFO - Epoch [1][550/4004]	lr: 4.430e-06, eta: 1:53:00, time: 1.887, data_time: 0.045, memory: 22962, loss_cls: 0.0998, loss_bbox: 0.6595, d0.loss_cls: 0.1234, d0.loss_bbox: 0.8380, d1.loss_cls: 0.1123, d1.loss_bbox: 0.7481, d2.loss_cls: 0.1022, d2.loss_bbox: 0.7023, d3.loss_cls: 0.1002, d3.loss_bbox: 0.6806, d4.loss_cls: 0.0997, d4.loss_bbox: 0.6647, dn_loss_cls: 0.4100, dn_loss_bbox: 0.5914, d0.dn_loss_cls: 0.4550, d0.dn_loss_bbox: 0.7318, d1.dn_loss_cls: 0.4322, d1.dn_loss_bbox: 0.6620, d2.dn_loss_cls: 0.4215, d2.dn_loss_bbox: 0.6264, d3.dn_loss_cls: 0.4147, d3.dn_loss_bbox: 0.6068, d4.dn_loss_cls: 0.4112, d4.dn_loss_bbox: 0.5950, loss: 11.2888, grad_norm: 91.4455
2025-10-12 02:46:40,556 - mmdet - INFO - Epoch [1][600/4004]	lr: 4.886e-06, eta: 1:51:35, time: 2.007, data_time: 0.043, memory: 22962, loss_cls: 0.0945, loss_bbox: 0.6329, d0.loss_cls: 0.1177, d0.loss_bbox: 0.8090, d1.loss_cls: 0.1068, d1.loss_bbox: 0.7234, d2.loss_cls: 0.0972, d2.loss_bbox: 0.6774, d3.loss_cls: 0.0945, d3.loss_bbox: 0.6533, d4.loss_cls: 0.0942, d4.loss_bbox: 0.6367, dn_loss_cls: 0.3994, dn_loss_bbox: 0.5662, d0.dn_loss_cls: 0.4449, d0.dn_loss_bbox: 0.7045, d1.dn_loss_cls: 0.4238, d1.dn_loss_bbox: 0.6395, d2.dn_loss_cls: 0.4136, d2.dn_loss_bbox: 0.6055, d3.dn_loss_cls: 0.4032, d3.dn_loss_bbox: 0.5806, d4.dn_loss_cls: 0.3999, d4.dn_loss_bbox: 0.5695, loss: 10.8882, grad_norm: 74.6530
2025-10-12 02:48:12,788 - mmdet - INFO - Epoch [1][650/4004]	lr: 5.343e-06, eta: 1:49:25, time: 1.845, data_time: 0.042, memory: 22962, loss_cls: 0.0913, loss_bbox: 0.6286, d0.loss_cls: 0.1150, d0.loss_bbox: 0.8015, d1.loss_cls: 0.1042, d1.loss_bbox: 0.7158, d2.loss_cls: 0.0943, d2.loss_bbox: 0.6734, d3.loss_cls: 0.0913, d3.loss_bbox: 0.6491, d4.loss_cls: 0.0911, d4.loss_bbox: 0.6333, dn_loss_cls: 0.3966, dn_loss_bbox: 0.5576, d0.dn_loss_cls: 0.4439, d0.dn_loss_bbox: 0.6950, d1.dn_loss_cls: 0.4219, d1.dn_loss_bbox: 0.6307, d2.dn_loss_cls: 0.4110, d2.dn_loss_bbox: 0.5972, d3.dn_loss_cls: 0.4015, d3.dn_loss_bbox: 0.5726, d4.dn_loss_cls: 0.3976, d4.dn_loss_bbox: 0.5609, loss: 10.7754, grad_norm: 62.9414
2025-10-12 02:49:44,405 - mmdet - INFO - Epoch [1][700/4004]	lr: 5.792e-06, eta: 1:47:17, time: 1.832, data_time: 0.043, memory: 22962, loss_cls: 0.0933, loss_bbox: 0.6412, d0.loss_cls: 0.1154, d0.loss_bbox: 0.8173, d1.loss_cls: 0.1056, d1.loss_bbox: 0.7287, d2.loss_cls: 0.0961, d2.loss_bbox: 0.6851, d3.loss_cls: 0.0936, d3.loss_bbox: 0.6593, d4.loss_cls: 0.0932, d4.loss_bbox: 0.6456, dn_loss_cls: 0.3965, dn_loss_bbox: 0.5712, d0.dn_loss_cls: 0.4419, d0.dn_loss_bbox: 0.7095, d1.dn_loss_cls: 0.4206, d1.dn_loss_bbox: 0.6442, d2.dn_loss_cls: 0.4105, d2.dn_loss_bbox: 0.6104, d3.dn_loss_cls: 0.4010, d3.dn_loss_bbox: 0.5859, d4.dn_loss_cls: 0.3973, d4.dn_loss_bbox: 0.5747, loss: 10.9379, grad_norm: 55.0497
2025-10-12 02:51:17,906 - mmdet - INFO - Epoch [1][750/4004]	lr: 6.226e-06, eta: 1:45:23, time: 1.870, data_time: 0.043, memory: 22962, loss_cls: 0.0905, loss_bbox: 0.6356, d0.loss_cls: 0.1124, d0.loss_bbox: 0.8116, d1.loss_cls: 0.1029, d1.loss_bbox: 0.7256, d2.loss_cls: 0.0938, d2.loss_bbox: 0.6797, d3.loss_cls: 0.0908, d3.loss_bbox: 0.6544, d4.loss_cls: 0.0905, d4.loss_bbox: 0.6402, dn_loss_cls: 0.3935, dn_loss_bbox: 0.5600, d0.dn_loss_cls: 0.4383, d0.dn_loss_bbox: 0.6972, d1.dn_loss_cls: 0.4181, d1.dn_loss_bbox: 0.6332, d2.dn_loss_cls: 0.4076, d2.dn_loss_bbox: 0.5985, d3.dn_loss_cls: 0.3978, d3.dn_loss_bbox: 0.5735, d4.dn_loss_cls: 0.3947, d4.dn_loss_bbox: 0.5637, loss: 10.8042, grad_norm: 52.5979
2025-10-12 02:52:52,578 - mmdet - INFO - Epoch [1][800/4004]	lr: 6.637e-06, eta: 1:43:36, time: 1.894, data_time: 0.045, memory: 22962, loss_cls: 0.0939, loss_bbox: 0.6473, d0.loss_cls: 0.1164, d0.loss_bbox: 0.8219, d1.loss_cls: 0.1063, d1.loss_bbox: 0.7346, d2.loss_cls: 0.0977, d2.loss_bbox: 0.6876, d3.loss_cls: 0.0942, d3.loss_bbox: 0.6642, d4.loss_cls: 0.0939, d4.loss_bbox: 0.6507, dn_loss_cls: 0.3949, dn_loss_bbox: 0.5679, d0.dn_loss_cls: 0.4389, d0.dn_loss_bbox: 0.7106, d1.dn_loss_cls: 0.4186, d1.dn_loss_bbox: 0.6434, d2.dn_loss_cls: 0.4084, d2.dn_loss_bbox: 0.6077, d3.dn_loss_cls: 0.3997, d3.dn_loss_bbox: 0.5819, d4.dn_loss_cls: 0.3958, d4.dn_loss_bbox: 0.5710, loss: 10.9478, grad_norm: 51.7140
2025-10-12 02:54:23,777 - mmdet - INFO - Epoch [1][850/4004]	lr: 7.018e-06, eta: 1:41:37, time: 1.824, data_time: 0.046, memory: 22962, loss_cls: 0.0897, loss_bbox: 0.6252, d0.loss_cls: 0.1120, d0.loss_bbox: 0.7975, d1.loss_cls: 0.1020, d1.loss_bbox: 0.7100, d2.loss_cls: 0.0931, d2.loss_bbox: 0.6647, d3.loss_cls: 0.0900, d3.loss_bbox: 0.6421, d4.loss_cls: 0.0896, d4.loss_bbox: 0.6285, dn_loss_cls: 0.3897, dn_loss_bbox: 0.5526, d0.dn_loss_cls: 0.4348, d0.dn_loss_bbox: 0.6905, d1.dn_loss_cls: 0.4140, d1.dn_loss_bbox: 0.6252, d2.dn_loss_cls: 0.4045, d2.dn_loss_bbox: 0.5914, d3.dn_loss_cls: 0.3943, d3.dn_loss_bbox: 0.5655, d4.dn_loss_cls: 0.3905, d4.dn_loss_bbox: 0.5553, loss: 10.6527, grad_norm: 49.4330
2025-10-12 02:55:55,599 - mmdet - INFO - Epoch [1][900/4004]	lr: 7.364e-06, eta: 1:39:44, time: 1.836, data_time: 0.045, memory: 22962, loss_cls: 0.0894, loss_bbox: 0.6163, d0.loss_cls: 0.1117, d0.loss_bbox: 0.7845, d1.loss_cls: 0.1018, d1.loss_bbox: 0.7011, d2.loss_cls: 0.0928, d2.loss_bbox: 0.6574, d3.loss_cls: 0.0895, d3.loss_bbox: 0.6337, d4.loss_cls: 0.0893, d4.loss_bbox: 0.6197, dn_loss_cls: 0.3878, dn_loss_bbox: 0.5415, d0.dn_loss_cls: 0.4321, d0.dn_loss_bbox: 0.6779, d1.dn_loss_cls: 0.4126, d1.dn_loss_bbox: 0.6158, d2.dn_loss_cls: 0.4021, d2.dn_loss_bbox: 0.5821, d3.dn_loss_cls: 0.3922, d3.dn_loss_bbox: 0.5553, d4.dn_loss_cls: 0.3887, d4.dn_loss_bbox: 0.5444, loss: 10.5197, grad_norm: 46.4800
2025-10-12 02:57:27,696 - mmdet - INFO - Epoch [1][950/4004]	lr: 7.667e-06, eta: 1:37:54, time: 1.842, data_time: 0.047, memory: 22962, loss_cls: 0.0913, loss_bbox: 0.6292, d0.loss_cls: 0.1146, d0.loss_bbox: 0.7984, d1.loss_cls: 0.1044, d1.loss_bbox: 0.7133, d2.loss_cls: 0.0953, d2.loss_bbox: 0.6678, d3.loss_cls: 0.0918, d3.loss_bbox: 0.6445, d4.loss_cls: 0.0915, d4.loss_bbox: 0.6319, dn_loss_cls: 0.3905, dn_loss_bbox: 0.5487, d0.dn_loss_cls: 0.4356, d0.dn_loss_bbox: 0.6852, d1.dn_loss_cls: 0.4153, d1.dn_loss_bbox: 0.6223, d2.dn_loss_cls: 0.4053, d2.dn_loss_bbox: 0.5893, d3.dn_loss_cls: 0.3950, d3.dn_loss_bbox: 0.5617, d4.dn_loss_cls: 0.3914, d4.dn_loss_bbox: 0.5514, loss: 10.6659, grad_norm: 60.3829

üîç AQR Debug Info (Forward #1000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.019085
     std: 0.111087
     min: -8.158565
     max: 6.188046
   lidar_weights_stats:
     mean: 0.679115
     std: 0.178313
     min: 0.103533
     max: 0.988862
     shape: [4, 1270]
   camera_weights_stats:
     mean: 0.759535
     std: 0.167935
     min: 0.137807
     max: 0.991912
     shape: [4, 1270]
   weight_map_bev_stats:
     mean: 0.045886
     std: 0.087969
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.155325
     std: 0.526662
     min: 0.000000
     max: 27.524223
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013250
     std_change: 0.062471
     max_change: 3.418158
     relative_change: 0.072878
   modulation_effect_pers:
     mean_change: -0.004387
     std_change: 0.051712
     max_change: 7.869502
     relative_change: 0.291145

üîç AQR Debug Info (Forward #1000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.020071
     std: 0.114913
     min: -7.020677
     max: 8.505651
   lidar_weights_stats:
     mean: 0.748473
     std: 0.150444
     min: 0.105060
     max: 0.987983
     shape: [4, 1290]
   camera_weights_stats:
     mean: 0.727399
     std: 0.174881
     min: 0.073528
     max: 0.995542
     shape: [4, 1290]
   weight_map_bev_stats:
     mean: 0.049965
     std: 0.087320
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.150308
     std: 0.531833
     min: 0.000000
     max: 35.290852
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.012989
     std_change: 0.061587
     max_change: 1.847637
     relative_change: 0.066287
   modulation_effect_pers:
     mean_change: -0.004678
     std_change: 0.051563
     max_change: 8.269322
     relative_change: 0.280610

üîç AQR Debug Info (Forward #1000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.019717
     std: 0.117164
     min: -15.141777
     max: 13.824682
   lidar_weights_stats:
     mean: 0.727674
     std: 0.153613
     min: 0.109098
     max: 0.973786
     shape: [4, 1270]
   camera_weights_stats:
     mean: 0.724799
     std: 0.194995
     min: 0.118206
     max: 0.996190
     shape: [4, 1270]
   weight_map_bev_stats:
     mean: 0.048597
     std: 0.097556
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.145801
     std: 0.432082
     min: 0.000000
     max: 18.989117
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013156
     std_change: 0.059914
     max_change: 2.002528
     relative_change: 0.070124
   modulation_effect_pers:
     mean_change: -0.004562
     std_change: 0.056707
     max_change: 14.372734
     relative_change: 0.278149

üîç AQR Debug Info (Forward #1000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.020221
     std: 0.135187
     min: -17.316488
     max: 16.856251
   lidar_weights_stats:
     mean: 0.721250
     std: 0.161850
     min: 0.144524
     max: 0.985762
     shape: [4, 1380]
   camera_weights_stats:
     mean: 0.757528
     std: 0.169465
     min: 0.066618
     max: 0.993042
     shape: [4, 1380]
   weight_map_bev_stats:
     mean: 0.049604
     std: 0.100545
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.166718
     std: 0.827760
     min: 0.000000
     max: 58.210583
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.012963
     std_change: 0.060203
     max_change: 2.235073
     relative_change: 0.068935
   modulation_effect_pers:
     mean_change: -0.004160
     std_change: 0.083517
     max_change: 17.022543
     relative_change: 0.297342

üîç AQR Debug Info (Forward #1000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.019766
     std: 0.125006
     min: -13.718095
     max: 13.670773
   lidar_weights_stats:
     mean: 0.722644
     std: 0.153243
     min: 0.106425
     max: 0.985613
     shape: [4, 1370]
   camera_weights_stats:
     mean: 0.730097
     std: 0.163532
     min: 0.142501
     max: 0.994632
     shape: [4, 1370]
   weight_map_bev_stats:
     mean: 0.045933
     std: 0.083793
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.160692
     std: 0.768786
     min: 0.000000
     max: 41.181427
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013749
     std_change: 0.060285
     max_change: 2.502409
     relative_change: 0.073366
   modulation_effect_pers:
     mean_change: -0.004212
     std_change: 0.071174
     max_change: 13.309200
     relative_change: 0.295864

üîç AQR Debug Info (Forward #1000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.020703
     std: 0.174626
     min: -25.931633
     max: 26.434616
   lidar_weights_stats:
     mean: 0.707384
     std: 0.171212
     min: 0.095337
     max: 0.978087
     shape: [4, 1660]
   camera_weights_stats:
     mean: 0.792618
     std: 0.153166
     min: 0.062164
     max: 0.993463
     shape: [4, 1660]
   weight_map_bev_stats:
     mean: 0.051828
     std: 0.100727
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.210093
     std: 1.429407
     min: 0.000000
     max: 75.604576
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.012915
     std_change: 0.059312
     max_change: 2.819098
     relative_change: 0.071202
   modulation_effect_pers:
     mean_change: -0.003984
     std_change: 0.131141
     max_change: 26.088181
     relative_change: 0.337077

üîç AQR Debug Info (Forward #1000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.020200
     std: 0.161578
     min: -19.475306
     max: 21.530397
   lidar_weights_stats:
     mean: 0.728310
     std: 0.142190
     min: 0.108720
     max: 0.979824
     shape: [4, 1720]
   camera_weights_stats:
     mean: 0.749165
     std: 0.161812
     min: 0.126718
     max: 0.996335
     shape: [4, 1720]
   weight_map_bev_stats:
     mean: 0.052568
     std: 0.116973
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.208694
     std: 1.430399
     min: 0.000000
     max: 79.230713
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013084
     std_change: 0.061315
     max_change: 2.423464
     relative_change: 0.068880
   modulation_effect_pers:
     mean_change: -0.003430
     std_change: 0.122693
     max_change: 21.207888
     relative_change: 0.339697

üîç AQR Debug Info (Forward #1000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.020665
     std: 0.210331
     min: -61.544991
     max: 73.891121
   lidar_weights_stats:
     mean: 0.731138
     std: 0.143444
     min: 0.085959
     max: 0.980906
     shape: [4, 1790]
   camera_weights_stats:
     mean: 0.774141
     std: 0.155380
     min: 0.116944
     max: 0.992530
     shape: [4, 1790]
   weight_map_bev_stats:
     mean: 0.055815
     std: 0.133054
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.222695
     std: 1.682724
     min: 0.000000
     max: 94.355911
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.012670
     std_change: 0.062985
     max_change: 3.072341
     relative_change: 0.069300
   modulation_effect_pers:
     mean_change: -0.003095
     std_change: 0.180548
     max_change: 73.113777
     relative_change: 0.357754
2025-10-12 02:58:59,793 - mmdet - INFO - Exp name: cmt_aqr_voxel0100_r50_800x320_cbgs.py
2025-10-12 02:58:59,793 - mmdet - INFO - Epoch [1][1000/4004]	lr: 7.923e-06, eta: 1:36:05, time: 1.842, data_time: 0.047, memory: 22962, loss_cls: 0.0935, loss_bbox: 0.6466, d0.loss_cls: 0.1156, d0.loss_bbox: 0.8238, d1.loss_cls: 0.1060, d1.loss_bbox: 0.7359, d2.loss_cls: 0.0974, d2.loss_bbox: 0.6885, d3.loss_cls: 0.0938, d3.loss_bbox: 0.6623, d4.loss_cls: 0.0935, d4.loss_bbox: 0.6504, dn_loss_cls: 0.3914, dn_loss_bbox: 0.5651, d0.dn_loss_cls: 0.4375, d0.dn_loss_bbox: 0.7069, d1.dn_loss_cls: 0.4174, d1.dn_loss_bbox: 0.6405, d2.dn_loss_cls: 0.4064, d2.dn_loss_bbox: 0.6058, d3.dn_loss_cls: 0.3953, d3.dn_loss_bbox: 0.5777, d4.dn_loss_cls: 0.3921, d4.dn_loss_bbox: 0.5681, loss: 10.9117, grad_norm: 47.1990
2025-10-12 03:00:36,063 - mmdet - INFO - Epoch [1][1050/4004]	lr: 8.127e-06, eta: 1:34:30, time: 1.925, data_time: 0.045, memory: 22962, loss_cls: 0.0887, loss_bbox: 0.6144, d0.loss_cls: 0.1103, d0.loss_bbox: 0.7802, d1.loss_cls: 0.1010, d1.loss_bbox: 0.6959, d2.loss_cls: 0.0920, d2.loss_bbox: 0.6550, d3.loss_cls: 0.0889, d3.loss_bbox: 0.6299, d4.loss_cls: 0.0886, d4.loss_bbox: 0.6176, dn_loss_cls: 0.3861, dn_loss_bbox: 0.5404, d0.dn_loss_cls: 0.4305, d0.dn_loss_bbox: 0.6753, d1.dn_loss_cls: 0.4104, d1.dn_loss_bbox: 0.6122, d2.dn_loss_cls: 0.4006, d2.dn_loss_bbox: 0.5794, d3.dn_loss_cls: 0.3902, d3.dn_loss_bbox: 0.5535, d4.dn_loss_cls: 0.3869, d4.dn_loss_bbox: 0.5432, loss: 10.4713, grad_norm: 47.8512
2025-10-12 03:02:09,974 - mmdet - INFO - Epoch [1][1100/4004]	lr: 8.276e-06, eta: 1:32:49, time: 1.879, data_time: 0.045, memory: 22962, loss_cls: 0.0896, loss_bbox: 0.6166, d0.loss_cls: 0.1120, d0.loss_bbox: 0.7765, d1.loss_cls: 0.1024, d1.loss_bbox: 0.6960, d2.loss_cls: 0.0930, d2.loss_bbox: 0.6576, d3.loss_cls: 0.0899, d3.loss_bbox: 0.6321, d4.loss_cls: 0.0897, d4.loss_bbox: 0.6201, dn_loss_cls: 0.3830, dn_loss_bbox: 0.5416, d0.dn_loss_cls: 0.4283, d0.dn_loss_bbox: 0.6760, d1.dn_loss_cls: 0.4080, d1.dn_loss_bbox: 0.6141, d2.dn_loss_cls: 0.3978, d2.dn_loss_bbox: 0.5811, d3.dn_loss_cls: 0.3876, d3.dn_loss_bbox: 0.5541, d4.dn_loss_cls: 0.3839, d4.dn_loss_bbox: 0.5441, loss: 10.4752, grad_norm: 70.0754
2025-10-12 03:03:41,929 - mmdet - INFO - Epoch [1][1150/4004]	lr: 8.368e-06, eta: 1:31:03, time: 1.839, data_time: 0.046, memory: 22962, loss_cls: 0.0890, loss_bbox: 0.6193, d0.loss_cls: 0.1105, d0.loss_bbox: 0.7875, d1.loss_cls: 0.1011, d1.loss_bbox: 0.7036, d2.loss_cls: 0.0921, d2.loss_bbox: 0.6613, d3.loss_cls: 0.0893, d3.loss_bbox: 0.6353, d4.loss_cls: 0.0889, d4.loss_bbox: 0.6235, dn_loss_cls: 0.3834, dn_loss_bbox: 0.5476, d0.dn_loss_cls: 0.4280, d0.dn_loss_bbox: 0.6874, d1.dn_loss_cls: 0.4079, d1.dn_loss_bbox: 0.6231, d2.dn_loss_cls: 0.3973, d2.dn_loss_bbox: 0.5875, d3.dn_loss_cls: 0.3877, d3.dn_loss_bbox: 0.5603, d4.dn_loss_cls: 0.3844, d4.dn_loss_bbox: 0.5503, loss: 10.5462, grad_norm: 46.3117
2025-10-12 03:05:14,001 - mmdet - INFO - Epoch [1][1200/4004]	lr: 8.400e-06, eta: 1:29:19, time: 1.841, data_time: 0.046, memory: 22962, loss_cls: 0.0882, loss_bbox: 0.6177, d0.loss_cls: 0.1108, d0.loss_bbox: 0.7836, d1.loss_cls: 0.1010, d1.loss_bbox: 0.7044, d2.loss_cls: 0.0921, d2.loss_bbox: 0.6594, d3.loss_cls: 0.0885, d3.loss_bbox: 0.6340, d4.loss_cls: 0.0882, d4.loss_bbox: 0.6206, dn_loss_cls: 0.3841, dn_loss_bbox: 0.5437, d0.dn_loss_cls: 0.4303, d0.dn_loss_bbox: 0.6837, d1.dn_loss_cls: 0.4092, d1.dn_loss_bbox: 0.6199, d2.dn_loss_cls: 0.3989, d2.dn_loss_bbox: 0.5848, d3.dn_loss_cls: 0.3884, d3.dn_loss_bbox: 0.5570, d4.dn_loss_cls: 0.3850, d4.dn_loss_bbox: 0.5464, loss: 10.5201, grad_norm: 49.3938
2025-10-12 03:06:45,756 - mmdet - INFO - Epoch [1][1250/4004]	lr: 8.394e-06, eta: 1:27:35, time: 1.835, data_time: 0.046, memory: 22962, loss_cls: 0.0880, loss_bbox: 0.6124, d0.loss_cls: 0.1105, d0.loss_bbox: 0.7719, d1.loss_cls: 0.1008, d1.loss_bbox: 0.6923, d2.loss_cls: 0.0918, d2.loss_bbox: 0.6512, d3.loss_cls: 0.0885, d3.loss_bbox: 0.6270, d4.loss_cls: 0.0882, d4.loss_bbox: 0.6148, dn_loss_cls: 0.3818, dn_loss_bbox: 0.5357, d0.dn_loss_cls: 0.4260, d0.dn_loss_bbox: 0.6687, d1.dn_loss_cls: 0.4063, d1.dn_loss_bbox: 0.6080, d2.dn_loss_cls: 0.3962, d2.dn_loss_bbox: 0.5757, d3.dn_loss_cls: 0.3858, d3.dn_loss_bbox: 0.5480, d4.dn_loss_cls: 0.3826, d4.dn_loss_bbox: 0.5384, loss: 10.3905, grad_norm: 48.0871
2025-10-12 03:08:17,581 - mmdet - INFO - Epoch [1][1300/4004]	lr: 8.375e-06, eta: 1:25:52, time: 1.836, data_time: 0.045, memory: 22962, loss_cls: 0.0894, loss_bbox: 0.6258, d0.loss_cls: 0.1117, d0.loss_bbox: 0.7977, d1.loss_cls: 0.1023, d1.loss_bbox: 0.7095, d2.loss_cls: 0.0932, d2.loss_bbox: 0.6662, d3.loss_cls: 0.0896, d3.loss_bbox: 0.6421, d4.loss_cls: 0.0892, d4.loss_bbox: 0.6295, dn_loss_cls: 0.3846, dn_loss_bbox: 0.5450, d0.dn_loss_cls: 0.4313, d0.dn_loss_bbox: 0.6851, d1.dn_loss_cls: 0.4103, d1.dn_loss_bbox: 0.6194, d2.dn_loss_cls: 0.4000, d2.dn_loss_bbox: 0.5862, d3.dn_loss_cls: 0.3893, d3.dn_loss_bbox: 0.5580, d4.dn_loss_cls: 0.3853, d4.dn_loss_bbox: 0.5477, loss: 10.5884, grad_norm: 51.2483
2025-10-12 03:09:48,870 - mmdet - INFO - Epoch [1][1350/4004]	lr: 8.342e-06, eta: 1:24:09, time: 1.826, data_time: 0.044, memory: 22962, loss_cls: 0.0860, loss_bbox: 0.6141, d0.loss_cls: 0.1088, d0.loss_bbox: 0.7788, d1.loss_cls: 0.0990, d1.loss_bbox: 0.6972, d2.loss_cls: 0.0899, d2.loss_bbox: 0.6533, d3.loss_cls: 0.0864, d3.loss_bbox: 0.6296, d4.loss_cls: 0.0861, d4.loss_bbox: 0.6170, dn_loss_cls: 0.3808, dn_loss_bbox: 0.5351, d0.dn_loss_cls: 0.4255, d0.dn_loss_bbox: 0.6736, d1.dn_loss_cls: 0.4054, d1.dn_loss_bbox: 0.6102, d2.dn_loss_cls: 0.3953, d2.dn_loss_bbox: 0.5764, d3.dn_loss_cls: 0.3849, d3.dn_loss_bbox: 0.5479, d4.dn_loss_cls: 0.3817, d4.dn_loss_bbox: 0.5378, loss: 10.4009, grad_norm: 48.3349
2025-10-12 03:11:23,439 - mmdet - INFO - Epoch [1][1400/4004]	lr: 8.297e-06, eta: 1:22:33, time: 1.891, data_time: 0.044, memory: 22962, loss_cls: 0.0870, loss_bbox: 0.6086, d0.loss_cls: 0.1095, d0.loss_bbox: 0.7744, d1.loss_cls: 0.1003, d1.loss_bbox: 0.6947, d2.loss_cls: 0.0909, d2.loss_bbox: 0.6496, d3.loss_cls: 0.0874, d3.loss_bbox: 0.6250, d4.loss_cls: 0.0872, d4.loss_bbox: 0.6116, dn_loss_cls: 0.3823, dn_loss_bbox: 0.5315, d0.dn_loss_cls: 0.4273, d0.dn_loss_bbox: 0.6698, d1.dn_loss_cls: 0.4074, d1.dn_loss_bbox: 0.6070, d2.dn_loss_cls: 0.3976, d2.dn_loss_bbox: 0.5732, d3.dn_loss_cls: 0.3867, d3.dn_loss_bbox: 0.5444, d4.dn_loss_cls: 0.3830, d4.dn_loss_bbox: 0.5341, loss: 10.3703, grad_norm: 44.0698
2025-10-12 03:13:03,841 - mmdet - INFO - Epoch [1][1450/4004]	lr: 8.239e-06, eta: 1:21:07, time: 2.008, data_time: 0.042, memory: 22962, loss_cls: 0.0869, loss_bbox: 0.6201, d0.loss_cls: 0.1093, d0.loss_bbox: 0.7885, d1.loss_cls: 0.0997, d1.loss_bbox: 0.7039, d2.loss_cls: 0.0907, d2.loss_bbox: 0.6601, d3.loss_cls: 0.0871, d3.loss_bbox: 0.6359, d4.loss_cls: 0.0869, d4.loss_bbox: 0.6235, dn_loss_cls: 0.3817, dn_loss_bbox: 0.5424, d0.dn_loss_cls: 0.4267, d0.dn_loss_bbox: 0.6799, d1.dn_loss_cls: 0.4064, d1.dn_loss_bbox: 0.6166, d2.dn_loss_cls: 0.3966, d2.dn_loss_bbox: 0.5825, d3.dn_loss_cls: 0.3861, d3.dn_loss_bbox: 0.5548, d4.dn_loss_cls: 0.3824, d4.dn_loss_bbox: 0.5450, loss: 10.4939, grad_norm: 47.6822
2025-10-12 03:14:40,922 - mmdet - INFO - Epoch [1][1500/4004]	lr: 8.168e-06, eta: 1:19:35, time: 1.942, data_time: 0.041, memory: 22962, loss_cls: 0.0883, loss_bbox: 0.6218, d0.loss_cls: 0.1108, d0.loss_bbox: 0.7913, d1.loss_cls: 0.1014, d1.loss_bbox: 0.7066, d2.loss_cls: 0.0923, d2.loss_bbox: 0.6641, d3.loss_cls: 0.0886, d3.loss_bbox: 0.6374, d4.loss_cls: 0.0884, d4.loss_bbox: 0.6251, dn_loss_cls: 0.3828, dn_loss_bbox: 0.5413, d0.dn_loss_cls: 0.4276, d0.dn_loss_bbox: 0.6805, d1.dn_loss_cls: 0.4079, d1.dn_loss_bbox: 0.6174, d2.dn_loss_cls: 0.3979, d2.dn_loss_bbox: 0.5838, d3.dn_loss_cls: 0.3872, d3.dn_loss_bbox: 0.5542, d4.dn_loss_cls: 0.3835, d4.dn_loss_bbox: 0.5439, loss: 10.5239, grad_norm: 47.7554
2025-10-12 03:16:14,649 - mmdet - INFO - Epoch [1][1550/4004]	lr: 8.085e-06, eta: 1:17:57, time: 1.874, data_time: 0.040, memory: 22962, loss_cls: 0.0856, loss_bbox: 0.6170, d0.loss_cls: 0.1071, d0.loss_bbox: 0.7807, d1.loss_cls: 0.0981, d1.loss_bbox: 0.7008, d2.loss_cls: 0.0891, d2.loss_bbox: 0.6584, d3.loss_cls: 0.0858, d3.loss_bbox: 0.6336, d4.loss_cls: 0.0857, d4.loss_bbox: 0.6203, dn_loss_cls: 0.3815, dn_loss_bbox: 0.5430, d0.dn_loss_cls: 0.4265, d0.dn_loss_bbox: 0.6803, d1.dn_loss_cls: 0.4063, d1.dn_loss_bbox: 0.6168, d2.dn_loss_cls: 0.3964, d2.dn_loss_bbox: 0.5830, d3.dn_loss_cls: 0.3856, d3.dn_loss_bbox: 0.5554, d4.dn_loss_cls: 0.3824, d4.dn_loss_bbox: 0.5458, loss: 10.4650, grad_norm: 52.7354
2025-10-12 03:17:52,303 - mmdet - INFO - Epoch [1][1600/4004]	lr: 7.989e-06, eta: 1:16:25, time: 1.953, data_time: 0.041, memory: 22962, loss_cls: 0.0869, loss_bbox: 0.6085, d0.loss_cls: 0.1087, d0.loss_bbox: 0.7760, d1.loss_cls: 0.0996, d1.loss_bbox: 0.6931, d2.loss_cls: 0.0903, d2.loss_bbox: 0.6509, d3.loss_cls: 0.0870, d3.loss_bbox: 0.6257, d4.loss_cls: 0.0869, d4.loss_bbox: 0.6126, dn_loss_cls: 0.3813, dn_loss_bbox: 0.5315, d0.dn_loss_cls: 0.4256, d0.dn_loss_bbox: 0.6689, d1.dn_loss_cls: 0.4060, d1.dn_loss_bbox: 0.6059, d2.dn_loss_cls: 0.3960, d2.dn_loss_bbox: 0.5719, d3.dn_loss_cls: 0.3855, d3.dn_loss_bbox: 0.5439, d4.dn_loss_cls: 0.3821, d4.dn_loss_bbox: 0.5341, loss: 10.3590, grad_norm: 47.0914
2025-10-12 03:19:25,724 - mmdet - INFO - Epoch [1][1650/4004]	lr: 7.882e-06, eta: 1:14:47, time: 1.868, data_time: 0.043, memory: 22962, loss_cls: 0.0900, loss_bbox: 0.6271, d0.loss_cls: 0.1125, d0.loss_bbox: 0.8025, d1.loss_cls: 0.1031, d1.loss_bbox: 0.7129, d2.loss_cls: 0.0940, d2.loss_bbox: 0.6687, d3.loss_cls: 0.0900, d3.loss_bbox: 0.6435, d4.loss_cls: 0.0900, d4.loss_bbox: 0.6303, dn_loss_cls: 0.3850, dn_loss_bbox: 0.5432, d0.dn_loss_cls: 0.4295, d0.dn_loss_bbox: 0.6858, d1.dn_loss_cls: 0.4100, d1.dn_loss_bbox: 0.6198, d2.dn_loss_cls: 0.4003, d2.dn_loss_bbox: 0.5848, d3.dn_loss_cls: 0.3892, d3.dn_loss_bbox: 0.5553, d4.dn_loss_cls: 0.3858, d4.dn_loss_bbox: 0.5454, loss: 10.5984, grad_norm: 53.1398
2025-10-12 03:20:59,766 - mmdet - INFO - Epoch [1][1700/4004]	lr: 7.763e-06, eta: 1:13:10, time: 1.880, data_time: 0.043, memory: 22962, loss_cls: 0.0875, loss_bbox: 0.6167, d0.loss_cls: 0.1102, d0.loss_bbox: 0.7896, d1.loss_cls: 0.1001, d1.loss_bbox: 0.7017, d2.loss_cls: 0.0912, d2.loss_bbox: 0.6582, d3.loss_cls: 0.0879, d3.loss_bbox: 0.6336, d4.loss_cls: 0.0875, d4.loss_bbox: 0.6213, dn_loss_cls: 0.3803, dn_loss_bbox: 0.5428, d0.dn_loss_cls: 0.4249, d0.dn_loss_bbox: 0.6849, d1.dn_loss_cls: 0.4053, d1.dn_loss_bbox: 0.6183, d2.dn_loss_cls: 0.3947, d2.dn_loss_bbox: 0.5837, d3.dn_loss_cls: 0.3843, d3.dn_loss_bbox: 0.5554, d4.dn_loss_cls: 0.3811, d4.dn_loss_bbox: 0.5453, loss: 10.4863, grad_norm: 54.6210
2025-10-12 03:22:34,535 - mmdet - INFO - Epoch [1][1750/4004]	lr: 7.633e-06, eta: 1:11:34, time: 1.896, data_time: 0.043, memory: 22962, loss_cls: 0.0868, loss_bbox: 0.6146, d0.loss_cls: 0.1083, d0.loss_bbox: 0.7813, d1.loss_cls: 0.0992, d1.loss_bbox: 0.6974, d2.loss_cls: 0.0907, d2.loss_bbox: 0.6548, d3.loss_cls: 0.0870, d3.loss_bbox: 0.6303, d4.loss_cls: 0.0868, d4.loss_bbox: 0.6186, dn_loss_cls: 0.3805, dn_loss_bbox: 0.5378, d0.dn_loss_cls: 0.4248, d0.dn_loss_bbox: 0.6758, d1.dn_loss_cls: 0.4048, d1.dn_loss_bbox: 0.6113, d2.dn_loss_cls: 0.3952, d2.dn_loss_bbox: 0.5769, d3.dn_loss_cls: 0.3845, d3.dn_loss_bbox: 0.5500, d4.dn_loss_cls: 0.3813, d4.dn_loss_bbox: 0.5406, loss: 10.4193, grad_norm: 51.7557
2025-10-12 03:24:07,189 - mmdet - INFO - Epoch [1][1800/4004]	lr: 7.492e-06, eta: 1:09:55, time: 1.853, data_time: 0.043, memory: 22962, loss_cls: 0.0884, loss_bbox: 0.6191, d0.loss_cls: 0.1110, d0.loss_bbox: 0.7901, d1.loss_cls: 0.1012, d1.loss_bbox: 0.7036, d2.loss_cls: 0.0923, d2.loss_bbox: 0.6609, d3.loss_cls: 0.0885, d3.loss_bbox: 0.6357, d4.loss_cls: 0.0882, d4.loss_bbox: 0.6239, dn_loss_cls: 0.3839, dn_loss_bbox: 0.5448, d0.dn_loss_cls: 0.4299, d0.dn_loss_bbox: 0.6871, d1.dn_loss_cls: 0.4095, d1.dn_loss_bbox: 0.6221, d2.dn_loss_cls: 0.3986, d2.dn_loss_bbox: 0.5865, d3.dn_loss_cls: 0.3881, d3.dn_loss_bbox: 0.5575, d4.dn_loss_cls: 0.3847, d4.dn_loss_bbox: 0.5475, loss: 10.5430, grad_norm: 52.8154
2025-10-12 03:25:39,294 - mmdet - INFO - Epoch [1][1850/4004]	lr: 7.340e-06, eta: 1:08:17, time: 1.842, data_time: 0.044, memory: 22962, loss_cls: 0.0856, loss_bbox: 0.6085, d0.loss_cls: 0.1078, d0.loss_bbox: 0.7756, d1.loss_cls: 0.0986, d1.loss_bbox: 0.6901, d2.loss_cls: 0.0898, d2.loss_bbox: 0.6488, d3.loss_cls: 0.0859, d3.loss_bbox: 0.6240, d4.loss_cls: 0.0856, d4.loss_bbox: 0.6128, dn_loss_cls: 0.3785, dn_loss_bbox: 0.5325, d0.dn_loss_cls: 0.4235, d0.dn_loss_bbox: 0.6716, d1.dn_loss_cls: 0.4031, d1.dn_loss_bbox: 0.6054, d2.dn_loss_cls: 0.3930, d2.dn_loss_bbox: 0.5716, d3.dn_loss_cls: 0.3831, d3.dn_loss_bbox: 0.5449, d4.dn_loss_cls: 0.3795, d4.dn_loss_bbox: 0.5352, loss: 10.3349, grad_norm: 67.4242
2025-10-12 03:27:13,575 - mmdet - INFO - Epoch [1][1900/4004]	lr: 7.179e-06, eta: 1:06:41, time: 1.886, data_time: 0.043, memory: 22962, loss_cls: 0.0858, loss_bbox: 0.6159, d0.loss_cls: 0.1077, d0.loss_bbox: 0.7843, d1.loss_cls: 0.0985, d1.loss_bbox: 0.6980, d2.loss_cls: 0.0894, d2.loss_bbox: 0.6564, d3.loss_cls: 0.0860, d3.loss_bbox: 0.6315, d4.loss_cls: 0.0857, d4.loss_bbox: 0.6193, dn_loss_cls: 0.3798, dn_loss_bbox: 0.5403, d0.dn_loss_cls: 0.4240, d0.dn_loss_bbox: 0.6811, d1.dn_loss_cls: 0.4041, d1.dn_loss_bbox: 0.6164, d2.dn_loss_cls: 0.3942, d2.dn_loss_bbox: 0.5817, d3.dn_loss_cls: 0.3839, d3.dn_loss_bbox: 0.5532, d4.dn_loss_cls: 0.3805, d4.dn_loss_bbox: 0.5431, loss: 10.4409, grad_norm: 45.4714
2025-10-12 03:28:50,007 - mmdet - INFO - Epoch [1][1950/4004]	lr: 7.009e-06, eta: 1:05:07, time: 1.928, data_time: 0.042, memory: 22962, loss_cls: 0.0847, loss_bbox: 0.5999, d0.loss_cls: 0.1071, d0.loss_bbox: 0.7612, d1.loss_cls: 0.0975, d1.loss_bbox: 0.6815, d2.loss_cls: 0.0884, d2.loss_bbox: 0.6399, d3.loss_cls: 0.0849, d3.loss_bbox: 0.6155, d4.loss_cls: 0.0847, d4.loss_bbox: 0.6033, dn_loss_cls: 0.3775, dn_loss_bbox: 0.5312, d0.dn_loss_cls: 0.4224, d0.dn_loss_bbox: 0.6691, d1.dn_loss_cls: 0.4022, d1.dn_loss_bbox: 0.6047, d2.dn_loss_cls: 0.3924, d2.dn_loss_bbox: 0.5722, d3.dn_loss_cls: 0.3814, d3.dn_loss_bbox: 0.5442, d4.dn_loss_cls: 0.3782, d4.dn_loss_bbox: 0.5339, loss: 10.2581, grad_norm: 46.5252

üîç AQR Debug Info (Forward #2000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023328
     std: 0.136888
     min: -22.546021
     max: 18.742245
   lidar_weights_stats:
     mean: 0.700062
     std: 0.166615
     min: 0.088535
     max: 0.979656
     shape: [4, 1400]
   camera_weights_stats:
     mean: 0.757724
     std: 0.160839
     min: 0.194575
     max: 0.995644
     shape: [4, 1400]
   weight_map_bev_stats:
     mean: 0.048382
     std: 0.090689
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.169702
     std: 0.640676
     min: 0.000000
     max: 34.709702
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.014820
     std_change: 0.060680
     max_change: 1.978279
     relative_change: 0.076707
   modulation_effect_pers:
     mean_change: -0.004580
     std_change: 0.078443
     max_change: 21.909302
     relative_change: 0.297732

üîç AQR Debug Info (Forward #2000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023392
     std: 0.129100
     min: -8.830566
     max: 12.335097
   lidar_weights_stats:
     mean: 0.723234
     std: 0.153440
     min: 0.110697
     max: 0.986544
     shape: [4, 1380]
   camera_weights_stats:
     mean: 0.753915
     std: 0.157033
     min: 0.139179
     max: 0.994485
     shape: [4, 1380]
   weight_map_bev_stats:
     mean: 0.049793
     std: 0.099863
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.164613
     std: 0.760639
     min: 0.000000
     max: 45.441151
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.014456
     std_change: 0.060686
     max_change: 1.989088
     relative_change: 0.075892
   modulation_effect_pers:
     mean_change: -0.005000
     std_change: 0.072851
     max_change: 12.067763
     relative_change: 0.303136

üîç AQR Debug Info (Forward #2000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023112
     std: 0.133599
     min: -17.242607
     max: 21.025440
   lidar_weights_stats:
     mean: 0.725898
     std: 0.152864
     min: 0.095055
     max: 0.974311
     shape: [4, 1440]
   camera_weights_stats:
     mean: 0.793848
     std: 0.138408
     min: 0.190527
     max: 0.994834
     shape: [4, 1440]
   weight_map_bev_stats:
     mean: 0.049576
     std: 0.101401
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.178010
     std: 0.899627
     min: 0.000000
     max: 50.711491
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013576
     std_change: 0.061069
     max_change: 3.402493
     relative_change: 0.072082
   modulation_effect_pers:
     mean_change: -0.004686
     std_change: 0.085792
     max_change: 20.604542
     relative_change: 0.314492

üîç AQR Debug Info (Forward #2000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023109
     std: 0.132127
     min: -26.879541
     max: 22.214733
   lidar_weights_stats:
     mean: 0.716311
     std: 0.148630
     min: 0.075059
     max: 0.980336
     shape: [4, 1470]
   camera_weights_stats:
     mean: 0.738853
     std: 0.162381
     min: 0.148253
     max: 0.992995
     shape: [4, 1470]
   weight_map_bev_stats:
     mean: 0.047023
     std: 0.088195
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.173817
     std: 0.989565
     min: 0.000000
     max: 57.553230
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013090
     std_change: 0.061391
     max_change: 2.332308
     relative_change: 0.068598
   modulation_effect_pers:
     mean_change: -0.004649
     std_change: 0.088585
     max_change: 26.418116
     relative_change: 0.306004

üîç AQR Debug Info (Forward #2000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023060
     std: 0.148909
     min: -21.285372
     max: 22.056992
   lidar_weights_stats:
     mean: 0.692631
     std: 0.168373
     min: 0.092243
     max: 0.985763
     shape: [4, 1470]
   camera_weights_stats:
     mean: 0.752180
     std: 0.156214
     min: 0.128854
     max: 0.992963
     shape: [4, 1470]
   weight_map_bev_stats:
     mean: 0.048286
     std: 0.089214
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.176513
     std: 0.903453
     min: 0.000000
     max: 48.977997
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.014706
     std_change: 0.060978
     max_change: 2.191696
     relative_change: 0.076857
   modulation_effect_pers:
     mean_change: -0.004788
     std_change: 0.098984
     max_change: 21.544296
     relative_change: 0.304973

üîç AQR Debug Info (Forward #2000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023204
     std: 0.159634
     min: -17.988115
     max: 22.672356
   lidar_weights_stats:
     mean: 0.711595
     std: 0.145035
     min: 0.129241
     max: 0.984742
     shape: [4, 1530]
   camera_weights_stats:
     mean: 0.722483
     std: 0.178267
     min: 0.081984
     max: 0.991928
     shape: [4, 1530]
   weight_map_bev_stats:
     mean: 0.049960
     std: 0.108759
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.177973
     std: 1.039802
     min: 0.000000
     max: 64.560692
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013146
     std_change: 0.062394
     max_change: 2.279682
     relative_change: 0.068399
   modulation_effect_pers:
     mean_change: -0.004930
     std_change: 0.113268
     max_change: 22.324944
     relative_change: 0.321063

üîç AQR Debug Info (Forward #2000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023588
     std: 0.160562
     min: -25.371794
     max: 19.641518
   lidar_weights_stats:
     mean: 0.681619
     std: 0.156845
     min: 0.075623
     max: 0.980304
     shape: [4, 1520]
   camera_weights_stats:
     mean: 0.774434
     std: 0.158831
     min: 0.164736
     max: 0.994297
     shape: [4, 1520]
   weight_map_bev_stats:
     mean: 0.046211
     std: 0.086883
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.188353
     std: 1.269869
     min: 0.000000
     max: 73.108856
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.014238
     std_change: 0.062196
     max_change: 2.448268
     relative_change: 0.072714
   modulation_effect_pers:
     mean_change: -0.004433
     std_change: 0.118115
     max_change: 25.028044
     relative_change: 0.325086

üîç AQR Debug Info (Forward #2000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.022478
     std: 0.130750
     min: -11.284266
     max: 11.069191
   lidar_weights_stats:
     mean: 0.701331
     std: 0.157428
     min: 0.060819
     max: 0.978994
     shape: [4, 1300]
   camera_weights_stats:
     mean: 0.733951
     std: 0.168885
     min: 0.107281
     max: 0.992839
     shape: [4, 1300]
   weight_map_bev_stats:
     mean: 0.041494
     std: 0.072419
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.153645
     std: 0.847126
     min: 0.000000
     max: 46.248276
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013359
     std_change: 0.061807
     max_change: 2.530106
     relative_change: 0.069175
   modulation_effect_pers:
     mean_change: -0.004967
     std_change: 0.078023
     max_change: 10.899988
     relative_change: 0.303243
2025-10-12 03:30:22,915 - mmdet - INFO - Exp name: cmt_aqr_voxel0100_r50_800x320_cbgs.py
2025-10-12 03:30:22,915 - mmdet - INFO - Epoch [1][2000/4004]	lr: 6.829e-06, eta: 1:03:30, time: 1.858, data_time: 0.041, memory: 22962, loss_cls: 0.0862, loss_bbox: 0.6157, d0.loss_cls: 0.1077, d0.loss_bbox: 0.7823, d1.loss_cls: 0.0988, d1.loss_bbox: 0.6954, d2.loss_cls: 0.0901, d2.loss_bbox: 0.6544, d3.loss_cls: 0.0864, d3.loss_bbox: 0.6309, d4.loss_cls: 0.0863, d4.loss_bbox: 0.6187, dn_loss_cls: 0.3802, dn_loss_bbox: 0.5425, d0.dn_loss_cls: 0.4236, d0.dn_loss_bbox: 0.6798, d1.dn_loss_cls: 0.4046, d1.dn_loss_bbox: 0.6136, d2.dn_loss_cls: 0.3943, d2.dn_loss_bbox: 0.5799, d3.dn_loss_cls: 0.3842, d3.dn_loss_bbox: 0.5540, d4.dn_loss_cls: 0.3811, d4.dn_loss_bbox: 0.5450, loss: 10.4355, grad_norm: 45.0856
2025-10-12 03:31:58,068 - mmdet - INFO - Epoch [1][2050/4004]	lr: 6.642e-06, eta: 1:01:55, time: 1.903, data_time: 0.037, memory: 22962, loss_cls: 0.0868, loss_bbox: 0.6025, d0.loss_cls: 0.1095, d0.loss_bbox: 0.7674, d1.loss_cls: 0.0997, d1.loss_bbox: 0.6864, d2.loss_cls: 0.0910, d2.loss_bbox: 0.6417, d3.loss_cls: 0.0870, d3.loss_bbox: 0.6186, d4.loss_cls: 0.0867, d4.loss_bbox: 0.6068, dn_loss_cls: 0.3783, dn_loss_bbox: 0.5229, d0.dn_loss_cls: 0.4233, d0.dn_loss_bbox: 0.6598, d1.dn_loss_cls: 0.4034, d1.dn_loss_bbox: 0.5969, d2.dn_loss_cls: 0.3929, d2.dn_loss_bbox: 0.5632, d3.dn_loss_cls: 0.3828, d3.dn_loss_bbox: 0.5350, d4.dn_loss_cls: 0.3793, d4.dn_loss_bbox: 0.5253, loss: 10.2472, grad_norm: 45.9575
2025-10-12 03:33:36,211 - mmdet - INFO - Epoch [1][2100/4004]	lr: 6.447e-06, eta: 1:00:22, time: 1.963, data_time: 0.031, memory: 22962, loss_cls: 0.0859, loss_bbox: 0.6134, d0.loss_cls: 0.1080, d0.loss_bbox: 0.7862, d1.loss_cls: 0.0990, d1.loss_bbox: 0.6966, d2.loss_cls: 0.0899, d2.loss_bbox: 0.6553, d3.loss_cls: 0.0862, d3.loss_bbox: 0.6298, d4.loss_cls: 0.0858, d4.loss_bbox: 0.6176, dn_loss_cls: 0.3795, dn_loss_bbox: 0.5372, d0.dn_loss_cls: 0.4242, d0.dn_loss_bbox: 0.6794, d1.dn_loss_cls: 0.4045, d1.dn_loss_bbox: 0.6126, d2.dn_loss_cls: 0.3947, d2.dn_loss_bbox: 0.5790, d3.dn_loss_cls: 0.3838, d3.dn_loss_bbox: 0.5504, d4.dn_loss_cls: 0.3802, d4.dn_loss_bbox: 0.5400, loss: 10.4192, grad_norm: 49.0272
2025-10-12 03:35:16,270 - mmdet - INFO - Epoch [1][2150/4004]	lr: 6.244e-06, eta: 0:58:51, time: 2.001, data_time: 0.030, memory: 22962, loss_cls: 0.0855, loss_bbox: 0.5969, d0.loss_cls: 0.1085, d0.loss_bbox: 0.7648, d1.loss_cls: 0.0987, d1.loss_bbox: 0.6782, d2.loss_cls: 0.0894, d2.loss_bbox: 0.6387, d3.loss_cls: 0.0856, d3.loss_bbox: 0.6146, d4.loss_cls: 0.0854, d4.loss_bbox: 0.6014, dn_loss_cls: 0.3765, dn_loss_bbox: 0.5274, d0.dn_loss_cls: 0.4219, d0.dn_loss_bbox: 0.6696, d1.dn_loss_cls: 0.4017, d1.dn_loss_bbox: 0.6044, d2.dn_loss_cls: 0.3917, d2.dn_loss_bbox: 0.5696, d3.dn_loss_cls: 0.3807, d3.dn_loss_bbox: 0.5406, d4.dn_loss_cls: 0.3773, d4.dn_loss_bbox: 0.5303, loss: 10.2394, grad_norm: 47.9602
2025-10-12 03:36:54,306 - mmdet - INFO - Epoch [1][2200/4004]	lr: 6.036e-06, eta: 0:57:18, time: 1.961, data_time: 0.030, memory: 22962, loss_cls: 0.0873, loss_bbox: 0.6105, d0.loss_cls: 0.1102, d0.loss_bbox: 0.7786, d1.loss_cls: 0.1003, d1.loss_bbox: 0.6930, d2.loss_cls: 0.0913, d2.loss_bbox: 0.6509, d3.loss_cls: 0.0876, d3.loss_bbox: 0.6257, d4.loss_cls: 0.0874, d4.loss_bbox: 0.6141, dn_loss_cls: 0.3778, dn_loss_bbox: 0.5413, d0.dn_loss_cls: 0.4228, d0.dn_loss_bbox: 0.6821, d1.dn_loss_cls: 0.4021, d1.dn_loss_bbox: 0.6180, d2.dn_loss_cls: 0.3922, d2.dn_loss_bbox: 0.5832, d3.dn_loss_cls: 0.3821, d3.dn_loss_bbox: 0.5539, d4.dn_loss_cls: 0.3785, d4.dn_loss_bbox: 0.5440, loss: 10.4147, grad_norm: 49.6861
2025-10-12 03:38:30,108 - mmdet - INFO - Epoch [1][2250/4004]	lr: 5.821e-06, eta: 0:55:44, time: 1.916, data_time: 0.033, memory: 22962, loss_cls: 0.0855, loss_bbox: 0.5997, d0.loss_cls: 0.1085, d0.loss_bbox: 0.7646, d1.loss_cls: 0.0988, d1.loss_bbox: 0.6846, d2.loss_cls: 0.0896, d2.loss_bbox: 0.6395, d3.loss_cls: 0.0856, d3.loss_bbox: 0.6154, d4.loss_cls: 0.0855, d4.loss_bbox: 0.6031, dn_loss_cls: 0.3793, dn_loss_bbox: 0.5260, d0.dn_loss_cls: 0.4242, d0.dn_loss_bbox: 0.6617, d1.dn_loss_cls: 0.4040, d1.dn_loss_bbox: 0.5996, d2.dn_loss_cls: 0.3939, d2.dn_loss_bbox: 0.5658, d3.dn_loss_cls: 0.3836, d3.dn_loss_bbox: 0.5380, d4.dn_loss_cls: 0.3801, d4.dn_loss_bbox: 0.5284, loss: 10.2449, grad_norm: 43.0823
2025-10-12 03:40:07,536 - mmdet - INFO - Epoch [1][2300/4004]	lr: 5.602e-06, eta: 0:54:10, time: 1.948, data_time: 0.036, memory: 22962, loss_cls: 0.0840, loss_bbox: 0.6091, d0.loss_cls: 0.1063, d0.loss_bbox: 0.7746, d1.loss_cls: 0.0971, d1.loss_bbox: 0.6895, d2.loss_cls: 0.0882, d2.loss_bbox: 0.6479, d3.loss_cls: 0.0844, d3.loss_bbox: 0.6239, d4.loss_cls: 0.0842, d4.loss_bbox: 0.6121, dn_loss_cls: 0.3780, dn_loss_bbox: 0.5336, d0.dn_loss_cls: 0.4231, d0.dn_loss_bbox: 0.6763, d1.dn_loss_cls: 0.4036, d1.dn_loss_bbox: 0.6097, d2.dn_loss_cls: 0.3924, d2.dn_loss_bbox: 0.5743, d3.dn_loss_cls: 0.3821, d3.dn_loss_bbox: 0.5463, d4.dn_loss_cls: 0.3789, d4.dn_loss_bbox: 0.5363, loss: 10.3356, grad_norm: 42.9463
2025-10-12 03:41:43,545 - mmdet - INFO - Epoch [1][2350/4004]	lr: 5.378e-06, eta: 0:52:35, time: 1.920, data_time: 0.036, memory: 22962, loss_cls: 0.0860, loss_bbox: 0.6196, d0.loss_cls: 0.1083, d0.loss_bbox: 0.7893, d1.loss_cls: 0.0988, d1.loss_bbox: 0.7035, d2.loss_cls: 0.0902, d2.loss_bbox: 0.6592, d3.loss_cls: 0.0865, d3.loss_bbox: 0.6342, d4.loss_cls: 0.0862, d4.loss_bbox: 0.6222, dn_loss_cls: 0.3823, dn_loss_bbox: 0.5404, d0.dn_loss_cls: 0.4265, d0.dn_loss_bbox: 0.6811, d1.dn_loss_cls: 0.4066, d1.dn_loss_bbox: 0.6161, d2.dn_loss_cls: 0.3967, d2.dn_loss_bbox: 0.5816, d3.dn_loss_cls: 0.3864, d3.dn_loss_bbox: 0.5530, d4.dn_loss_cls: 0.3829, d4.dn_loss_bbox: 0.5430, loss: 10.4807, grad_norm: 49.1209
2025-10-12 03:43:23,118 - mmdet - INFO - Epoch [1][2400/4004]	lr: 5.150e-06, eta: 0:51:02, time: 1.991, data_time: 0.034, memory: 22962, loss_cls: 0.0852, loss_bbox: 0.5978, d0.loss_cls: 0.1077, d0.loss_bbox: 0.7634, d1.loss_cls: 0.0982, d1.loss_bbox: 0.6825, d2.loss_cls: 0.0892, d2.loss_bbox: 0.6389, d3.loss_cls: 0.0856, d3.loss_bbox: 0.6129, d4.loss_cls: 0.0852, d4.loss_bbox: 0.6013, dn_loss_cls: 0.3764, dn_loss_bbox: 0.5256, d0.dn_loss_cls: 0.4211, d0.dn_loss_bbox: 0.6646, d1.dn_loss_cls: 0.4013, d1.dn_loss_bbox: 0.6000, d2.dn_loss_cls: 0.3908, d2.dn_loss_bbox: 0.5665, d3.dn_loss_cls: 0.3807, d3.dn_loss_bbox: 0.5382, d4.dn_loss_cls: 0.3770, d4.dn_loss_bbox: 0.5282, loss: 10.2182, grad_norm: 48.0863
2025-10-12 03:45:01,686 - mmdet - INFO - Epoch [1][2450/4004]	lr: 4.920e-06, eta: 0:49:29, time: 1.971, data_time: 0.034, memory: 22962, loss_cls: 0.0857, loss_bbox: 0.6123, d0.loss_cls: 0.1078, d0.loss_bbox: 0.7805, d1.loss_cls: 0.0985, d1.loss_bbox: 0.6977, d2.loss_cls: 0.0893, d2.loss_bbox: 0.6569, d3.loss_cls: 0.0859, d3.loss_bbox: 0.6286, d4.loss_cls: 0.0857, d4.loss_bbox: 0.6165, dn_loss_cls: 0.3766, dn_loss_bbox: 0.5346, d0.dn_loss_cls: 0.4213, d0.dn_loss_bbox: 0.6754, d1.dn_loss_cls: 0.4016, d1.dn_loss_bbox: 0.6095, d2.dn_loss_cls: 0.3913, d2.dn_loss_bbox: 0.5759, d3.dn_loss_cls: 0.3807, d3.dn_loss_bbox: 0.5473, d4.dn_loss_cls: 0.3772, d4.dn_loss_bbox: 0.5372, loss: 10.3741, grad_norm: 43.8012
2025-10-12 03:46:41,469 - mmdet - INFO - Epoch [1][2500/4004]	lr: 4.687e-06, eta: 0:47:56, time: 1.996, data_time: 0.034, memory: 22962, loss_cls: 0.0876, loss_bbox: 0.6159, d0.loss_cls: 0.1097, d0.loss_bbox: 0.7856, d1.loss_cls: 0.1005, d1.loss_bbox: 0.7011, d2.loss_cls: 0.0915, d2.loss_bbox: 0.6574, d3.loss_cls: 0.0878, d3.loss_bbox: 0.6319, d4.loss_cls: 0.0876, d4.loss_bbox: 0.6187, dn_loss_cls: 0.3815, dn_loss_bbox: 0.5404, d0.dn_loss_cls: 0.4260, d0.dn_loss_bbox: 0.6810, d1.dn_loss_cls: 0.4057, d1.dn_loss_bbox: 0.6165, d2.dn_loss_cls: 0.3962, d2.dn_loss_bbox: 0.5820, d3.dn_loss_cls: 0.3855, d3.dn_loss_bbox: 0.5531, d4.dn_loss_cls: 0.3821, d4.dn_loss_bbox: 0.5431, loss: 10.4684, grad_norm: 51.9486
2025-10-12 03:48:19,734 - mmdet - INFO - Epoch [1][2550/4004]	lr: 4.452e-06, eta: 0:46:22, time: 1.965, data_time: 0.031, memory: 22962, loss_cls: 0.0851, loss_bbox: 0.5963, d0.loss_cls: 0.1077, d0.loss_bbox: 0.7551, d1.loss_cls: 0.0980, d1.loss_bbox: 0.6800, d2.loss_cls: 0.0887, d2.loss_bbox: 0.6374, d3.loss_cls: 0.0852, d3.loss_bbox: 0.6132, d4.loss_cls: 0.0851, d4.loss_bbox: 0.6010, dn_loss_cls: 0.3756, dn_loss_bbox: 0.5273, d0.dn_loss_cls: 0.4203, d0.dn_loss_bbox: 0.6617, d1.dn_loss_cls: 0.4004, d1.dn_loss_bbox: 0.6000, d2.dn_loss_cls: 0.3903, d2.dn_loss_bbox: 0.5667, d3.dn_loss_cls: 0.3798, d3.dn_loss_bbox: 0.5397, d4.dn_loss_cls: 0.3764, d4.dn_loss_bbox: 0.5299, loss: 10.2009, grad_norm: 42.2264
2025-10-12 03:49:58,127 - mmdet - INFO - Epoch [1][2600/4004]	lr: 4.217e-06, eta: 0:44:47, time: 1.968, data_time: 0.031, memory: 22962, loss_cls: 0.0851, loss_bbox: 0.5974, d0.loss_cls: 0.1077, d0.loss_bbox: 0.7641, d1.loss_cls: 0.0982, d1.loss_bbox: 0.6819, d2.loss_cls: 0.0888, d2.loss_bbox: 0.6396, d3.loss_cls: 0.0852, d3.loss_bbox: 0.6151, d4.loss_cls: 0.0852, d4.loss_bbox: 0.6011, dn_loss_cls: 0.3769, dn_loss_bbox: 0.5272, d0.dn_loss_cls: 0.4224, d0.dn_loss_bbox: 0.6638, d1.dn_loss_cls: 0.4025, d1.dn_loss_bbox: 0.6020, d2.dn_loss_cls: 0.3918, d2.dn_loss_bbox: 0.5683, d3.dn_loss_cls: 0.3810, d3.dn_loss_bbox: 0.5395, d4.dn_loss_cls: 0.3775, d4.dn_loss_bbox: 0.5298, loss: 10.2321, grad_norm: 43.2519
2025-10-12 03:51:31,160 - mmdet - INFO - Epoch [1][2650/4004]	lr: 3.982e-06, eta: 0:43:10, time: 1.861, data_time: 0.034, memory: 22962, loss_cls: 0.0848, loss_bbox: 0.6004, d0.loss_cls: 0.1076, d0.loss_bbox: 0.7667, d1.loss_cls: 0.0977, d1.loss_bbox: 0.6831, d2.loss_cls: 0.0886, d2.loss_bbox: 0.6401, d3.loss_cls: 0.0849, d3.loss_bbox: 0.6163, d4.loss_cls: 0.0848, d4.loss_bbox: 0.6050, dn_loss_cls: 0.3747, dn_loss_bbox: 0.5269, d0.dn_loss_cls: 0.4180, d0.dn_loss_bbox: 0.6630, d1.dn_loss_cls: 0.3989, d1.dn_loss_bbox: 0.5987, d2.dn_loss_cls: 0.3887, d2.dn_loss_bbox: 0.5652, d3.dn_loss_cls: 0.3788, d3.dn_loss_bbox: 0.5394, d4.dn_loss_cls: 0.3755, d4.dn_loss_bbox: 0.5296, loss: 10.2171, grad_norm: 41.1757
2025-10-12 03:53:02,239 - mmdet - INFO - Epoch [1][2700/4004]	lr: 3.747e-06, eta: 0:41:32, time: 1.821, data_time: 0.034, memory: 22962, loss_cls: 0.0835, loss_bbox: 0.6036, d0.loss_cls: 0.1054, d0.loss_bbox: 0.7665, d1.loss_cls: 0.0960, d1.loss_bbox: 0.6840, d2.loss_cls: 0.0870, d2.loss_bbox: 0.6443, d3.loss_cls: 0.0836, d3.loss_bbox: 0.6197, d4.loss_cls: 0.0834, d4.loss_bbox: 0.6076, dn_loss_cls: 0.3747, dn_loss_bbox: 0.5376, d0.dn_loss_cls: 0.4187, d0.dn_loss_bbox: 0.6731, d1.dn_loss_cls: 0.3991, d1.dn_loss_bbox: 0.6108, d2.dn_loss_cls: 0.3888, d2.dn_loss_bbox: 0.5766, d3.dn_loss_cls: 0.3790, d3.dn_loss_bbox: 0.5503, d4.dn_loss_cls: 0.3755, d4.dn_loss_bbox: 0.5404, loss: 10.2891, grad_norm: 42.9147
2025-10-12 03:54:38,996 - mmdet - INFO - Epoch [1][2750/4004]	lr: 3.514e-06, eta: 0:39:57, time: 1.935, data_time: 0.031, memory: 22962, loss_cls: 0.0843, loss_bbox: 0.6035, d0.loss_cls: 0.1067, d0.loss_bbox: 0.7674, d1.loss_cls: 0.0970, d1.loss_bbox: 0.6839, d2.loss_cls: 0.0881, d2.loss_bbox: 0.6432, d3.loss_cls: 0.0846, d3.loss_bbox: 0.6190, d4.loss_cls: 0.0842, d4.loss_bbox: 0.6076, dn_loss_cls: 0.3765, dn_loss_bbox: 0.5262, d0.dn_loss_cls: 0.4202, d0.dn_loss_bbox: 0.6603, d1.dn_loss_cls: 0.4011, d1.dn_loss_bbox: 0.5982, d2.dn_loss_cls: 0.3910, d2.dn_loss_bbox: 0.5650, d3.dn_loss_cls: 0.3807, d3.dn_loss_bbox: 0.5382, d4.dn_loss_cls: 0.3770, d4.dn_loss_bbox: 0.5287, loss: 10.2328, grad_norm: 43.0841
2025-10-12 03:56:13,080 - mmdet - INFO - Epoch [1][2800/4004]	lr: 3.283e-06, eta: 0:38:21, time: 1.882, data_time: 0.034, memory: 22962, loss_cls: 0.0841, loss_bbox: 0.5955, d0.loss_cls: 0.1075, d0.loss_bbox: 0.7650, d1.loss_cls: 0.0976, d1.loss_bbox: 0.6816, d2.loss_cls: 0.0882, d2.loss_bbox: 0.6379, d3.loss_cls: 0.0844, d3.loss_bbox: 0.6111, d4.loss_cls: 0.0843, d4.loss_bbox: 0.5987, dn_loss_cls: 0.3756, dn_loss_bbox: 0.5232, d0.dn_loss_cls: 0.4204, d0.dn_loss_bbox: 0.6625, d1.dn_loss_cls: 0.4003, d1.dn_loss_bbox: 0.5978, d2.dn_loss_cls: 0.3904, d2.dn_loss_bbox: 0.5646, d3.dn_loss_cls: 0.3802, d3.dn_loss_bbox: 0.5359, d4.dn_loss_cls: 0.3764, d4.dn_loss_bbox: 0.5260, loss: 10.1894, grad_norm: 42.1210
2025-10-12 03:57:45,243 - mmdet - INFO - Epoch [1][2850/4004]	lr: 3.055e-06, eta: 0:36:44, time: 1.843, data_time: 0.035, memory: 22962, loss_cls: 0.0835, loss_bbox: 0.5949, d0.loss_cls: 0.1060, d0.loss_bbox: 0.7595, d1.loss_cls: 0.0963, d1.loss_bbox: 0.6772, d2.loss_cls: 0.0874, d2.loss_bbox: 0.6360, d3.loss_cls: 0.0835, d3.loss_bbox: 0.6109, d4.loss_cls: 0.0835, d4.loss_bbox: 0.5988, dn_loss_cls: 0.3748, dn_loss_bbox: 0.5244, d0.dn_loss_cls: 0.4197, d0.dn_loss_bbox: 0.6608, d1.dn_loss_cls: 0.3998, d1.dn_loss_bbox: 0.5980, d2.dn_loss_cls: 0.3896, d2.dn_loss_bbox: 0.5647, d3.dn_loss_cls: 0.3794, d3.dn_loss_bbox: 0.5371, d4.dn_loss_cls: 0.3756, d4.dn_loss_bbox: 0.5272, loss: 10.1688, grad_norm: 45.0325
2025-10-12 03:59:16,811 - mmdet - INFO - Epoch [1][2900/4004]	lr: 2.831e-06, eta: 0:35:07, time: 1.831, data_time: 0.035, memory: 22962, loss_cls: 0.0857, loss_bbox: 0.5957, d0.loss_cls: 0.1087, d0.loss_bbox: 0.7587, d1.loss_cls: 0.0992, d1.loss_bbox: 0.6787, d2.loss_cls: 0.0897, d2.loss_bbox: 0.6354, d3.loss_cls: 0.0860, d3.loss_bbox: 0.6109, d4.loss_cls: 0.0860, d4.loss_bbox: 0.5979, dn_loss_cls: 0.3750, dn_loss_bbox: 0.5223, d0.dn_loss_cls: 0.4201, d0.dn_loss_bbox: 0.6578, d1.dn_loss_cls: 0.4002, d1.dn_loss_bbox: 0.5961, d2.dn_loss_cls: 0.3898, d2.dn_loss_bbox: 0.5627, d3.dn_loss_cls: 0.3794, d3.dn_loss_bbox: 0.5351, d4.dn_loss_cls: 0.3760, d4.dn_loss_bbox: 0.5251, loss: 10.1721, grad_norm: 42.2270
2025-10-12 04:00:48,895 - mmdet - INFO - Epoch [1][2950/4004]	lr: 2.611e-06, eta: 0:33:30, time: 1.842, data_time: 0.035, memory: 22962, loss_cls: 0.0842, loss_bbox: 0.5926, d0.loss_cls: 0.1076, d0.loss_bbox: 0.7575, d1.loss_cls: 0.0977, d1.loss_bbox: 0.6744, d2.loss_cls: 0.0882, d2.loss_bbox: 0.6324, d3.loss_cls: 0.0846, d3.loss_bbox: 0.6077, d4.loss_cls: 0.0843, d4.loss_bbox: 0.5963, dn_loss_cls: 0.3756, dn_loss_bbox: 0.5243, d0.dn_loss_cls: 0.4206, d0.dn_loss_bbox: 0.6628, d1.dn_loss_cls: 0.4002, d1.dn_loss_bbox: 0.5982, d2.dn_loss_cls: 0.3903, d2.dn_loss_bbox: 0.5642, d3.dn_loss_cls: 0.3800, d3.dn_loss_bbox: 0.5366, d4.dn_loss_cls: 0.3764, d4.dn_loss_bbox: 0.5268, loss: 10.1634, grad_norm: 47.3762

üîç AQR Debug Info (Forward #3000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.022955
     std: 0.122047
     min: -7.253612
     max: 7.698337
   lidar_weights_stats:
     mean: 0.698340
     std: 0.162858
     min: 0.070201
     max: 0.978484
     shape: [4, 1120]
   camera_weights_stats:
     mean: 0.771186
     std: 0.154398
     min: 0.182137
     max: 0.993790
     shape: [4, 1120]
   weight_map_bev_stats:
     mean: 0.041469
     std: 0.069872
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.138077
     std: 0.438944
     min: 0.000000
     max: 20.062788
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013916
     std_change: 0.064168
     max_change: 2.600512
     relative_change: 0.071427
   modulation_effect_pers:
     mean_change: -0.005505
     std_change: 0.053073
     max_change: 6.962985
     relative_change: 0.280891

üîç AQR Debug Info (Forward #3000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.021820
     std: 0.120662
     min: -6.686604
     max: 5.821313
   lidar_weights_stats:
     mean: 0.722690
     std: 0.136489
     min: 0.202251
     max: 0.985179
     shape: [4, 1220]
   camera_weights_stats:
     mean: 0.709781
     std: 0.179883
     min: 0.125674
     max: 0.994609
     shape: [4, 1220]
   weight_map_bev_stats:
     mean: 0.046325
     std: 0.084695
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.139987
     std: 0.493952
     min: 0.000000
     max: 22.849726
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013020
     std_change: 0.065554
     max_change: 1.641301
     relative_change: 0.072460
   modulation_effect_pers:
     mean_change: -0.005448
     std_change: 0.055770
     max_change: 6.402668
     relative_change: 0.293033

üîç AQR Debug Info (Forward #3000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023122
     std: 0.120010
     min: -8.680829
     max: 9.173828
   lidar_weights_stats:
     mean: 0.701085
     std: 0.166384
     min: 0.085735
     max: 0.984029
     shape: [4, 1220]
   camera_weights_stats:
     mean: 0.720943
     std: 0.172301
     min: 0.095978
     max: 0.994142
     shape: [4, 1220]
   weight_map_bev_stats:
     mean: 0.044285
     std: 0.072706
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.140311
     std: 0.456666
     min: 0.000000
     max: 24.147432
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013934
     std_change: 0.060511
     max_change: 2.096808
     relative_change: 0.070760
   modulation_effect_pers:
     mean_change: -0.005453
     std_change: 0.056163
     max_change: 8.660645
     relative_change: 0.270617

üîç AQR Debug Info (Forward #3000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.022943
     std: 0.118792
     min: -10.502398
     max: 9.366078
   lidar_weights_stats:
     mean: 0.694999
     std: 0.156095
     min: 0.088991
     max: 0.977526
     shape: [4, 1210]
   camera_weights_stats:
     mean: 0.748392
     std: 0.163193
     min: 0.125611
     max: 0.994628
     shape: [4, 1210]
   weight_map_bev_stats:
     mean: 0.042206
     std: 0.074575
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.146443
     std: 0.534747
     min: 0.000000
     max: 26.392479
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.014315
     std_change: 0.061625
     max_change: 1.938331
     relative_change: 0.072618
   modulation_effect_pers:
     mean_change: -0.005413
     std_change: 0.063725
     max_change: 10.110309
     relative_change: 0.289757

üîç AQR Debug Info (Forward #3000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023731
     std: 0.129803
     min: -7.434908
     max: 6.882418
   lidar_weights_stats:
     mean: 0.706529
     std: 0.153383
     min: 0.136990
     max: 0.985352
     shape: [4, 1270]
   camera_weights_stats:
     mean: 0.763789
     std: 0.165405
     min: 0.137569
     max: 0.995048
     shape: [4, 1270]
   weight_map_bev_stats:
     mean: 0.047450
     std: 0.083530
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.154861
     std: 0.500716
     min: 0.000000
     max: 18.795425
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013436
     std_change: 0.062413
     max_change: 2.226976
     relative_change: 0.068694
   modulation_effect_pers:
     mean_change: -0.005404
     std_change: 0.058019
     max_change: 6.817721
     relative_change: 0.286392

üîç AQR Debug Info (Forward #3000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.022141
     std: 0.117051
     min: -5.756210
     max: 5.579999
   lidar_weights_stats:
     mean: 0.705732
     std: 0.168314
     min: 0.097341
     max: 0.981623
     shape: [4, 1310]
   camera_weights_stats:
     mean: 0.780073
     std: 0.148252
     min: 0.176127
     max: 0.995717
     shape: [4, 1310]
   weight_map_bev_stats:
     mean: 0.049179
     std: 0.097401
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.165400
     std: 0.514783
     min: 0.000000
     max: 24.624851
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013714
     std_change: 0.062771
     max_change: 3.174874
     relative_change: 0.073823
   modulation_effect_pers:
     mean_change: -0.004662
     std_change: 0.052010
     max_change: 5.528915
     relative_change: 0.295659

üîç AQR Debug Info (Forward #3000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.022878
     std: 0.126829
     min: -18.635756
     max: 15.338614
   lidar_weights_stats:
     mean: 0.741797
     std: 0.142494
     min: 0.109574
     max: 0.980908
     shape: [4, 1500]
   camera_weights_stats:
     mean: 0.745258
     std: 0.169922
     min: 0.108018
     max: 0.995398
     shape: [4, 1500]
   weight_map_bev_stats:
     mean: 0.051132
     std: 0.104931
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.179657
     std: 1.001163
     min: 0.000000
     max: 61.724018
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013364
     std_change: 0.060736
     max_change: 2.741426
     relative_change: 0.071759
   modulation_effect_pers:
     mean_change: -0.004185
     std_change: 0.084282
     max_change: 18.248793
     relative_change: 0.313871

üîç AQR Debug Info (Forward #3000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023379
     std: 0.138471
     min: -20.221920
     max: 17.052614
   lidar_weights_stats:
     mean: 0.684617
     std: 0.162259
     min: 0.076633
     max: 0.986175
     shape: [4, 1490]
   camera_weights_stats:
     mean: 0.730167
     std: 0.178942
     min: 0.090744
     max: 0.996854
     shape: [4, 1490]
   weight_map_bev_stats:
     mean: 0.047135
     std: 0.084929
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.176710
     std: 0.820682
     min: 0.000000
     max: 40.693794
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.014291
     std_change: 0.060096
     max_change: 2.618840
     relative_change: 0.077472
   modulation_effect_pers:
     mean_change: -0.004664
     std_change: 0.088955
     max_change: 19.733395
     relative_change: 0.306228
2025-10-12 04:02:20,488 - mmdet - INFO - Exp name: cmt_aqr_voxel0100_r50_800x320_cbgs.py
2025-10-12 04:02:20,489 - mmdet - INFO - Epoch [1][3000/4004]	lr: 2.395e-06, eta: 0:31:54, time: 1.832, data_time: 0.035, memory: 22962, loss_cls: 0.0840, loss_bbox: 0.5987, d0.loss_cls: 0.1064, d0.loss_bbox: 0.7625, d1.loss_cls: 0.0971, d1.loss_bbox: 0.6823, d2.loss_cls: 0.0880, d2.loss_bbox: 0.6382, d3.loss_cls: 0.0843, d3.loss_bbox: 0.6145, d4.loss_cls: 0.0841, d4.loss_bbox: 0.6021, dn_loss_cls: 0.3758, dn_loss_bbox: 0.5282, d0.dn_loss_cls: 0.4203, d0.dn_loss_bbox: 0.6645, d1.dn_loss_cls: 0.4006, d1.dn_loss_bbox: 0.6019, d2.dn_loss_cls: 0.3903, d2.dn_loss_bbox: 0.5672, d3.dn_loss_cls: 0.3800, d3.dn_loss_bbox: 0.5406, d4.dn_loss_cls: 0.3765, d4.dn_loss_bbox: 0.5307, loss: 10.2187, grad_norm: 44.4816
2025-10-12 04:03:51,299 - mmdet - INFO - Epoch [1][3050/4004]	lr: 2.186e-06, eta: 0:30:17, time: 1.816, data_time: 0.035, memory: 22962, loss_cls: 0.0838, loss_bbox: 0.6061, d0.loss_cls: 0.1067, d0.loss_bbox: 0.7723, d1.loss_cls: 0.0972, d1.loss_bbox: 0.6876, d2.loss_cls: 0.0880, d2.loss_bbox: 0.6470, d3.loss_cls: 0.0844, d3.loss_bbox: 0.6206, d4.loss_cls: 0.0840, d4.loss_bbox: 0.6089, dn_loss_cls: 0.3761, dn_loss_bbox: 0.5306, d0.dn_loss_cls: 0.4201, d0.dn_loss_bbox: 0.6678, d1.dn_loss_cls: 0.4005, d1.dn_loss_bbox: 0.6039, d2.dn_loss_cls: 0.3905, d2.dn_loss_bbox: 0.5700, d3.dn_loss_cls: 0.3805, d3.dn_loss_bbox: 0.5427, d4.dn_loss_cls: 0.3768, d4.dn_loss_bbox: 0.5332, loss: 10.2793, grad_norm: 43.3579
2025-10-12 04:05:22,603 - mmdet - INFO - Epoch [1][3100/4004]	lr: 1.983e-06, eta: 0:28:41, time: 1.826, data_time: 0.035, memory: 22962, loss_cls: 0.0850, loss_bbox: 0.6057, d0.loss_cls: 0.1073, d0.loss_bbox: 0.7743, d1.loss_cls: 0.0984, d1.loss_bbox: 0.6904, d2.loss_cls: 0.0890, d2.loss_bbox: 0.6477, d3.loss_cls: 0.0850, d3.loss_bbox: 0.6233, d4.loss_cls: 0.0850, d4.loss_bbox: 0.6097, dn_loss_cls: 0.3772, dn_loss_bbox: 0.5318, d0.dn_loss_cls: 0.4221, d0.dn_loss_bbox: 0.6748, d1.dn_loss_cls: 0.4019, d1.dn_loss_bbox: 0.6073, d2.dn_loss_cls: 0.3919, d2.dn_loss_bbox: 0.5728, d3.dn_loss_cls: 0.3817, d3.dn_loss_bbox: 0.5447, d4.dn_loss_cls: 0.3782, d4.dn_loss_bbox: 0.5346, loss: 10.3198, grad_norm: 41.1244
2025-10-12 04:06:54,495 - mmdet - INFO - Epoch [1][3150/4004]	lr: 1.786e-06, eta: 0:27:05, time: 1.838, data_time: 0.035, memory: 22962, loss_cls: 0.0858, loss_bbox: 0.5986, d0.loss_cls: 0.1092, d0.loss_bbox: 0.7671, d1.loss_cls: 0.0996, d1.loss_bbox: 0.6831, d2.loss_cls: 0.0899, d2.loss_bbox: 0.6408, d3.loss_cls: 0.0862, d3.loss_bbox: 0.6141, d4.loss_cls: 0.0859, d4.loss_bbox: 0.6015, dn_loss_cls: 0.3743, dn_loss_bbox: 0.5235, d0.dn_loss_cls: 0.4195, d0.dn_loss_bbox: 0.6659, d1.dn_loss_cls: 0.3997, d1.dn_loss_bbox: 0.6005, d2.dn_loss_cls: 0.3889, d2.dn_loss_bbox: 0.5654, d3.dn_loss_cls: 0.3787, d3.dn_loss_bbox: 0.5367, d4.dn_loss_cls: 0.3752, d4.dn_loss_bbox: 0.5264, loss: 10.2165, grad_norm: 41.4242
2025-10-12 04:08:26,142 - mmdet - INFO - Epoch [1][3200/4004]	lr: 1.598e-06, eta: 0:25:29, time: 1.833, data_time: 0.034, memory: 22962, loss_cls: 0.0832, loss_bbox: 0.5946, d0.loss_cls: 0.1058, d0.loss_bbox: 0.7631, d1.loss_cls: 0.0967, d1.loss_bbox: 0.6799, d2.loss_cls: 0.0872, d2.loss_bbox: 0.6364, d3.loss_cls: 0.0835, d3.loss_bbox: 0.6106, d4.loss_cls: 0.0832, d4.loss_bbox: 0.5985, dn_loss_cls: 0.3731, dn_loss_bbox: 0.5210, d0.dn_loss_cls: 0.4173, d0.dn_loss_bbox: 0.6574, d1.dn_loss_cls: 0.3974, d1.dn_loss_bbox: 0.5953, d2.dn_loss_cls: 0.3872, d2.dn_loss_bbox: 0.5613, d3.dn_loss_cls: 0.3774, d3.dn_loss_bbox: 0.5336, d4.dn_loss_cls: 0.3738, d4.dn_loss_bbox: 0.5236, loss: 10.1410, grad_norm: 42.7691
2025-10-12 04:09:57,311 - mmdet - INFO - Epoch [1][3250/4004]	lr: 1.417e-06, eta: 0:23:53, time: 1.823, data_time: 0.035, memory: 22962, loss_cls: 0.0840, loss_bbox: 0.6019, d0.loss_cls: 0.1063, d0.loss_bbox: 0.7715, d1.loss_cls: 0.0970, d1.loss_bbox: 0.6842, d2.loss_cls: 0.0878, d2.loss_bbox: 0.6440, d3.loss_cls: 0.0842, d3.loss_bbox: 0.6190, d4.loss_cls: 0.0839, d4.loss_bbox: 0.6065, dn_loss_cls: 0.3747, dn_loss_bbox: 0.5260, d0.dn_loss_cls: 0.4194, d0.dn_loss_bbox: 0.6661, d1.dn_loss_cls: 0.3990, d1.dn_loss_bbox: 0.6007, d2.dn_loss_cls: 0.3893, d2.dn_loss_bbox: 0.5669, d3.dn_loss_cls: 0.3790, d3.dn_loss_bbox: 0.5392, d4.dn_loss_cls: 0.3755, d4.dn_loss_bbox: 0.5287, loss: 10.2352, grad_norm: 41.4081
2025-10-12 04:11:27,540 - mmdet - INFO - Epoch [1][3300/4004]	lr: 1.246e-06, eta: 0:22:16, time: 1.805, data_time: 0.035, memory: 22962, loss_cls: 0.0827, loss_bbox: 0.6030, d0.loss_cls: 0.1050, d0.loss_bbox: 0.7747, d1.loss_cls: 0.0959, d1.loss_bbox: 0.6878, d2.loss_cls: 0.0868, d2.loss_bbox: 0.6454, d3.loss_cls: 0.0830, d3.loss_bbox: 0.6190, d4.loss_cls: 0.0828, d4.loss_bbox: 0.6073, dn_loss_cls: 0.3751, dn_loss_bbox: 0.5302, d0.dn_loss_cls: 0.4208, d0.dn_loss_bbox: 0.6739, d1.dn_loss_cls: 0.4008, d1.dn_loss_bbox: 0.6073, d2.dn_loss_cls: 0.3912, d2.dn_loss_bbox: 0.5726, d3.dn_loss_cls: 0.3797, d3.dn_loss_bbox: 0.5431, d4.dn_loss_cls: 0.3759, d4.dn_loss_bbox: 0.5331, loss: 10.2772, grad_norm: 50.1481
2025-10-12 04:12:58,976 - mmdet - INFO - Epoch [1][3350/4004]	lr: 1.083e-06, eta: 0:20:41, time: 1.829, data_time: 0.035, memory: 22962, loss_cls: 0.0862, loss_bbox: 0.5968, d0.loss_cls: 0.1090, d0.loss_bbox: 0.7636, d1.loss_cls: 0.0993, d1.loss_bbox: 0.6815, d2.loss_cls: 0.0902, d2.loss_bbox: 0.6377, d3.loss_cls: 0.0863, d3.loss_bbox: 0.6130, d4.loss_cls: 0.0861, d4.loss_bbox: 0.6010, dn_loss_cls: 0.3771, dn_loss_bbox: 0.5248, d0.dn_loss_cls: 0.4216, d0.dn_loss_bbox: 0.6647, d1.dn_loss_cls: 0.4019, d1.dn_loss_bbox: 0.5994, d2.dn_loss_cls: 0.3917, d2.dn_loss_bbox: 0.5658, d3.dn_loss_cls: 0.3811, d3.dn_loss_bbox: 0.5374, d4.dn_loss_cls: 0.3779, d4.dn_loss_bbox: 0.5274, loss: 10.2215, grad_norm: 43.0099
2025-10-12 04:14:31,340 - mmdet - INFO - Epoch [1][3400/4004]	lr: 9.304e-07, eta: 0:19:05, time: 1.847, data_time: 0.034, memory: 22962, loss_cls: 0.0847, loss_bbox: 0.6032, d0.loss_cls: 0.1073, d0.loss_bbox: 0.7753, d1.loss_cls: 0.0977, d1.loss_bbox: 0.6894, d2.loss_cls: 0.0889, d2.loss_bbox: 0.6455, d3.loss_cls: 0.0850, d3.loss_bbox: 0.6202, d4.loss_cls: 0.0848, d4.loss_bbox: 0.6070, dn_loss_cls: 0.3752, dn_loss_bbox: 0.5256, d0.dn_loss_cls: 0.4199, d0.dn_loss_bbox: 0.6655, d1.dn_loss_cls: 0.3998, d1.dn_loss_bbox: 0.6000, d2.dn_loss_cls: 0.3896, d2.dn_loss_bbox: 0.5660, d3.dn_loss_cls: 0.3793, d3.dn_loss_bbox: 0.5390, d4.dn_loss_cls: 0.3759, d4.dn_loss_bbox: 0.5284, loss: 10.2533, grad_norm: 43.8539
2025-10-12 04:16:02,128 - mmdet - INFO - Epoch [1][3450/4004]	lr: 7.880e-07, eta: 0:17:30, time: 1.816, data_time: 0.034, memory: 22962, loss_cls: 0.0846, loss_bbox: 0.6000, d0.loss_cls: 0.1074, d0.loss_bbox: 0.7709, d1.loss_cls: 0.0979, d1.loss_bbox: 0.6840, d2.loss_cls: 0.0887, d2.loss_bbox: 0.6419, d3.loss_cls: 0.0848, d3.loss_bbox: 0.6160, d4.loss_cls: 0.0846, d4.loss_bbox: 0.6034, dn_loss_cls: 0.3730, dn_loss_bbox: 0.5284, d0.dn_loss_cls: 0.4171, d0.dn_loss_bbox: 0.6717, d1.dn_loss_cls: 0.3980, d1.dn_loss_bbox: 0.6056, d2.dn_loss_cls: 0.3877, d2.dn_loss_bbox: 0.5701, d3.dn_loss_cls: 0.3772, d3.dn_loss_bbox: 0.5414, d4.dn_loss_cls: 0.3737, d4.dn_loss_bbox: 0.5311, loss: 10.2393, grad_norm: 40.6331
2025-10-12 04:17:33,251 - mmdet - INFO - Epoch [1][3500/4004]	lr: 6.563e-07, eta: 0:15:55, time: 1.822, data_time: 0.035, memory: 22962, loss_cls: 0.0838, loss_bbox: 0.5989, d0.loss_cls: 0.1060, d0.loss_bbox: 0.7673, d1.loss_cls: 0.0968, d1.loss_bbox: 0.6837, d2.loss_cls: 0.0880, d2.loss_bbox: 0.6404, d3.loss_cls: 0.0841, d3.loss_bbox: 0.6148, d4.loss_cls: 0.0839, d4.loss_bbox: 0.6023, dn_loss_cls: 0.3757, dn_loss_bbox: 0.5255, d0.dn_loss_cls: 0.4203, d0.dn_loss_bbox: 0.6674, d1.dn_loss_cls: 0.4007, d1.dn_loss_bbox: 0.6009, d2.dn_loss_cls: 0.3905, d2.dn_loss_bbox: 0.5675, d3.dn_loss_cls: 0.3800, d3.dn_loss_bbox: 0.5382, d4.dn_loss_cls: 0.3765, d4.dn_loss_bbox: 0.5284, loss: 10.2216, grad_norm: 43.0018
2025-10-12 04:19:04,817 - mmdet - INFO - Epoch [1][3550/4004]	lr: 5.357e-07, eta: 0:14:19, time: 1.831, data_time: 0.035, memory: 22962, loss_cls: 0.0860, loss_bbox: 0.6093, d0.loss_cls: 0.1085, d0.loss_bbox: 0.7818, d1.loss_cls: 0.0995, d1.loss_bbox: 0.6940, d2.loss_cls: 0.0901, d2.loss_bbox: 0.6509, d3.loss_cls: 0.0863, d3.loss_bbox: 0.6256, d4.loss_cls: 0.0863, d4.loss_bbox: 0.6125, dn_loss_cls: 0.3772, dn_loss_bbox: 0.5321, d0.dn_loss_cls: 0.4224, d0.dn_loss_bbox: 0.6729, d1.dn_loss_cls: 0.4029, d1.dn_loss_bbox: 0.6084, d2.dn_loss_cls: 0.3928, d2.dn_loss_bbox: 0.5739, d3.dn_loss_cls: 0.3816, d3.dn_loss_bbox: 0.5447, d4.dn_loss_cls: 0.3781, d4.dn_loss_bbox: 0.5350, loss: 10.3528, grad_norm: 42.1740
2025-10-12 04:20:35,093 - mmdet - INFO - Epoch [1][3600/4004]	lr: 4.266e-07, eta: 0:12:44, time: 1.805, data_time: 0.035, memory: 22962, loss_cls: 0.0839, loss_bbox: 0.5973, d0.loss_cls: 0.1063, d0.loss_bbox: 0.7690, d1.loss_cls: 0.0972, d1.loss_bbox: 0.6825, d2.loss_cls: 0.0877, d2.loss_bbox: 0.6403, d3.loss_cls: 0.0841, d3.loss_bbox: 0.6138, d4.loss_cls: 0.0840, d4.loss_bbox: 0.6003, dn_loss_cls: 0.3734, dn_loss_bbox: 0.5269, d0.dn_loss_cls: 0.4174, d0.dn_loss_bbox: 0.6656, d1.dn_loss_cls: 0.3977, d1.dn_loss_bbox: 0.6015, d2.dn_loss_cls: 0.3877, d2.dn_loss_bbox: 0.5675, d3.dn_loss_cls: 0.3775, d3.dn_loss_bbox: 0.5392, d4.dn_loss_cls: 0.3742, d4.dn_loss_bbox: 0.5295, loss: 10.2045, grad_norm: 47.9930
2025-10-12 04:22:06,877 - mmdet - INFO - Epoch [1][3650/4004]	lr: 3.294e-07, eta: 0:11:09, time: 1.836, data_time: 0.035, memory: 22962, loss_cls: 0.0837, loss_bbox: 0.6035, d0.loss_cls: 0.1063, d0.loss_bbox: 0.7749, d1.loss_cls: 0.0973, d1.loss_bbox: 0.6879, d2.loss_cls: 0.0880, d2.loss_bbox: 0.6462, d3.loss_cls: 0.0841, d3.loss_bbox: 0.6198, d4.loss_cls: 0.0838, d4.loss_bbox: 0.6072, dn_loss_cls: 0.3763, dn_loss_bbox: 0.5255, d0.dn_loss_cls: 0.4219, d0.dn_loss_bbox: 0.6682, d1.dn_loss_cls: 0.4021, d1.dn_loss_bbox: 0.6022, d2.dn_loss_cls: 0.3919, d2.dn_loss_bbox: 0.5673, d3.dn_loss_cls: 0.3807, d3.dn_loss_bbox: 0.5381, d4.dn_loss_cls: 0.3771, d4.dn_loss_bbox: 0.5282, loss: 10.2623, grad_norm: 46.2524
2025-10-12 04:23:37,972 - mmdet - INFO - Epoch [1][3700/4004]	lr: 2.444e-07, eta: 0:09:34, time: 1.822, data_time: 0.035, memory: 22962, loss_cls: 0.0845, loss_bbox: 0.6006, d0.loss_cls: 0.1070, d0.loss_bbox: 0.7666, d1.loss_cls: 0.0978, d1.loss_bbox: 0.6842, d2.loss_cls: 0.0885, d2.loss_bbox: 0.6414, d3.loss_cls: 0.0848, d3.loss_bbox: 0.6166, d4.loss_cls: 0.0846, d4.loss_bbox: 0.6048, dn_loss_cls: 0.3760, dn_loss_bbox: 0.5282, d0.dn_loss_cls: 0.4201, d0.dn_loss_bbox: 0.6687, d1.dn_loss_cls: 0.4007, d1.dn_loss_bbox: 0.6034, d2.dn_loss_cls: 0.3905, d2.dn_loss_bbox: 0.5692, d3.dn_loss_cls: 0.3803, d3.dn_loss_bbox: 0.5408, d4.dn_loss_cls: 0.3770, d4.dn_loss_bbox: 0.5310, loss: 10.2474, grad_norm: 41.5513
2025-10-12 04:25:08,688 - mmdet - INFO - Epoch [1][3750/4004]	lr: 1.717e-07, eta: 0:08:00, time: 1.814, data_time: 0.035, memory: 22962, loss_cls: 0.0839, loss_bbox: 0.5979, d0.loss_cls: 0.1064, d0.loss_bbox: 0.7652, d1.loss_cls: 0.0973, d1.loss_bbox: 0.6808, d2.loss_cls: 0.0880, d2.loss_bbox: 0.6385, d3.loss_cls: 0.0842, d3.loss_bbox: 0.6131, d4.loss_cls: 0.0841, d4.loss_bbox: 0.6004, dn_loss_cls: 0.3736, dn_loss_bbox: 0.5259, d0.dn_loss_cls: 0.4184, d0.dn_loss_bbox: 0.6635, d1.dn_loss_cls: 0.3980, d1.dn_loss_bbox: 0.5992, d2.dn_loss_cls: 0.3884, d2.dn_loss_bbox: 0.5661, d3.dn_loss_cls: 0.3780, d3.dn_loss_bbox: 0.5385, d4.dn_loss_cls: 0.3744, d4.dn_loss_bbox: 0.5285, loss: 10.1923, grad_norm: 39.3691
2025-10-12 04:26:39,781 - mmdet - INFO - Epoch [1][3800/4004]	lr: 1.118e-07, eta: 0:06:25, time: 1.822, data_time: 0.035, memory: 22962, loss_cls: 0.0849, loss_bbox: 0.5988, d0.loss_cls: 0.1075, d0.loss_bbox: 0.7678, d1.loss_cls: 0.0980, d1.loss_bbox: 0.6825, d2.loss_cls: 0.0889, d2.loss_bbox: 0.6406, d3.loss_cls: 0.0851, d3.loss_bbox: 0.6146, d4.loss_cls: 0.0850, d4.loss_bbox: 0.6023, dn_loss_cls: 0.3756, dn_loss_bbox: 0.5265, d0.dn_loss_cls: 0.4213, d0.dn_loss_bbox: 0.6657, d1.dn_loss_cls: 0.4017, d1.dn_loss_bbox: 0.6012, d2.dn_loss_cls: 0.3910, d2.dn_loss_bbox: 0.5666, d3.dn_loss_cls: 0.3799, d3.dn_loss_bbox: 0.5390, d4.dn_loss_cls: 0.3764, d4.dn_loss_bbox: 0.5292, loss: 10.2301, grad_norm: 42.0676
2025-10-12 04:28:10,275 - mmdet - INFO - Epoch [1][3850/4004]	lr: 6.461e-08, eta: 0:04:50, time: 1.810, data_time: 0.035, memory: 22962, loss_cls: 0.0834, loss_bbox: 0.5991, d0.loss_cls: 0.1062, d0.loss_bbox: 0.7682, d1.loss_cls: 0.0968, d1.loss_bbox: 0.6839, d2.loss_cls: 0.0874, d2.loss_bbox: 0.6416, d3.loss_cls: 0.0838, d3.loss_bbox: 0.6140, d4.loss_cls: 0.0836, d4.loss_bbox: 0.6028, dn_loss_cls: 0.3734, dn_loss_bbox: 0.5285, d0.dn_loss_cls: 0.4181, d0.dn_loss_bbox: 0.6690, d1.dn_loss_cls: 0.3982, d1.dn_loss_bbox: 0.6039, d2.dn_loss_cls: 0.3879, d2.dn_loss_bbox: 0.5699, d3.dn_loss_cls: 0.3777, d3.dn_loss_bbox: 0.5412, d4.dn_loss_cls: 0.3743, d4.dn_loss_bbox: 0.5312, loss: 10.2241, grad_norm: 43.4653
2025-10-12 04:29:40,822 - mmdet - INFO - Epoch [1][3900/4004]	lr: 3.045e-08, eta: 0:03:16, time: 1.811, data_time: 0.035, memory: 22962, loss_cls: 0.0841, loss_bbox: 0.5973, d0.loss_cls: 0.1069, d0.loss_bbox: 0.7661, d1.loss_cls: 0.0974, d1.loss_bbox: 0.6846, d2.loss_cls: 0.0879, d2.loss_bbox: 0.6395, d3.loss_cls: 0.0842, d3.loss_bbox: 0.6138, d4.loss_cls: 0.0841, d4.loss_bbox: 0.6018, dn_loss_cls: 0.3737, dn_loss_bbox: 0.5273, d0.dn_loss_cls: 0.4200, d0.dn_loss_bbox: 0.6669, d1.dn_loss_cls: 0.3993, d1.dn_loss_bbox: 0.6032, d2.dn_loss_cls: 0.3887, d2.dn_loss_bbox: 0.5685, d3.dn_loss_cls: 0.3782, d3.dn_loss_bbox: 0.5402, d4.dn_loss_cls: 0.3745, d4.dn_loss_bbox: 0.5301, loss: 10.2183, grad_norm: 42.2770
2025-10-12 04:31:12,559 - mmdet - INFO - Epoch [1][3950/4004]	lr: 9.376e-09, eta: 0:01:41, time: 1.835, data_time: 0.035, memory: 22962, loss_cls: 0.0854, loss_bbox: 0.6064, d0.loss_cls: 0.1079, d0.loss_bbox: 0.7779, d1.loss_cls: 0.0984, d1.loss_bbox: 0.6921, d2.loss_cls: 0.0895, d2.loss_bbox: 0.6479, d3.loss_cls: 0.0856, d3.loss_bbox: 0.6212, d4.loss_cls: 0.0853, d4.loss_bbox: 0.6101, dn_loss_cls: 0.3781, dn_loss_bbox: 0.5279, d0.dn_loss_cls: 0.4235, d0.dn_loss_bbox: 0.6687, d1.dn_loss_cls: 0.4037, d1.dn_loss_bbox: 0.6032, d2.dn_loss_cls: 0.3935, d2.dn_loss_bbox: 0.5691, d3.dn_loss_cls: 0.3827, d3.dn_loss_bbox: 0.5406, d4.dn_loss_cls: 0.3791, d4.dn_loss_bbox: 0.5307, loss: 10.3086, grad_norm: 46.1753

üîç AQR Debug Info (Forward #4000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.022344
     std: 0.123403
     min: -8.135506
     max: 8.644357
   lidar_weights_stats:
     mean: 0.735503
     std: 0.149185
     min: 0.141515
     max: 0.973509
     shape: [4, 1390]
   camera_weights_stats:
     mean: 0.764576
     std: 0.158128
     min: 0.083649
     max: 0.996048
     shape: [4, 1390]
   weight_map_bev_stats:
     mean: 0.051394
     std: 0.097560
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.170731
     std: 0.601996
     min: 0.000000
     max: 30.639856
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.012864
     std_change: 0.061784
     max_change: 1.981627
     relative_change: 0.066737
   modulation_effect_pers:
     mean_change: -0.004833
     std_change: 0.062701
     max_change: 8.260079
     relative_change: 0.305036

üîç AQR Debug Info (Forward #4000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023348
     std: 0.133642
     min: -14.462277
     max: 13.428419
   lidar_weights_stats:
     mean: 0.713042
     std: 0.143575
     min: 0.075035
     max: 0.988521
     shape: [4, 1440]
   camera_weights_stats:
     mean: 0.753257
     std: 0.166584
     min: 0.135800
     max: 0.995568
     shape: [4, 1440]
   weight_map_bev_stats:
     mean: 0.048811
     std: 0.097031
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.173119
     std: 0.802882
     min: 0.000000
     max: 47.421436
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013029
     std_change: 0.061602
     max_change: 2.130558
     relative_change: 0.069249
   modulation_effect_pers:
     mean_change: -0.004798
     std_change: 0.081287
     max_change: 14.161740
     relative_change: 0.298697

üîç AQR Debug Info (Forward #4000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023164
     std: 0.135054
     min: -19.713039
     max: 19.763115
   lidar_weights_stats:
     mean: 0.708916
     std: 0.157851
     min: 0.117561
     max: 0.978876
     shape: [4, 1490]
   camera_weights_stats:
     mean: 0.761336
     std: 0.167782
     min: 0.138207
     max: 0.993680
     shape: [4, 1490]
   weight_map_bev_stats:
     mean: 0.048779
     std: 0.095990
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.184327
     std: 0.882288
     min: 0.000000
     max: 45.487312
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013948
     std_change: 0.064567
     max_change: 3.047569
     relative_change: 0.073858
   modulation_effect_pers:
     mean_change: -0.004199
     std_change: 0.088901
     max_change: 19.184990
     relative_change: 0.310790

üîç AQR Debug Info (Forward #4000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023889
     std: 0.150567
     min: -16.841175
     max: 15.867964
   lidar_weights_stats:
     mean: 0.747101
     std: 0.133578
     min: 0.164838
     max: 0.989416
     shape: [4, 1510]
   camera_weights_stats:
     mean: 0.751794
     std: 0.155597
     min: 0.137365
     max: 0.995839
     shape: [4, 1510]
   weight_map_bev_stats:
     mean: 0.051608
     std: 0.106717
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.181112
     std: 1.087710
     min: 0.000000
     max: 75.228951
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013240
     std_change: 0.061176
     max_change: 5.466581
     relative_change: 0.068362
   modulation_effect_pers:
     mean_change: -0.004641
     std_change: 0.101709
     max_change: 16.619373
     relative_change: 0.305985

üîç AQR Debug Info (Forward #4000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.022450
     std: 0.160305
     min: -33.261074
     max: 36.333115
   lidar_weights_stats:
     mean: 0.721576
     std: 0.138782
     min: 0.085748
     max: 0.977116
     shape: [4, 1610]
   camera_weights_stats:
     mean: 0.721419
     std: 0.163580
     min: 0.116916
     max: 0.994492
     shape: [4, 1610]
   weight_map_bev_stats:
     mean: 0.052183
     std: 0.112346
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.189397
     std: 1.184495
     min: 0.000000
     max: 67.316658
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013255
     std_change: 0.063503
     max_change: 1.623710
     relative_change: 0.069869
   modulation_effect_pers:
     mean_change: -0.004378
     std_change: 0.112120
     max_change: 35.798935
     relative_change: 0.326050

üîç AQR Debug Info (Forward #4000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023283
     std: 0.145723
     min: -16.898596
     max: 18.299469
   lidar_weights_stats:
     mean: 0.721486
     std: 0.144257
     min: 0.130897
     max: 0.982273
     shape: [4, 1600]
   camera_weights_stats:
     mean: 0.747417
     std: 0.156916
     min: 0.127948
     max: 0.992796
     shape: [4, 1600]
   weight_map_bev_stats:
     mean: 0.051292
     std: 0.112272
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.193140
     std: 1.135989
     min: 0.000000
     max: 68.749191
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013899
     std_change: 0.062390
     max_change: 2.532318
     relative_change: 0.072337
   modulation_effect_pers:
     mean_change: -0.004333
     std_change: 0.099154
     max_change: 17.700836
     relative_change: 0.318546

üîç AQR Debug Info (Forward #4000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023066
     std: 0.158721
     min: -25.015568
     max: 35.416451
   lidar_weights_stats:
     mean: 0.734734
     std: 0.152112
     min: 0.108403
     max: 0.982884
     shape: [4, 1670]
   camera_weights_stats:
     mean: 0.777986
     std: 0.147220
     min: 0.171885
     max: 0.994307
     shape: [4, 1670]
   weight_map_bev_stats:
     mean: 0.053994
     std: 0.114915
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.211006
     std: 1.343595
     min: 0.000000
     max: 83.493729
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.014147
     std_change: 0.061529
     max_change: 2.837128
     relative_change: 0.076696
   modulation_effect_pers:
     mean_change: -0.004243
     std_change: 0.114229
     max_change: 34.995796
     relative_change: 0.332920

üîç AQR Debug Info (Forward #4000):
   FeatureModulator_output_shape: torch.Size([24, 256, 20, 50])
   FeatureModulator_output_stats:
     mean: 0.023770
     std: 0.157186
     min: -21.742994
     max: 26.835825
   lidar_weights_stats:
     mean: 0.701886
     std: 0.156995
     min: 0.093843
     max: 0.982368
     shape: [4, 1730]
   camera_weights_stats:
     mean: 0.723329
     std: 0.167259
     min: 0.140803
     max: 0.993774
     shape: [4, 1730]
   weight_map_bev_stats:
     mean: 0.052535
     std: 0.120050
     min: 0.000000
     max: 1.500000
     shape: [4, 128, 128]
   weight_map_pers_stats:
     mean: 0.201530
     std: 1.203692
     min: 0.000000
     max: 70.829094
     shape: [4, 6, 20, 50]
   modulation_effect_bev:
     mean_change: -0.013016
     std_change: 0.061528
     max_change: 2.343538
     relative_change: 0.070013
   modulation_effect_pers:
     mean_change: -0.004483
     std_change: 0.108119
     max_change: 26.353403
     relative_change: 0.333118
2025-10-12 04:32:44,545 - mmdet - INFO - Exp name: cmt_aqr_voxel0100_r50_800x320_cbgs.py
2025-10-12 04:32:44,546 - mmdet - INFO - Epoch [1][4000/4004]	lr: 1.466e-09, eta: 0:00:07, time: 1.840, data_time: 0.035, memory: 22962, loss_cls: 0.0842, loss_bbox: 0.5932, d0.loss_cls: 0.1069, d0.loss_bbox: 0.7590, d1.loss_cls: 0.0978, d1.loss_bbox: 0.6775, d2.loss_cls: 0.0881, d2.loss_bbox: 0.6358, d3.loss_cls: 0.0845, d3.loss_bbox: 0.6094, d4.loss_cls: 0.0842, d4.loss_bbox: 0.5982, dn_loss_cls: 0.3722, dn_loss_bbox: 0.5228, d0.dn_loss_cls: 0.4175, d0.dn_loss_bbox: 0.6607, d1.dn_loss_cls: 0.3971, d1.dn_loss_bbox: 0.5976, d2.dn_loss_cls: 0.3865, d2.dn_loss_bbox: 0.5635, d3.dn_loss_cls: 0.3766, d3.dn_loss_bbox: 0.5354, d4.dn_loss_cls: 0.3729, d4.dn_loss_bbox: 0.5254, loss: 10.1469, grad_norm: 41.7388
2025-10-12 04:32:52,319 - mmdet - INFO - Saving checkpoint at 1 epochs
[                                                  ] 0/6019, elapsed: 0s, ETA:/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
[                                ] 1/6019, 0.3 task/s, elapsed: 4s, ETA: 21442s[                                ] 2/6019, 0.6 task/s, elapsed: 4s, ETA: 10720s[                                ] 3/6019, 0.8 task/s, elapsed: 4s, ETA:  7145s[                                ] 4/6019, 1.1 task/s, elapsed: 4s, ETA:  5358s[                                ] 5/6019, 1.4 task/s, elapsed: 4s, ETA:  4286s[                                ] 6/6019, 1.7 task/s, elapsed: 4s, ETA:  3571s[                                ] 7/6019, 2.0 task/s, elapsed: 4s, ETA:  3060s[                                ] 8/6019, 2.2 task/s, elapsed: 4s, ETA:  2677s/data/coding/projects/mmdet3d_plugin/core/bbox/coders/multi_task_bbox_coder.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.post_center_range = torch.tensor(
[                                ] 9/6019, 2.3 task/s, elapsed: 4s, ETA:  2559s[                               ] 10/6019, 2.6 task/s, elapsed: 4s, ETA:  2302s[                               ] 11/6019, 2.9 task/s, elapsed: 4s, ETA:  2093s[                               ] 12/6019, 3.1 task/s, elapsed: 4s, ETA:  1918s[                               ] 13/6019, 3.4 task/s, elapsed: 4s, ETA:  1770s[                               ] 14/6019, 3.7 task/s, elapsed: 4s, ETA:  1643s[                               ] 15/6019, 3.9 task/s, elapsed: 4s, ETA:  1534sÔºàÁúÅÁï•ËØÑ‰º∞ËøáÁ®ãÔºâ                                                     mAP: 0.6449
mATE: 0.3390
mASE: 0.2506
mAOE: 0.3226
mAVE: 0.2738
mAAE: 0.1894
NDS: 0.6849
Eval time: 145.2s

Per-class results:
Object Class	AP	ATE	ASE	AOE	AVE	AAE
car	0.853	0.189	0.147	0.079	0.298	0.200
truck	0.602	0.352	0.180	0.128	0.242	0.220
bus	0.727	0.370	0.174	0.045	0.468	0.234
trailer	0.423	0.600	0.205	0.525	0.174	0.167
construction_vehicle	0.295	0.809	0.462	0.940	0.122	0.335
pedestrian	0.826	0.182	0.275	0.344	0.223	0.095
motorcycle	0.706	0.227	0.232	0.257	0.473	0.258
bicycle	0.609	0.188	0.259	0.526	0.189	0.006
traffic_cone	0.700	0.202	0.312	nan	nan	nan
barrier	0.709	0.271	0.261	0.058	nan	nan
2025-10-12 04:46:36,536 - mmdet - INFO - Exp name: cmt_aqr_voxel0100_r50_800x320_cbgs.py
2025-10-12 04:46:36,537 - mmdet - INFO - Epoch(val) [1][753]	pts_bbox_NuScenes/car_AP_dist_0.5: 0.7507, pts_bbox_NuScenes/car_AP_dist_1.0: 0.8594, pts_bbox_NuScenes/car_AP_dist_2.0: 0.8915, pts_bbox_NuScenes/car_AP_dist_4.0: 0.9088, pts_bbox_NuScenes/car_trans_err: 0.1893, pts_bbox_NuScenes/car_scale_err: 0.1474, pts_bbox_NuScenes/car_orient_err: 0.0791, pts_bbox_NuScenes/car_vel_err: 0.2980, pts_bbox_NuScenes/car_attr_err: 0.2000, pts_bbox_NuScenes/mATE: 0.3390, pts_bbox_NuScenes/mASE: 0.2506, pts_bbox_NuScenes/mAOE: 0.3226, pts_bbox_NuScenes/mAVE: 0.2738, pts_bbox_NuScenes/mAAE: 0.1894, pts_bbox_NuScenes/truck_AP_dist_0.5: 0.3839, pts_bbox_NuScenes/truck_AP_dist_1.0: 0.5919, pts_bbox_NuScenes/truck_AP_dist_2.0: 0.6978, pts_bbox_NuScenes/truck_AP_dist_4.0: 0.7330, pts_bbox_NuScenes/truck_trans_err: 0.3516, pts_bbox_NuScenes/truck_scale_err: 0.1795, pts_bbox_NuScenes/truck_orient_err: 0.1282, pts_bbox_NuScenes/truck_vel_err: 0.2424, pts_bbox_NuScenes/truck_attr_err: 0.2203, pts_bbox_NuScenes/construction_vehicle_AP_dist_0.5: 0.0275, pts_bbox_NuScenes/construction_vehicle_AP_dist_1.0: 0.1723, pts_bbox_NuScenes/construction_vehicle_AP_dist_2.0: 0.4352, pts_bbox_NuScenes/construction_vehicle_AP_dist_4.0: 0.5452, pts_bbox_NuScenes/construction_vehicle_trans_err: 0.8094, pts_bbox_NuScenes/construction_vehicle_scale_err: 0.4616, pts_bbox_NuScenes/construction_vehicle_orient_err: 0.9401, pts_bbox_NuScenes/construction_vehicle_vel_err: 0.1218, pts_bbox_NuScenes/construction_vehicle_attr_err: 0.3351, pts_bbox_NuScenes/bus_AP_dist_0.5: 0.4617, pts_bbox_NuScenes/bus_AP_dist_1.0: 0.7147, pts_bbox_NuScenes/bus_AP_dist_2.0: 0.8459, pts_bbox_NuScenes/bus_AP_dist_4.0: 0.8850, pts_bbox_NuScenes/bus_trans_err: 0.3704, pts_bbox_NuScenes/bus_scale_err: 0.1743, pts_bbox_NuScenes/bus_orient_err: 0.0454, pts_bbox_NuScenes/bus_vel_err: 0.4682, pts_bbox_NuScenes/bus_attr_err: 0.2336, pts_bbox_NuScenes/trailer_AP_dist_0.5: 0.1051, pts_bbox_NuScenes/trailer_AP_dist_1.0: 0.3565, pts_bbox_NuScenes/trailer_AP_dist_2.0: 0.5571, pts_bbox_NuScenes/trailer_AP_dist_4.0: 0.6715, pts_bbox_NuScenes/trailer_trans_err: 0.5997, pts_bbox_NuScenes/trailer_scale_err: 0.2048, pts_bbox_NuScenes/trailer_orient_err: 0.5252, pts_bbox_NuScenes/trailer_vel_err: 0.1742, pts_bbox_NuScenes/trailer_attr_err: 0.1671, pts_bbox_NuScenes/barrier_AP_dist_0.5: 0.5598, pts_bbox_NuScenes/barrier_AP_dist_1.0: 0.7028, pts_bbox_NuScenes/barrier_AP_dist_2.0: 0.7726, pts_bbox_NuScenes/barrier_AP_dist_4.0: 0.8006, pts_bbox_NuScenes/barrier_trans_err: 0.2712, pts_bbox_NuScenes/barrier_scale_err: 0.2608, pts_bbox_NuScenes/barrier_orient_err: 0.0576, pts_bbox_NuScenes/barrier_vel_err: nan, pts_bbox_NuScenes/barrier_attr_err: nan, pts_bbox_NuScenes/motorcycle_AP_dist_0.5: 0.5881, pts_bbox_NuScenes/motorcycle_AP_dist_1.0: 0.7212, pts_bbox_NuScenes/motorcycle_AP_dist_2.0: 0.7522, pts_bbox_NuScenes/motorcycle_AP_dist_4.0: 0.7639, pts_bbox_NuScenes/motorcycle_trans_err: 0.2268, pts_bbox_NuScenes/motorcycle_scale_err: 0.2323, pts_bbox_NuScenes/motorcycle_orient_err: 0.2575, pts_bbox_NuScenes/motorcycle_vel_err: 0.4731, pts_bbox_NuScenes/motorcycle_attr_err: 0.2578, pts_bbox_NuScenes/bicycle_AP_dist_0.5: 0.5580, pts_bbox_NuScenes/bicycle_AP_dist_1.0: 0.6156, pts_bbox_NuScenes/bicycle_AP_dist_2.0: 0.6271, pts_bbox_NuScenes/bicycle_AP_dist_4.0: 0.6366, pts_bbox_NuScenes/bicycle_trans_err: 0.1879, pts_bbox_NuScenes/bicycle_scale_err: 0.2585, pts_bbox_NuScenes/bicycle_orient_err: 0.5262, pts_bbox_NuScenes/bicycle_vel_err: 0.1888, pts_bbox_NuScenes/bicycle_attr_err: 0.0060, pts_bbox_NuScenes/pedestrian_AP_dist_0.5: 0.7621, pts_bbox_NuScenes/pedestrian_AP_dist_1.0: 0.8193, pts_bbox_NuScenes/pedestrian_AP_dist_2.0: 0.8513, pts_bbox_NuScenes/pedestrian_AP_dist_4.0: 0.8698, pts_bbox_NuScenes/pedestrian_trans_err: 0.1825, pts_bbox_NuScenes/pedestrian_scale_err: 0.2752, pts_bbox_NuScenes/pedestrian_orient_err: 0.3438, pts_bbox_NuScenes/pedestrian_vel_err: 0.2234, pts_bbox_NuScenes/pedestrian_attr_err: 0.0954, pts_bbox_NuScenes/traffic_cone_AP_dist_0.5: 0.6231, pts_bbox_NuScenes/traffic_cone_AP_dist_1.0: 0.6838, pts_bbox_NuScenes/traffic_cone_AP_dist_2.0: 0.7274, pts_bbox_NuScenes/traffic_cone_AP_dist_4.0: 0.7651, pts_bbox_NuScenes/traffic_cone_trans_err: 0.2015, pts_bbox_NuScenes/traffic_cone_scale_err: 0.3118, pts_bbox_NuScenes/traffic_cone_orient_err: nan, pts_bbox_NuScenes/traffic_cone_vel_err: nan, pts_bbox_NuScenes/traffic_cone_attr_err: nan, pts_bbox_NuScenes/NDS: 0.6849, pts_bbox_NuScenes/mAP: 0.6449
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
/data/miniconda/envs/torch/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:70: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.000278472900390625 seconds
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 0, "group_rank": 0, "worker_id": "11745", "role": "default", "hostname": "fyleanvkgntuufnb-make-789c955558-4v6fw", "state": "SUCCEEDED", "total_run_time": 8423, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [0], \"role_rank\": [0], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 1, "group_rank": 0, "worker_id": "11746", "role": "default", "hostname": "fyleanvkgntuufnb-make-789c955558-4v6fw", "state": "SUCCEEDED", "total_run_time": 8423, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [1], \"role_rank\": [1], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 2, "group_rank": 0, "worker_id": "11747", "role": "default", "hostname": "fyleanvkgntuufnb-make-789c955558-4v6fw", "state": "SUCCEEDED", "total_run_time": 8423, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [2], \"role_rank\": [2], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 3, "group_rank": 0, "worker_id": "11748", "role": "default", "hostname": "fyleanvkgntuufnb-make-789c955558-4v6fw", "state": "SUCCEEDED", "total_run_time": 8423, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [3], \"role_rank\": [3], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 4, "group_rank": 0, "worker_id": "11749", "role": "default", "hostname": "fyleanvkgntuufnb-make-789c955558-4v6fw", "state": "SUCCEEDED", "total_run_time": 8423, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [4], \"role_rank\": [4], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 5, "group_rank": 0, "worker_id": "11750", "role": "default", "hostname": "fyleanvkgntuufnb-make-789c955558-4v6fw", "state": "SUCCEEDED", "total_run_time": 8423, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [5], \"role_rank\": [5], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 6, "group_rank": 0, "worker_id": "11751", "role": "default", "hostname": "fyleanvkgntuufnb-make-789c955558-4v6fw", "state": "SUCCEEDED", "total_run_time": 8423, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [6], \"role_rank\": [6], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 7, "group_rank": 0, "worker_id": "11752", "role": "default", "hostname": "fyleanvkgntuufnb-make-789c955558-4v6fw", "state": "SUCCEEDED", "total_run_time": 8423, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [7], \"role_rank\": [7], \"role_world_size\": [8]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "AGENT", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": null, "group_rank": 0, "worker_id": null, "role": "default", "hostname": "fyleanvkgntuufnb-make-789c955558-4v6fw", "state": "SUCCEEDED", "total_run_time": 8423, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\"}", "agent_restarts": 0}}
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
