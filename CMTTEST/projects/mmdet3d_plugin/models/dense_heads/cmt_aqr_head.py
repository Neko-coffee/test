# ------------------------------------------------------------------------
# CmtAQRHead - é›†æˆAQRæƒé‡å›¾æ¸²æŸ“æœºåˆ¶çš„CMTæ£€æµ‹å¤´
# æ ¸å¿ƒåŠŸèƒ½ï¼šå°†AQRæƒé‡ç”Ÿæˆã€æƒé‡å›¾æ¸²æŸ“ã€ç‰¹å¾è°ƒåˆ¶é›†æˆåˆ°CMTæ¡†æ¶ä¸­
# å®ç°ç»†ç²’åº¦çš„å¤šæ¨¡æ€ç‰¹å¾è°ƒåˆ¶
# ------------------------------------------------------------------------
import torch
import torch.nn as nn
import numpy as np
import warnings
from mmcv.runner import force_fp32, auto_fp16
from mmdet.models import HEADS
from ..utils.aqr_weight_generator import AQRWeightGenerator
from ..utils.weight_renderer import WeightRenderer
from ..utils.feature_modulator import FeatureModulator
from .cmt_head import CmtHead


@HEADS.register_module()
class CmtAQRHead(CmtHead):
    """
    é›†æˆAQRæƒé‡å›¾æ¸²æŸ“æœºåˆ¶çš„CMTæ£€æµ‹å¤´ï¼ˆåŒæ¨¡å¼æ”¯æŒï¼‰
    
    ç»§æ‰¿è‡ªCmtHeadï¼Œåœ¨åŸæœ‰åŸºç¡€ä¸Šå¢åŠ ï¼š
    1. AQRæƒé‡ç”Ÿæˆå™¨ï¼šä¸ºæ¯ä¸ªæŸ¥è¯¢ç”Ÿæˆæ¨¡æ€æƒé‡
    2. æƒé‡å›¾æ¸²æŸ“å™¨ï¼šå°†æŸ¥è¯¢æƒé‡æ¸²æŸ“åˆ°ç‰¹å¾å›¾ç©ºé—´
    3. çµæ´»çš„ç‰¹å¾è°ƒåˆ¶ï¼šæ”¯æŒç®€åŒ–æ¨¡å¼ï¼ˆç›´æ¥ç›¸ä¹˜ï¼‰å’Œå®Œæ•´æ¨¡å¼ï¼ˆFeatureModulatorï¼‰
    4. ä¿æŒä¸åŸCMT Transformerçš„å®Œå…¨å…¼å®¹æ€§
    5. ä½¿ç”¨pipelineçš„ModalMask3Dè¿›è¡Œæ¨¡æ€maskï¼ˆæ— æ¨¡å‹å†…éƒ¨maskï¼‰
    
    ç‰¹å¾è°ƒåˆ¶æ¨¡å¼ï¼š
    - use_simple_modulation=True: ğŸ”¥ ç®€åŒ–æ¨¡å¼ï¼Œç›´æ¥ç›¸ä¹˜ï¼Œé€Ÿåº¦å¿«
    - use_simple_modulation=False: ğŸ›¡ï¸ å®Œæ•´æ¨¡å¼ï¼ŒåŒ…å«æ®‹å·®è¿æ¥ã€æƒé‡å½’ä¸€åŒ–ç­‰ï¼Œæ›´ç¨³å®š
    
    Args:
        aqr_config (dict): AQRæƒé‡ç”Ÿæˆå™¨é…ç½®
        renderer_config (dict): æƒé‡æ¸²æŸ“å™¨é…ç½®
        modulator_config (dict): ç‰¹å¾è°ƒåˆ¶å™¨é…ç½®ï¼ˆä»…åœ¨å®Œæ•´æ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
        enable_aqr (bool): æ˜¯å¦å¯ç”¨AQRæœºåˆ¶ï¼Œé»˜è®¤True
        debug_mode (bool): æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œé»˜è®¤False
        visualization_interval (int): å¯è§†åŒ–é—´éš”ï¼ˆä»…åœ¨debugæ¨¡å¼ä¸‹ï¼‰ï¼Œé»˜è®¤100
        use_simple_modulation (bool): æ˜¯å¦ä½¿ç”¨ç®€åŒ–è°ƒåˆ¶æ¨¡å¼ï¼Œé»˜è®¤Falseï¼ˆå®Œæ•´æ¨¡å¼ï¼‰
        **kwargs: CmtHeadçš„å…¶ä»–å‚æ•°
    """
    
    def __init__(self,
                 aqr_config=None,
                 renderer_config=None,
                 modulator_config=None,
                 enable_aqr=True,
                 debug_mode=False,
                 visualization_interval=100,
                 use_simple_modulation=False,  # ğŸ”¥ æ–°å¢ï¼šé€‰æ‹©ç®€åŒ–æ¨¡å¼è¿˜æ˜¯å®Œæ•´æ¨¡å¼
                 **kwargs):
        # å…ˆåˆå§‹åŒ–çˆ¶ç±»CmtHead
        super(CmtAQRHead, self).__init__(**kwargs)
        
        self.enable_aqr = enable_aqr
        self.debug_mode = debug_mode
        self.visualization_interval = visualization_interval
        self.use_simple_modulation = use_simple_modulation  # ğŸ”¥ è®°å½•è°ƒåˆ¶æ¨¡å¼
        self._forward_count = 0
        
        if self.enable_aqr:
            # åˆå§‹åŒ–AQRç»„ä»¶
            self._init_aqr_components(aqr_config, renderer_config, modulator_config)
        
        # è°ƒè¯•ä¿¡æ¯å­˜å‚¨
        if self.debug_mode:
            self.debug_info = {}
            self._setup_debug_hooks()
    
    def _init_aqr_components(self, aqr_config, renderer_config, modulator_config):
        """åˆå§‹åŒ–AQRç›¸å…³ç»„ä»¶"""
        
        # é»˜è®¤é…ç½®
        default_aqr_config = dict(
            type='AQRWeightGenerator',
            embed_dims=self.hidden_dim,
            encoder_config=dict(
                type='PETRTransformerDecoder',  # ğŸ”¥ ç»Ÿä¸€ä½¿ç”¨PETR
                return_intermediate=True,
                num_layers=1,
                transformerlayers=dict(
                    type='PETRTransformerDecoderLayer',  # ğŸ”¥ PETRå±‚
                    with_cp=False,
                    attn_cfgs=[  # ğŸ”¥ PETRéœ€è¦åˆ—è¡¨æ ¼å¼
                        dict(
                            type='MultiheadAttention',
                            embed_dims=self.hidden_dim,
                            num_heads=4,  # ğŸ”¥ ä¸MoMEä¿æŒä¸€è‡´ï¼šAQRä½¿ç”¨4å¤´
                            dropout=0.1
                        ),
                    ],
                    ffn_cfgs=dict(
                        type='FFN',
                        embed_dims=self.hidden_dim,
                        feedforward_channels=self.hidden_dim * 4,
                        num_fcs=2,
                        ffn_drop=0.1,
                        act_cfg=dict(type='ReLU', inplace=True)
                    ),
                    feedforward_channels=self.hidden_dim * 4,
                    operation_order=('cross_attn', 'norm', 'ffn', 'norm')  # ğŸ”¥ ä¸MoMEä¿æŒä¸€è‡´ï¼Œåªæœ‰cross_attn
                )
            ),
            window_sizes=[15, 5],
            use_type_embed=True,
            pc_range=self.pc_range
        )
        
        default_renderer_config = dict(
            type='WeightRenderer',
            render_method='gaussian',
            gaussian_sigma=2.0,
            bev_feature_shape=(180, 180),
            pers_feature_shape=(6, 40, 100),
            normalize_weights=True
        )
        
        # ğŸ”¥ æ ¹æ®æ¨¡å¼é€‰æ‹©ç‰¹å¾è°ƒåˆ¶æ–¹å¼
        default_modulator_config = dict(
            type='FeatureModulator',
            modulation_type='element_wise',
            normalize_weights=True,
            residual_connection=True,
            residual_weight=0.1,
            learnable_modulation=False,
            activation='none'
        )
        
        # åˆå¹¶ç”¨æˆ·é…ç½®
        if aqr_config:
            default_aqr_config.update(aqr_config)
        if renderer_config:
            default_renderer_config.update(renderer_config)
        if modulator_config:
            default_modulator_config.update(modulator_config)
        
        # åˆ›å»ºç»„ä»¶
        self.aqr_weight_generator = AQRWeightGenerator(**default_aqr_config)
        self.weight_renderer = WeightRenderer(**default_renderer_config)
        
        # ğŸ”¥ æ ¹æ®æ¨¡å¼é€‰æ‹©æ˜¯å¦åˆ›å»ºFeatureModulator
        if not self.use_simple_modulation:
            self.feature_modulator = FeatureModulator(**default_modulator_config)
        else:
            self.feature_modulator = None  # ä½¿ç”¨ç®€åŒ–æ¨¡å¼
        
        print(f"âœ… AQR components initialized successfully!")
        print(f"   - AQRWeightGenerator: {default_aqr_config['type']}")
        print(f"   - WeightRenderer: {default_renderer_config['type']} ({default_renderer_config['render_method']})")
        if self.use_simple_modulation:
            print(f"   - FeatureModulator: ğŸ”¥ Simple mode (direct multiplication)")
        else:
            print(f"   - FeatureModulator: ğŸ›¡ï¸ Full mode ({default_modulator_config['modulation_type']}, residual={default_modulator_config['residual_connection']})")
    
    def _setup_debug_hooks(self):
        """è®¾ç½®è°ƒè¯•é’©å­"""
        def debug_hook(module, input, output):
            if hasattr(output, 'shape'):
                self.debug_info[f'{module.__class__.__name__}_output_shape'] = output.shape
                if torch.is_tensor(output):
                    self.debug_info[f'{module.__class__.__name__}_output_stats'] = {
                        'mean': output.mean().item(),
                        'std': output.std().item(),
                        'min': output.min().item(),
                        'max': output.max().item()
                    }
        
        if hasattr(self, 'aqr_weight_generator'):
            self.aqr_weight_generator.register_forward_hook(debug_hook)
            self.weight_renderer.register_forward_hook(debug_hook)
            if hasattr(self, 'feature_modulator') and self.feature_modulator is not None:
                self.feature_modulator.register_forward_hook(debug_hook)
    
    @force_fp32(apply_to=('x', 'x_img'))
    def forward_single(self, x, x_img, img_metas):
        """
        å‰å‘ä¼ æ’­ï¼šé›†æˆAQRæƒé‡å›¾æ¸²æŸ“æœºåˆ¶
        
        Args:
            x: [bs, c, h, w] LiDARç‰¹å¾å›¾
            x_img: [bs*views, c, h, w] Cameraç‰¹å¾å›¾
            img_metas: å›¾åƒå…ƒæ•°æ®
            
        Returns:
            ret_dicts: æ£€æµ‹ç»“æœå­—å…¸åˆ—è¡¨
        """
        self._forward_count += 1
        ret_dicts = []
        
        # 1. æ ‡å‡†CMTç‰¹å¾é¢„å¤„ç†
        if x is not None:
            x = self.shared_conv(x)
        
        # è·å–å‚è€ƒç‚¹
        reference_points = self.reference_points.weight
        reference_points, attn_mask, mask_dict = self.prepare_for_dn(
            x.shape[0] if x is not None else len(img_metas), 
            reference_points, 
            img_metas
        )
        
        # 2. ğŸ”¥ AQRæƒé‡å›¾æ¸²æŸ“æµæ°´çº¿
        if self.enable_aqr and x is not None and x_img is not None:
            x, x_img = self._apply_aqr_modulation(x, x_img, reference_points, img_metas)
        
        # 3. æ ‡å‡†CMTä½ç½®ç¼–ç å’ŒæŸ¥è¯¢åµŒå…¥
        if x is not None:
            mask = x.new_zeros(x.shape[0], x.shape[2], x.shape[3])
            bev_pos_embeds = self.bev_embedding(
                self.pos2embed(self.coords_bev.to(x.device), num_pos_feats=self.hidden_dim)
            )
        else:
            mask = None
            bev_pos_embeds = None
        
        if x_img is not None:
            rv_pos_embeds = self._rv_pe(x_img, img_metas)
        else:
            rv_pos_embeds = None
        
        # æŸ¥è¯¢åµŒå…¥
        bev_query_embeds, rv_query_embeds = self.query_embed(reference_points, img_metas)
        query_embeds = bev_query_embeds
        if rv_query_embeds is not None:
            query_embeds = query_embeds + rv_query_embeds
        
        # 4. æ ‡å‡†CMT Transformerå¤„ç†
        outs_dec, _ = self.transformer(
            x, x_img, query_embeds,
            bev_pos_embeds, rv_pos_embeds,
            attn_masks=attn_mask
        )
        outs_dec = torch.nan_to_num(outs_dec)
        
        # 5. æ ‡å‡†CMTåå¤„ç†å’Œä»»åŠ¡å¤´
        reference = self.inverse_sigmoid(reference_points.clone())
        
        flag = 0
        for task_id, task in enumerate(self.task_heads):
            outs = task(outs_dec)
            
            # å›å½’åˆ†æ”¯å¤„ç†
            reg_branch = None
            if 'reg_branch' in outs:
                reg_branch = outs['reg_branch']
            
            # æ ‡å‡†CMTçš„è¾“å‡ºå¤„ç†é€»è¾‘
            for key in outs.keys():
                if 'reg' in key or 'height' in key:
                    outs[key] = outs[key] + reference[..., :outs[key].shape[-1]]
                    if 'vel' in key:
                        outs[key][..., :2] = outs[key][..., :2] / self.scalar
                    else:
                        outs[key] = outs[key] / self.scalar
            
            ret_dicts.append(outs)
        
        # 6. è°ƒè¯•å’Œå¯è§†åŒ–
        if self.debug_mode and self._forward_count % self.visualization_interval == 0:
            self._debug_visualization(img_metas)
        
        return ret_dicts
    
    def _apply_aqr_modulation(self, x, x_img, reference_points, img_metas):
        """
        åº”ç”¨AQRæƒé‡å›¾æ¸²æŸ“è°ƒåˆ¶ï¼ˆç®€åŒ–ç‰ˆï¼‰
        ğŸ”¥ æ ¸å¿ƒæ”¹è¿›ï¼šç›´æ¥ä½¿ç”¨pipelineçš„ModalMask3Dï¼Œç‰¹å¾è°ƒåˆ¶ç®€åŒ–ä¸ºç›´æ¥ç›¸ä¹˜
        
        Args:
            x: [bs, c, h, w] LiDARç‰¹å¾å›¾
            x_img: [bs*views, c, h, w] Cameraç‰¹å¾å›¾
            reference_points: [bs, num_queries, 3] å‚è€ƒç‚¹
            img_metas: å›¾åƒå…ƒæ•°æ®
            
        Returns:
            x_modulated: è°ƒåˆ¶åçš„LiDARç‰¹å¾å›¾
            x_img_modulated: è°ƒåˆ¶åçš„Cameraç‰¹å¾å›¾
        """
        # ğŸ”¥ ä½¿ç”¨pipelineçš„ModalMask3Dï¼Œæ— éœ€æ¨¡å‹å†…éƒ¨mask
        bs, c, h, w = x.shape
        
        # å‡†å¤‡èåˆç‰¹å¾å’Œä½ç½®ç¼–ç ï¼ˆç”¨äºAQRï¼‰
        bev_memory = x.flatten(2).transpose(1, 2)  # [bs, h*w, c]
        rv_memory = x_img.view(bs, -1, x_img.shape[1], x_img.shape[2] * x_img.shape[3])
        rv_memory = rv_memory.flatten(2).transpose(1, 2)  # [bs, views*h*w, c]
        
        # èåˆmemory
        memory = torch.cat([bev_memory, rv_memory], dim=1).transpose(0, 1)  # [total_elements, bs, c]
        
        # ä½ç½®ç¼–ç 
        bev_pos_embeds = self.bev_embedding(
            self.pos2embed(self.coords_bev.to(x.device), num_pos_feats=self.hidden_dim)
        )
        rv_pos_embeds = self._rv_pe(x_img, img_metas)
        bev_pos_embeds = bev_pos_embeds.unsqueeze(1).repeat(1, bs, 1)
        rv_pos_embeds = rv_pos_embeds.view(bs, -1, self.hidden_dim).transpose(0, 1)
        
        pos_embed = torch.cat([bev_pos_embeds, rv_pos_embeds], dim=0)  # [total_elements, bs, c]
        
        # æŸ¥è¯¢åµŒå…¥
        bev_query_embeds, rv_query_embeds = self.query_embed(reference_points, img_metas)
        query_embed = bev_query_embeds + rv_query_embeds  # [bs, num_queries, c]
        query_embed = query_embed.transpose(0, 1)  # [num_queries, bs, c]
        
        try:
            # Step 1: AQRæƒé‡ç”Ÿæˆï¼ˆç«¯åˆ°ç«¯å­¦ä¹ ï¼Œæ— éœ€æƒé‡æŸå¤±ï¼‰
            lidar_weights, camera_weights, _, projection_info = self.aqr_weight_generator(
                query_embed, memory, pos_embed, reference_points, img_metas
            )
            
            # Step 2: æƒé‡å›¾æ¸²æŸ“
            weight_map_bev = self.weight_renderer.render_bev_weights(
                lidar_weights, projection_info['pts_bev']
            )
            weight_map_pers = self.weight_renderer.render_perspective_weights(
                camera_weights, projection_info['pts_pers']
            )
            
            # Step 3: ğŸ”¥ ç‰¹å¾è°ƒåˆ¶ï¼ˆæ”¯æŒä¸¤ç§æ¨¡å¼ï¼‰
            if self.use_simple_modulation:
                # ç®€åŒ–æ¨¡å¼ï¼šç›´æ¥ç›¸ä¹˜
                x_modulated = x * weight_map_bev.unsqueeze(1)  # [bs, c, h, w] * [bs, 1, h, w]
                x_img_modulated = x_img * weight_map_pers.view(-1, 1, weight_map_pers.shape[-2], weight_map_pers.shape[-1])
            else:
                # å®Œæ•´æ¨¡å¼ï¼šä½¿ç”¨FeatureModulatorï¼ˆåŒ…å«æ®‹å·®è¿æ¥ã€å½’ä¸€åŒ–ç­‰ï¼‰
                x_modulated = self.feature_modulator(x, weight_map_bev, feature_type='bev')
                x_img_modulated = self.feature_modulator(x_img, weight_map_pers, feature_type='perspective')
            
            # å­˜å‚¨è°ƒè¯•ä¿¡æ¯
            if self.debug_mode:
                self.debug_info.update({
                    'lidar_weights_stats': self._compute_tensor_stats(lidar_weights),
                    'camera_weights_stats': self._compute_tensor_stats(camera_weights),
                    'weight_map_bev_stats': self._compute_tensor_stats(weight_map_bev),
                    'weight_map_pers_stats': self._compute_tensor_stats(weight_map_pers),
                    'modulation_effect_bev': self._compute_modulation_effect(x, x_modulated),
                    'modulation_effect_pers': self._compute_modulation_effect(x_img, x_img_modulated)
                })
            
            return x_modulated, x_img_modulated
            
        except Exception as e:
            warnings.warn(f"AQR modulation failed: {e}. Using original features.")
            return x, x_img
    
    # ğŸ”¥ _apply_modal_maskingå‡½æ•°å·²åˆ é™¤ï¼Œä½¿ç”¨pipelineçš„ModalMask3Dæ›¿ä»£
    
    def _compute_tensor_stats(self, tensor):
        """è®¡ç®—å¼ é‡ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'mean': tensor.mean().item(),
            'std': tensor.std().item(),
            'min': tensor.min().item(),
            'max': tensor.max().item(),
            'shape': list(tensor.shape)
        }
    
    def _compute_modulation_effect(self, original, modulated):
        """è®¡ç®—è°ƒåˆ¶æ•ˆæœ"""
        diff = modulated - original
        return {
            'mean_change': diff.mean().item(),
            'std_change': diff.std().item(),
            'max_change': diff.abs().max().item(),
            'relative_change': (diff.abs() / (original.abs() + 1e-8)).mean().item()
        }
    
    def _debug_visualization(self, img_metas):
        """è°ƒè¯•å¯è§†åŒ–"""
        if not hasattr(self, 'debug_info') or len(self.debug_info) == 0:
            return
        
        print(f"\nğŸ” AQR Debug Info (Forward #{self._forward_count}):")
        for key, value in self.debug_info.items():
            if isinstance(value, dict):
                print(f"   {key}:")
                for k, v in value.items():
                    if isinstance(v, float):
                        print(f"     {k}: {v:.6f}")
                    else:
                        print(f"     {k}: {v}")
            else:
                print(f"   {key}: {value}")
        
        # æ¸…ç©ºè°ƒè¯•ä¿¡æ¯
        self.debug_info.clear()
    
    def pos2embed(self, pos, num_pos_feats=128, temperature=10000):
        """ä½ç½®ç¼–ç è½¬æ¢ï¼ˆå¤ç”¨CMTé€»è¾‘ï¼‰"""
        scale = 2 * np.pi
        pos = pos * scale
        dim_t = torch.arange(num_pos_feats, dtype=torch.float32, device=pos.device)
        dim_t = temperature ** (2 * (dim_t // 2) / num_pos_feats)
        pos_x = pos[..., 0, None] / dim_t
        pos_y = pos[..., 1, None] / dim_t
        pos_x = torch.stack((pos_x[..., 0::2].sin(), pos_x[..., 1::2].cos()), dim=-1).flatten(-2)
        pos_y = torch.stack((pos_y[..., 0::2].sin(), pos_y[..., 1::2].cos()), dim=-1).flatten(-2)
        posemb = torch.cat((pos_y, pos_x), dim=-1)
        return posemb
    
    def inverse_sigmoid(self, x, eps=1e-5):
        """åsigmoidå‡½æ•°ï¼ˆå¤ç”¨CMTé€»è¾‘ï¼‰"""
        x = x.clamp(min=0, max=1)
        x1 = x.clamp(min=eps)
        x2 = (1 - x).clamp(min=eps)
        return torch.log(x1 / x2)
    
    def get_aqr_loss(self):
        """è·å–AQRç›¸å…³çš„æŸå¤±ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ AQRç‰¹å®šçš„æŸå¤±è®¡ç®—
        # ä¾‹å¦‚ï¼šæƒé‡åˆ†å¸ƒçš„æ­£åˆ™åŒ–æŸå¤±ã€æ¨¡æ€å¹³è¡¡æŸå¤±ç­‰
        loss_dict = {}
        
        # ç¤ºä¾‹ï¼šæƒé‡å¹³è¡¡æŸå¤±
        if hasattr(self, '_last_lidar_weights') and hasattr(self, '_last_camera_weights'):
            lidar_mean = self._last_lidar_weights.mean()
            camera_mean = self._last_camera_weights.mean()
            balance_loss = torch.abs(lidar_mean - camera_mean)
            loss_dict['aqr_balance_loss'] = balance_loss * 0.01  # å°æƒé‡
        
        return loss_dict


# é…ç½®ç¤ºä¾‹
def get_cmt_aqr_config():
    """è·å–CmtAQRHeadçš„é…ç½®ç¤ºä¾‹"""
    return dict(
        type='CmtAQRHead',
        # CMT HeadåŸºæœ¬é…ç½®
        in_channels=512,
        hidden_dim=256,
        num_query=900,
        # AQRç‰¹å®šé…ç½®
        enable_aqr=True,
        debug_mode=False,
        visualization_interval=100,
        aqr_config=dict(
            embed_dims=256,
            window_sizes=[15, 5],
            use_type_embed=True
        ),
        renderer_config=dict(
            render_method='gaussian',
            gaussian_sigma=2.0,
            normalize_weights=True
        ),
        modulator_config=dict(
            modulation_type='element_wise',
            residual_connection=True,
            residual_weight=0.1
        ),
        # å…¶ä»–CMTé…ç½®...
        transformer=dict(
            type='CmtTransformer',
            # transformeré…ç½®...
        ),
        # æŸå¤±å‡½æ•°é…ç½®...
        loss_cls=dict(type='FocalLoss', use_sigmoid=True, gamma=2, alpha=0.25, loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', reduction='mean', loss_weight=0.25),
        loss_heatmap=dict(type='GaussianFocalLoss', reduction='mean', loss_weight=1.0)
    )
