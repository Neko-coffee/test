# AQRæ—§æ–¹æ¡ˆ vs Attention Biasæ–°æ–¹æ¡ˆå¯¹æ¯” ğŸ”„

**åˆ›å»ºæ—¶é—´**: 2025-01-XX  
**ç›®çš„**: æ¸…æ™°å±•ç¤ºAQRçš„ä¸¤ç§å®ç°æ–¹å¼åŠå…¶è”ç³»

---

## ğŸ¯ æ ¸å¿ƒæ€æƒ³å¯¹æ¯”

### **å…±åŒç‚¹ï¼šAQRçš„æ ¸å¿ƒç†å¿µ**
```
ç›®æ ‡ï¼šè®©æ¨¡å‹çŸ¥é“å½“å‰ä½ç½®ï¼Œå“ªä¸ªæ¨¡æ€æ›´å¯ä¿¡
æ–¹æ³•ï¼šä¸ºæ¯ä¸ªqueryç”ŸæˆLiDARå’ŒCameraçš„å¯ä¿¡åº¦æƒé‡

æ ¸å¿ƒæ¨¡å—ï¼ˆå®Œå…¨ç›¸åŒï¼‰ï¼š
â”œâ”€ AQRWeightGeneratorï¼ˆæƒé‡ç”Ÿæˆå™¨ï¼‰
â”‚   â”œâ”€ è¾“å…¥ï¼šqueryç‰¹å¾ã€BEV+Cameraèåˆç‰¹å¾ã€ä½ç½®ä¿¡æ¯
â”‚   â”œâ”€ å¤„ç†ï¼šTransformerç¼–ç å™¨ï¼ˆ1å±‚ï¼‰
â”‚   â””â”€ è¾“å‡ºï¼šlidar_weights [bs, 900], camera_weights [bs, 900]
```

### **ä¸åŒç‚¹ï¼šæƒé‡çš„ä½¿ç”¨æ–¹å¼**

```
æ—§æ–¹æ¡ˆï¼šç‰¹å¾è°ƒåˆ¶ï¼ˆFeature Modulationï¼‰
â”œâ”€ WeightRendererï¼šæƒé‡ â†’ æƒé‡å›¾
â”œâ”€ FeatureModulatorï¼šæƒé‡å›¾ Ã— ç‰¹å¾å›¾
â””â”€ é—®é¢˜ï¼šç›´æ¥æ”¹å˜ç‰¹å¾å€¼ï¼Œç ´åé¢„è®­ç»ƒåˆ†å¸ƒ

æ–°æ–¹æ¡ˆï¼šæ³¨æ„åŠ›åç½®ï¼ˆAttention Biasï¼‰
â”œâ”€ AttentionBiasGeneratorï¼šæƒé‡ â†’ attention bias
â”œâ”€ Transformerå†…éƒ¨ï¼šbiasåŠ åˆ°attention scores
â””â”€ ä¼˜åŠ¿ï¼šä¸æ”¹ç‰¹å¾ï¼Œåªè°ƒåˆ¶queryçš„å…³æ³¨ç¨‹åº¦
```

---

## ğŸ“‹ **æ—§æ–¹æ¡ˆä»£ç æµç¨‹**

### CmtHeadä¸­çš„æ—§AQRå®ç°ï¼š

```python
# æ–‡ä»¶ï¼šcmt_head.py
class CmtHead(BaseModule):
    
    def __init__(self, ...):
        # åˆå§‹åŒ–AQRç»„ä»¶
        self.aqr_weight_generator = AQRWeightGenerator(...)
        self.weight_renderer = WeightRenderer(...)
        self.feature_modulator = FeatureModulator(...)
    
    def forward_single(self, x, x_img, img_metas):
        # 1. ç‰¹å¾é¢„å¤„ç†
        x = self.shared_conv(x)  # [bs, 256, 180, 180]
        reference_points = self.reference_points.weight  # [900, 3]
        
        # 2. ğŸ”¥ AQRæƒé‡ç”Ÿæˆ
        lidar_weights, camera_weights, _, projection_info = \
            self.aqr_weight_generator(
                query_embed=query_embeds,
                memory=memory,
                pos_embed=pos_embeds,
                ref_points=reference_points,
                img_metas=img_metas
            )
        # è¾“å‡ºï¼š
        # lidar_weights: [bs, 900]  - æ¯ä¸ªqueryçš„LiDARæƒé‡
        # camera_weights: [bs, 900] - æ¯ä¸ªqueryçš„Cameraæƒé‡
        # projection_info: {'pts_bev': ..., 'pts_pers_idx': ...}
        
        # 3. ğŸ¨ æƒé‡å›¾æ¸²æŸ“
        weight_map_bev = self.weight_renderer.render_bev_weights(
            lidar_weights,                          # [bs, 900]
            projection_info['pts_bev'],            # [bs, 900, 2] (y, x)
            feature_shape=(180, 180)
        )  # â†’ [bs, 180, 180]
        
        weight_map_pers = self.weight_renderer.render_perspective_weights(
            camera_weights,                         # [bs, 900]
            projection_info['pts_pers_idx'],       # [bs, 900, 3] (view, h, w)
            feature_shape=(6, 40, 100)
        )  # â†’ [bs, 6, 40, 100]
        
        # 4. âŒ ç‰¹å¾è°ƒåˆ¶ï¼ˆé—®é¢˜æ‰€åœ¨ï¼‰
        x_modulated = self.feature_modulator(
            x,                # [bs, 256, 180, 180] åŸå§‹BEVç‰¹å¾
            weight_map_bev    # [bs, 180, 180] æƒé‡å›¾
        )
        # å†…éƒ¨å®ç°ï¼š
        # x_modulated = x * weight_map_bev.unsqueeze(1) * (1 - residual_weight) + \
        #               x * residual_weight
        # é—®é¢˜ï¼š
        # - æƒé‡>1æ—¶ï¼Œç‰¹å¾å€¼è¢«æ”¾å¤§ï¼ˆ1.5åŸæœ¬ä»£è¡¨ç»¿è‰²ï¼Œå˜æˆ2.25ä¸çŸ¥é“ä»£è¡¨ä»€ä¹ˆï¼‰
        # - ç ´åäº†é¢„è®­ç»ƒbackboneå­¦åˆ°çš„ç‰¹å¾åˆ†å¸ƒ
        # - å°ç›®æ ‡å¯¹ç‰¹å¾åˆ†å¸ƒæ‰°åŠ¨æ›´æ•æ„Ÿ
        
        x_img_modulated = self.feature_modulator(
            x_img,            # [bs*6, 256, 40, 100] åŸå§‹Cameraç‰¹å¾
            weight_map_pers.view(-1, 40, 100)  # [bs*6, 40, 100]
        )
        
        # 5. ğŸ¤– æ ‡å‡†CMT Transformer
        outs_dec, _ = self.transformer(
            x_modulated,      # âŒ ä½¿ç”¨è¢«ä¿®æ”¹è¿‡çš„ç‰¹å¾
            x_img_modulated,  # âŒ ä½¿ç”¨è¢«ä¿®æ”¹è¿‡çš„ç‰¹å¾
            query_embeds,
            bev_pos_embeds,
            rv_pos_embeds,
            attn_masks=attn_mask
        )
        
        return outs_dec
```

---

## âœ… **æ–°æ–¹æ¡ˆä»£ç æµç¨‹**

### CmtHeadä¸­çš„æ–°AQRå®ç°ï¼š

```python
# æ–‡ä»¶ï¼šcmt_head.py
class CmtHead(BaseModule):
    
    def __init__(self, ...):
        # åˆå§‹åŒ–AQRç»„ä»¶ï¼ˆç®€åŒ–ï¼ï¼‰
        self.aqr_weight_generator = AQRWeightGenerator(...)
        self.attention_bias_generator = AttentionBiasGenerator(...)
        # ä¸å†éœ€è¦ï¼š
        # self.weight_renderer = None  â† åºŸå¼ƒ
        # self.feature_modulator = None  â† åºŸå¼ƒ
    
    def forward_single(self, x, x_img, img_metas):
        # 1. ç‰¹å¾é¢„å¤„ç†ï¼ˆå®Œå…¨ç›¸åŒï¼‰
        x = self.shared_conv(x)
        reference_points = self.reference_points.weight
        
        # 2. ğŸ”¥ AQRæƒé‡ç”Ÿæˆï¼ˆå®Œå…¨ç›¸åŒï¼ï¼‰
        lidar_weights, camera_weights, _, projection_info = \
            self.aqr_weight_generator(
                query_embed=query_embeds,
                memory=memory,
                pos_embed=pos_embeds,
                ref_points=reference_points,
                img_metas=img_metas
            )
        # è¾“å‡ºä»ç„¶æ˜¯ï¼š
        # lidar_weights: [bs, 900]
        # camera_weights: [bs, 900]
        
        # 3. âœ¨ ç”ŸæˆAttention Biasï¼ˆæ–°ï¼ï¼‰
        attention_bias = self.attention_bias_generator(
            lidar_weights,                          # [bs, 900]
            camera_weights,                         # [bs, 900]
            projection_info['pts_idx'],            # [bs, 900] BEV 1Dç´¢å¼•
            projection_info['pts_pers_idx']        # [bs, 900, 3]
        )  # â†’ [bs, 900, 56400]
        # 56400 = 180*180(BEV) + 6*40*100(Camera)
        
        # è¿™ä¸ªbiasçš„å«ä¹‰ï¼š
        # - bias[b, q, :] æ˜¯ç¬¬bä¸ªbatchçš„ç¬¬qä¸ªqueryå¯¹æ‰€æœ‰ç‰¹å¾çš„bias
        # - biaså€¼åœ¨queryæŠ•å½±çš„å±€éƒ¨çª—å£å†…éé›¶ï¼Œå…¶ä»–ä½ç½®ä¸º0
        # - biaså€¼ = è¯¥æ¨¡æ€çš„æƒé‡ï¼ˆlidaræˆ–cameraï¼‰
        
        # 4. âœ… ä¸ä¿®æ”¹ç‰¹å¾ï¼Œç›´æ¥ä¼ ç»™Transformer
        outs_dec, _ = self.transformer(
            x,                  # âœ… åŸå§‹BEVç‰¹å¾ï¼ˆæœªä¿®æ”¹ï¼‰
            x_img,              # âœ… åŸå§‹Cameraç‰¹å¾ï¼ˆæœªä¿®æ”¹ï¼‰
            query_embeds,
            bev_pos_embeds,
            rv_pos_embeds,
            attn_masks=attn_mask,
            attention_bias=attention_bias  # â† âœ¨ æ–°å‚æ•°
        )
        
        return outs_dec
```

### Transformerä¸­çš„Biasåº”ç”¨ï¼š

```python
# æ–‡ä»¶ï¼šcmt_transformer.py
class CmtTransformer(BaseModule):
    
    def forward(self, x, x_img, query_embed, 
                bev_pos_embed, rv_pos_embed,
                attn_masks=None,
                attention_bias=None):  # â† âœ¨ æ–°å‚æ•°
        
        # èåˆBEVå’ŒCameraç‰¹å¾ï¼ˆå®Œå…¨ç›¸åŒï¼‰
        memory = torch.cat([bev_memory, rv_memory], dim=0)
        # memory: [56400, bs, 256]
        
        # ä¼ é€’biasåˆ°decoder
        out_dec = self.decoder(
            query=target,
            key=memory,
            value=memory,
            attention_bias=attention_bias  # â† âœ¨ ä¼ é€’
        )
        
        return out_dec, memory
```

```python
# æ–‡ä»¶ï¼špetr_transformer.py
@TRANSFORMER_LAYER.register_module()
class PETRTransformerDecoderLayer(BaseTransformerLayer):
    
    def forward(self, query, key, value,
                attention_bias=None,  # â† âœ¨ æ–°å‚æ•°
                ...):
        
        # åœ¨cross_attnæ“ä½œä¸­åº”ç”¨bias
        for layer in self.operation_order:
            if layer == 'cross_attn':
                query = self.cross_attn(
                    query,                      # [900, bs, 256]
                    key,                        # [56400, bs, 256]
                    value,                      # [56400, bs, 256]
                    attention_bias=attention_bias  # [bs, 900, 56400]
                )
        
        return query
```

```python
# æ–‡ä»¶ï¼šmultihead_attention.py (éœ€è¦ä¿®æ”¹çš„åœ°æ–¹)
class MultiheadAttention(nn.Module):
    
    def forward(self, query, key, value,
                attention_bias=None,  # â† âœ¨ æ–°å‚æ•°
                ...):
        
        # æ ‡å‡†attentionè®¡ç®—
        Q = self.q_proj(query)    # [900, bs, 256]
        K = self.k_proj(key)      # [56400, bs, 256]
        V = self.v_proj(value)    # [56400, bs, 256]
        
        # è®¡ç®—attention scores
        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / sqrt(d_k)
        # attn_scores: [bs, num_heads, 900, 56400]
        
        # âœ¨ åº”ç”¨Attention Biasï¼ˆå…³é”®ï¼ï¼‰
        if attention_bias is not None:
            # attention_bias: [bs, 900, 56400]
            # éœ€è¦æ‰©å±•åˆ°å¤šå¤´
            bias = attention_bias.unsqueeze(1)  # [bs, 1, 900, 56400]
            bias = bias.expand(-1, self.num_heads, -1, -1)
            # [bs, num_heads, 900, 56400]
            
            attn_scores = attn_scores + bias  # â† âœ¨ åŠ bias
            
            # æ•ˆæœï¼š
            # - åŸæœ¬attn_scores[i, j] = Q[i] Â· K[j] / sqrt(d)
            # - ç°åœ¨å˜æˆï¼šattn_scores[i, j] = Q[i] Â· K[j] / sqrt(d) + bias[i, j]
            # - bias>0ï¼šå¢å¼ºè¯¥ä½ç½®çš„attention
            # - bias=0ï¼šä¸å½±å“ï¼ˆå±€éƒ¨çª—å£å¤–ï¼‰
        
        # Softmax + dropoutï¼ˆæ­£å¸¸æµç¨‹ï¼‰
        attn_weights = F.softmax(attn_scores, dim=-1)
        # softmaxä¼šè‡ªåŠ¨normalizeï¼Œæ‰€ä»¥biasçš„å½±å“æ˜¯ç›¸å¯¹çš„
        
        attn_weights = self.dropout(attn_weights)
        
        # è®¡ç®—è¾“å‡º
        output = torch.matmul(attn_weights, V)
        
        return output
```

---

## ğŸ“Š **Attention Biasçš„å·¥ä½œåŸç†**

### ç¤ºä¾‹ï¼šquery #42åœ¨BEV (90, 90)ä½ç½®

```python
# 1. AQRç”Ÿæˆæƒé‡
lidar_weight[42] = 0.7   # è¿™ä¸ªqueryè®¤ä¸ºLiDARæ›´å¯ä¿¡
camera_weight[42] = 0.3  # Cameraå¯ä¿¡åº¦è¾ƒä½

# 2. AttentionBiasGeneratorç”Ÿæˆå±€éƒ¨bias
# query #42æŠ•å½±åˆ°BEV (90, 90)
# å±€éƒ¨çª—å£ï¼š15Ã—15 = ä»¥(90,90)ä¸ºä¸­å¿ƒçš„225ä¸ªä½ç½®

bias[42] = [
    0, 0, ..., 0,                    # BEVå‰é¢çš„ä½ç½®ï¼ˆçª—å£å¤–ï¼‰
    0.7, 0.7, 0.7, ..., 0.7,        # BEVå±€éƒ¨çª—å£ï¼ˆ15Ã—15=225ä¸ªï¼‰
    0, 0, ..., 0,                    # BEVåé¢çš„ä½ç½®ï¼ˆçª—å£å¤–ï¼‰
    0.3, 0.3, ..., 0.3,             # Cameraå±€éƒ¨çª—å£
    0, 0, ..., 0                     # Cameraçª—å£å¤–
]  # æ€»é•¿åº¦ 56400

# 3. Transformerä¸­çš„attentionè®¡ç®—
# åŸå§‹attention scoresï¼ˆæœªåŠ biasï¼‰ï¼š
attn_scores_original[42] = [
    0.1, 0.05, ..., 0.15,  # BEVå„ä½ç½®çš„ç›¸ä¼¼åº¦
    0.08, 0.12, ..., 0.09  # Cameraå„ä½ç½®çš„ç›¸ä¼¼åº¦
]

# åŠ biasåï¼š
attn_scores_biased[42] = attn_scores_original[42] + bias[42]
# = [
#     0.1, 0.05, ..., 0.15,          # çª—å£å¤–ä¸å˜
#     0.1+0.7, 0.05+0.7, ...,        # BEVçª—å£å†… +0.7
#     0.15, ...,                      # çª—å£å¤–ä¸å˜
#     0.08+0.3, 0.12+0.3, ...,       # Cameraçª—å£å†… +0.3
#     0.09, ...                       # çª—å£å¤–ä¸å˜
# ]

# 4. Softmaxåçš„attention weights
# ç”±äºBEVçª—å£å†…çš„scoreså¢åŠ äº†0.7ï¼ˆé«˜äºCameraçš„0.3ï¼‰
# â†’ softmaxåï¼Œquery #42ä¼šæ›´å¤šåœ°å…³æ³¨BEVç‰¹å¾
# â†’ è¿™æ­£æ˜¯AQRçš„ç›®æ ‡ï¼

# 5. å…³é”®ï¼šç‰¹å¾å€¼æœ¬èº«æ²¡æœ‰è¢«ä¿®æ”¹ï¼
# Vï¼ˆvalueå‘é‡ï¼‰ä»ç„¶æ˜¯åŸå§‹ç‰¹å¾
# åªæ˜¯queryå¯¹ä¸åŒä½ç½®çš„å…³æ³¨ç¨‹åº¦æ”¹å˜äº†
```

---

## ğŸ¯ **ä¸ºä»€ä¹ˆæ–°æ–¹æ¡ˆæ›´å¥½**

### 1. **ä¿æŒç‰¹å¾è¯­ä¹‰**
```
æ—§æ–¹æ¡ˆï¼š
feature[i] = 1.5 (åŸæœ¬ä»£è¡¨ç»¿è‰²)
â†’ modulated_feature[i] = 1.5 Ã— 2.0 = 3.0 (ä¸çŸ¥é“ä»£è¡¨ä»€ä¹ˆ)
âŒ ç ´åäº†backboneå­¦åˆ°çš„ç‰¹å¾è¡¨ç¤º

æ–°æ–¹æ¡ˆï¼š
feature[i] = 1.5 (ä»ç„¶ä»£è¡¨ç»¿è‰²)
åªæ˜¯queryå¯¹è¿™ä¸ªä½ç½®çš„å…³æ³¨æƒé‡å˜äº†
âœ… ç‰¹å¾è¯­ä¹‰ä¸å˜
```

### 2. **ä¸é¢„è®­ç»ƒå…¼å®¹**
```
æ—§æ–¹æ¡ˆï¼š
backboneåœ¨ImageNetä¸Šå­¦ä¹ ï¼š1.5 = ç»¿è‰²
AQRæ”¹æˆ 3.0 â†’ backbone: "ä»€ä¹ˆé¬¼ï¼Ÿ"
âŒ åç¦»é¢„è®­ç»ƒåˆ†å¸ƒ

æ–°æ–¹æ¡ˆï¼š
backboneçœ‹åˆ°çš„ä»ç„¶æ˜¯ 1.5 = ç»¿è‰²
åªæ˜¯ä¸Šå±‚Transformerå†³å®šå…³æ³¨å“ªäº›ç‰¹å¾
âœ… å……åˆ†åˆ©ç”¨é¢„è®­ç»ƒçŸ¥è¯†
```

### 3. **æ›´ç¬¦åˆAttentionæœºåˆ¶**
```
æ—§æ–¹æ¡ˆï¼š
å¼ºè¡Œä¿®æ”¹è¾“å…¥ â†’ Transformerè¢«åŠ¨æ¥å—
âŒ è¿åäº†attentionçš„"åŠ¨æ€é€‰æ‹©"ç†å¿µ

æ–°æ–¹æ¡ˆï¼š
æä¾›bias â†’ Transformerä¸»åŠ¨è°ƒæ•´å…³æ³¨
âœ… ç¬¦åˆattentionçš„è®¾è®¡å“²å­¦
```

---

## ğŸ”— **AQRæ ¸å¿ƒç»„ä»¶çš„å¤ç”¨**

### å®Œå…¨å¤ç”¨çš„éƒ¨åˆ†ï¼š

```python
âœ… AQRWeightGeneratorï¼ˆæƒé‡ç”Ÿæˆå™¨ï¼‰
   - è¾“å…¥ã€è¾“å‡ºã€ç½‘ç»œç»“æ„å®Œå…¨ä¸å˜
   - ä»ç„¶ç”Ÿæˆ [bs, 900] çš„æƒé‡
   - ä»ç„¶ä½¿ç”¨LAMï¼ˆå±€éƒ¨æ³¨æ„åŠ›maskï¼‰
   - ä»ç„¶ä½¿ç”¨1å±‚Transformerç¼–ç å™¨

âœ… 3DæŠ•å½±é€»è¾‘
   - project_3d_to_features() å®Œå…¨ä¸å˜
   - pts_bev, pts_pers_idx è®¡ç®—æ–¹å¼ä¸å˜

âœ… è®­ç»ƒç›®æ ‡
   - ä»ç„¶æ˜¯å­¦ä¹ å“ªä¸ªæ¨¡æ€æ›´å¯ä¿¡
   - ä»ç„¶æ˜¯per-queryçš„ç»†ç²’åº¦æƒé‡
```

### æ›¿æ¢çš„éƒ¨åˆ†ï¼š

```python
âŒ WeightRendererï¼ˆæƒé‡å›¾æ¸²æŸ“å™¨ï¼‰
   æ›¿æ¢ä¸º â†’ AttentionBiasGenerator

âŒ FeatureModulatorï¼ˆç‰¹å¾è°ƒåˆ¶å™¨ï¼‰
   æ›¿æ¢ä¸º â†’ Transformerå†…éƒ¨çš„biasåº”ç”¨

æ”¹åŠ¨ç‚¹ï¼š
- ä»"æƒé‡æ¸²æŸ“åˆ°ç‰¹å¾å›¾"å˜æˆ"æƒé‡è½¬æ¢ä¸ºå±€éƒ¨bias"
- ä»"ç‰¹å¾å›¾ä¹˜æ³•"å˜æˆ"attentionåŠ æ³•"
```

---

## ğŸ“ˆ **é¢„æœŸæ”¹è¿›**

### ç†è®ºä¼˜åŠ¿ï¼š
1. **å°ç›®æ ‡æ€§èƒ½æ¢å¤**ï¼šä¸å†ç ´åç‰¹å¾åˆ†å¸ƒ
2. **è®­ç»ƒç¨³å®šæ€§æå‡**ï¼šé¿å…è¿‡åº¦è°ƒåˆ¶
3. **æ”¶æ•›é€Ÿåº¦åŠ å¿«**ï¼šä¸é¢„è®­ç»ƒbackboneå…¼å®¹
4. **æ³›åŒ–èƒ½åŠ›å¢å¼º**ï¼šä¿æŒç‰¹å¾è¯­ä¹‰ä¸€è‡´

### éœ€è¦éªŒè¯çš„ç‚¹ï¼š
1. biasçš„å¹…åº¦æ˜¯å¦éœ€è¦è°ƒæ•´ï¼ˆ`bias_scale`ï¼‰
2. çª—å£å¤§å°æ˜¯å¦æœ€ä¼˜ï¼ˆ`window_size=15`ï¼‰
3. æ˜¯å¦éœ€è¦å¯å­¦ä¹ çš„biasè½¬æ¢ï¼ˆå½“å‰æ˜¯å›ºå®šçš„ï¼‰

---

## ğŸ› ï¸ **è¿ç§»æŒ‡å—**

### ä»æ—§AQRè¿ç§»åˆ°æ–°AQRï¼š

```python
# é…ç½®æ–‡ä»¶ä¿®æ”¹
model = dict(
    pts_head=dict(
        enable_aqr=True,
        
        # âœ… ä¿ç•™ï¼šAQRæƒé‡ç”Ÿæˆé…ç½®
        aqr_config=dict(
            type='AQRWeightGenerator',
            embed_dims=256,
            window_sizes=[15, 5],
            # ... å…¶ä»–é…ç½®ä¸å˜
        ),
        
        # âŒ åˆ é™¤ï¼šæƒé‡æ¸²æŸ“å’Œç‰¹å¾è°ƒåˆ¶
        # renderer_config=dict(...),  # ä¸å†éœ€è¦
        # modulator_config=dict(...), # ä¸å†éœ€è¦
        
        # âœ¨ æ–°å¢ï¼šAttention Biasé…ç½®
        attention_bias_config=dict(
            type='AttentionBiasGenerator',
            window_size=15,
            bias_scale=1.0,
            use_local_bias=True,
            fp16=True
        )
    )
)
```

---

**æ€»ç»“ï¼šAttention Biasæ–¹æ¡ˆæ˜¯AQRçš„æ”¹è¿›ç‰ˆæœ¬ï¼Œä¿ç•™äº†æ ¸å¿ƒçš„æƒé‡ç”Ÿæˆé€»è¾‘ï¼Œåªæ”¹å˜äº†æƒé‡çš„ä½¿ç”¨æ–¹å¼ï¼** âœ¨ğŸ¾

